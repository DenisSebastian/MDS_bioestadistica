---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Teorema del Límite Central {#fundamentos}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(require(knitr))
suppressPackageStartupMessages(require(kableExtra))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(vegan))
```

## Teorema del Límite Central

El teorema central del límite (TCL) es una teoría estadística que establece que, dada una muestra aleatoria suficientemente grande de la población, la distribución de las medias muestrales seguirá una distribución normal.

Si se toman muestras repetidas de una población con varianza ﬁnita y se calculan sus promedios, entonces los promedios se distribuirán normalmente.

Esto es verdad incluso cuando las muestras son tomadas de una distribución NO normal, siempre y cuando se tomen el suficiente número de muestras.

## Demostración en R

Calculemos la media de cinco números aleatorios distribuidos uniformemente entre 0 y 10. La media será baja cuando obtengamos, ej., 2,3,1,2,1 y alta cuando obtengamos 9,8,9,6,8. Lo normal es que la media se acerque a 5. Hagamos esto 10.000 veces y observamos la distribución de las 10.000 medias. Los datos se distribuyen de forma rectangular (uniforme) en el intervalo de 0 a 10, por lo que la distribución de los datos brutos debería ser plana:

```{r}
# distribución de 10.000 números 
# aleatorios entre 0-10
hist(runif(10000)*10, main="")
set.seed(1234) # fijar semilla para que el proceso aleatorio sea siempre igual
A <- runif(10000)*10 # distribucion aleatoria uniforme
hist(A)

# media de la poblacion
mediaA <- mean(A)
```

¿Qué ocurre con la distribución de las medias muestrales, basada en la toma de sólo cinco números aleatorios uniformemente distribuidos?

```{r}
# creamos un vector numérico vacío de tamaño 10.000
means <- numeric(10000)
# llenamos el vector vacío con medias de 5 números aleatorios
for (i in 1:10000){
means[i] <- mean(runif(5)*10)
}

hist(means,ylim=c(0,1600),main="")

```

Se ve bien, pero ¿cuan cerca está de una distribución normal?

-   Dibujar un distribución normal teórica usando X y S de la muestra.
-   Test de normalidad.

```{r}
m <- mean(means)
desv <- sd(means)

xv <- seq(0,10, 0.1)
yv <-  dnorm(xv, mean = m, sd = desv)

hist(means,ylim=c(0,1600),main="")
lines(xv, yv)

```

### Test de Normalidad

```{r}
qqnorm(means)
qqline(means, lty=2)
shapiro.test(sample(x = means, 5000))

```

Función para generar muestras de medias y visualiza el histograma

```{r}
generar_muestras_de_medias <- function(numero, muestras = 5){
  means <- numeric(numero)
  for (i in 1:numero){ means[i] <- mean(runif(muestras)*10) }
  hist(means, main = paste('Distribucion', i, 'muestras'))
}

```

Diferencias entre medias muestrales con diferentes repeticiones

```{r fig.cap="Distribuciones en $n$"}
# como se ven las diferencias entre medias muestrales con diferentes repeticiones?
par(mfrow = c(2, 2))
for(i in c(10, 100, 1000, 100000)){
  generar_muestras_de_medias(i)
}
```

### Incrementar el número muestral

Cuando seleccionamos muestras de una distribución normal, la distribución de las medias muestrales de la muestra también tiene una forma "normal".

Aumentar el tamaño muestral disminuye la dispersión.

```{r fig.cap="Distribución normal de 5000 muestras"}
means <- numeric(5000)
for (i in 1:5000){ 
  means[i] <- mean(runif(5)*10) 
  }

hist(means, col = 'lightblue', main = '')
```


```{r fig.cap="valor de la media de todas estas medias muestreales"}
plot(density(means), main = '5.000 muestras')
abline(v = 5, lty = 2, col = "red")

mean(means)
sd(means)

# media de la poblacion?
mediaA
```


Este comportamiento parece bastante razonable. Se esperaría una estimación más precisa de la media de la población original si tomamos la media de muestras de mayor tamaño.

### Distribución muestral de X

Media de la distribución muestral es = a las media de la población original

$$\mu_{\bar{x}}=E(\bar{x})=\mu$$

Desviación estándar de la distribución muestral igual:

$$\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$$ Este es el error estándar de la media.

![Error estándar de la media](images/error_standar.png){fig-align="center" width="400"}


### Ajustar una curva normal

```{r}
# generar datos entre 0-1
xv <- seq(0,10,0.1)
dnorm(xv, mean = mean(means), sd = sd(means))

hist(means, main = "", ylim = c(1,800)) 
yv <- dnorm(xv, mean = mean(means), sd = 1.28996)*2500
lines(xv,yv)
```


### Test de Normalidad 

```{r fig.cap="Test de Normalidad shapiro.test"}
qqnorm(means)
qqline(means, lty = 2, col = "red", lwd = 2)
shapiro.test(means)
```

$p > 0.05$ --> NO se rechaza H0 = es normal

$p < 0.05$ --> se rechaza H0 = NO es normal

Referencias <https://bookdown.org/dietrichson/metodos-cuantitativos/test-de-normalidad.html>



## Distribución $t$ de Student

<br>

$t$ de Student

:   En probabilidad y estadística, la distribución $t$ (de Student) es una distribución de probabilidad que surge del problema de estimar la media de una población normalmente distribuida cuando el tamaño de la muestra es pequeño y la desviación estándar poblacional es desconocida.

::: callout-note
completar formulación [wiki](https://es.wikipedia.org/wiki/Distribución_t_de_Student)
:::

Si el tamaño muestral ($n$) es muy largo (e.g., \> 30), la distribución de t Student se aproxima a una distribución Normal.


```{r fig.cap="las distribuciones de probabilidad de la t student se generan a partir de dt y pt"}
par(mfrow = c(1, 2))
curve(dt(x, df = 15), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1, main = 'Dist. t Student')
curve(pt(x, df = 15), -4, 4, col = 'blue', ylab = 'y', lwd = 2, las = 1, main = 'Probabilidad t Student')


```





La distribución Normal necesita de valores de $\mu$ y $\sigma$. Acabamos de demostrar que no es posible estimar σ a partir de S:

-   $X$ es un estimador sin sesgo de $\mu$
-   $S$ es un estimador sesgado de $\sigma$

t Student es una distribución que se describe con dos parámetros:

-   $X$
-   $DF$ (deegrees of freedom), o grados de libertad

Tiene distinta forma según los grados de libertad (Degrees of freedom \[DF\])

$DF = ν = n - 1$


Variación de la distribucion de t Student con distintos DF

```{r}
degf <- c(1, 3, 8, 30)
colors <- c("red", "blue", "darkgreen", "gold", "black")
labels <- c("df = 1", "df = 3", "df = 8", "df = 30", "normal")
```

```{r}
par(mfrow = c(1, 1))
curve(dnorm(x), -4, 4, lty=2, ylab='y', lwd=2, las=1)

# plot t student's
for (i in 1:4){
  curve(dt(x, degf[i]), lwd=2, col=colors[i], add=TRUE)
}

legend("topright", inset = .05, title = "Distributions", 
       labels, lwd = 2, lty = c(1, 1, 1, 1, 2), col = colors, bty = "n")
```


La distribución t se utiliza cuando: 

* Queremos estimar la media de una población normalmente distribuida a partir de una muestra pequeña. 

* Tamaño de la muestra es inferior a 30 elementos, es decir, n < 30. 

No se conoce la desviación típica o estándar de una población y tiene que ser estimada a partir de las observaciones de la muestra.

![Distribución de medias con tamaño de muestra 25](images/dist_means.png){fig-align="center" width="500"}
$± 1 S$

67.3% No igual a Dist. Norm., pero Parecida


### Funciones para estimar el error

El error estándar:
```{r}
se <- function(x) { 
  sqrt(var(x)/length(x))
}
```

Rango probable de valores para un Estadígrafo

Intervalo de confianza = estadígrafo ± margen de error

```{r}
IntervConf <- function(x, alpha = 0.05) {
  t.value <- qt((1-alpha), length(x)-1) # qt -> quantile function for t distrituion
  standard.error <- se(x)
  ci <- t.value*standard.error
  cat(paste((1-alpha), "Confidence Interval = "), mean(x) - ci, "to ", mean(x) + ci,"\n") # concatenate and print
  }

```


Intervalo de confianza para estimar un parámetro de población, ej. la media:


$$X ± t_{n-1} \frac{S}{\sqrt{n}}$$
Aplicación de la prueba

```{r}
# generamos datos de prueba
x <- rnorm(150, 25, 3) # Recuerdan el orden de rnorm
hist(x)
mean(x)

# intervalo deconfianza al 95%
IntervConf(x)

# intervalo deconfianza al 99%
IntervConf(x, alpha = 0.01)
```




Nivel de confianza (alpha): Probabilidad que el intervalo de confianza contenga al parámetro de población

- Ej., 95% de nivel de confianza
- $\alpha$ = 0.05; 1/20 veces de estar equivocado (Error tipo I)



