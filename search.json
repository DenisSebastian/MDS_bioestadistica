[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso: Bioestadística 2022",
    "section": "",
    "text": "Este libro que contiene los apuntes personales del curso de Bioestadística. Master of Science, de la Universidad Adolfo Ibañez. Chile 2022.\nPorfesor Titular: Prof. Javier Lopatin | javier.lopatin@uai.cl\nPrincipalmente para los procesos análisis de datos y visualización de resultados se usará R Project\n\n\n\nIntroducción al lenguaje de programación R: Instalación del programa R y RStudio. Lectura de archivos externos. Gráficos y estadística descriptiva. Tipos básicos de herramientas estadísticas.\nRegresión lineal y no lineal: Correlación, estimación y predicción. Intervalos de confianza. Diagnósticos y Análisis de residuos. Calibración\nAnálisis multivariante: Métodos de reducción de dimensionalidad en los datos. PCA. Análisis de Clusters.\nAnálisis de varianza de un factor (one-way ANOVA): Fundamentos, métricas y ejemplos de uso.\nAnálisis de varianza de dos o más factores (two-way ANOVA): Diferencia con ANOVA de un factor. Ejemplos de uso.\nAnálisis de covarianza (ANCOVA): Fundamentos, métricas y ejemplos de uso.\nDiseños de muestreo: Muestreo aleatorio simple, estratificado, y sistemático. Muestreo de dos etapas. Determinación del tamaño de la muestra.\nEstadística no paramétrica: Introducción a la estadística no paramétrica. Cuando utilizarla. Principio de parsimonia.\nSeries de tiempo: Ajuste estacional, media móvil, suavizado exponencial, extrapolación, predicción lineal, Estimación de tendencias, estacionalidad y modelado ARIMA."
  },
  {
    "objectID": "fundamentos.html",
    "href": "fundamentos.html",
    "title": "2  Fundamendos Básicos",
    "section": "",
    "text": "Estadística:\n\nLa estadística es la ciencia de los datos. Consiste en recoger, clasificar, resumir, organizar analizar e interpretar la información numérica. (McClave and Sincich 2003)\n\n\n\n\nLa estadística es el análisis y la interpretación de los datos con vistas a una evaluación objetiva de la fiabilidad de las conclusiones basadas en los datos. (Zar 1999)\n\n\n\n\nLa capacidad de utilizar el pensamiento racional para interpretar el significado de los datos\nEsta capacidad puede ayudarle a tomar decisiones inteligentes, inferencias y generalizaciones\n(McClave and Sincich 2003)\n\n\n\n\nEl objetivo principal del análisis estadístico es inferir los parámetros de la población a partir de una muestra.\n\nPalabra “Parámetro” se refiere a las Poblaciones, e.j., µ, σ (i.e., letras Griegas)\nPalabra “Estadígrafo” (Statistics) se refiere a las Muestras, e.j., X, Sx (i.e., letras latinas)\n\nEstadígrafos pueden variar de muestra a muestra.\nQueremos que estos Estadígrafos sean buenas representaciones de los parámetros de la población.\n\n\n\n\n\nParámetros en estadística (población y muestra)\n\n\n\n\n\nDos tipos principales de estadística:\n\n\nDescriptiva\n\nUtiliza métodos numéricos y gráficos para buscar patrones en un conjunto de datos, para resumir la información revelada en un conjunto de datos y presentar esa información en una forma conveniente.\n\n\n\n\n\nInferencial\n\nEs una estimación, predicción o alguna otra generalización sobre una población basada en la información contenida en una muestra.\n\n\n\n(McClave and Sincich 2003)"
  },
  {
    "objectID": "fundamentos.html#e-descriptiva",
    "href": "fundamentos.html#e-descriptiva",
    "title": "2  Fundamendos Básicos",
    "section": "2.2 Estadística Descriptiva",
    "text": "2.2 Estadística Descriptiva\n\n\n\nEjemplos Estadísticas descriptiva con datos\n\n\n\n\n\nRepresentación de tipos de datos\n\n\n\n2.2.1 Muestras reperesentativas\n\nContiene características similares o típicas de la población.\nLa forma más común de obtener muestras representativas es mediante selección aleatoria.\nUna muestra aleatoria garantiza que cada subconjunto de tamaño fijo de la población tiene la misma probabilidad de ser incluido en la muestra\n\n\n\n2.2.2 Consideraciones de la Estadísticas Descriptiva\n\nDefinir la población o muestra de interés\nDefinir las variables o características de la población que se van a investigar.\nDefinir el tipo de estadística descriptiva a usar: gráficos, tablas, valores de resumen\nIdentificar patrones en los datos.\n\n(McClave and Sincich 2003)"
  },
  {
    "objectID": "fundamentos.html#m-tendencia-central",
    "href": "fundamentos.html#m-tendencia-central",
    "title": "2  Fundamendos Básicos",
    "section": "2.3 Medidas de Tendencias Central",
    "text": "2.3 Medidas de Tendencias Central\n\n\n\n\n\n\nflowchart LR\n  A{Medidas de Tendencia Central}\n  A --> C[Moda]:::class_c1\n  A --> D[Mediana]:::class_c1\n  A --> E[Media]:::class_c1\nstyle A fill:#5D6D7E,color:#fff\nclassDef class_c1 fill:#1ABC9C,color:#fff\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuciones Normales y Sesgadas\n\n\n(Zar 1999)\n\n2.3.1 Media Aritmética\n\nDefinición:\n\nLa media aritmética es un concepto matemático usado en estadística. También llamada promedio o simplemente media, se obtiene con la suma de un conjunto de valores dividida entre el número total de sumandos. Detalles en Wikipedia.\n\n\n\n\\mu=\\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}\n\n\nX_i: cada observación de la población/muestra\nN: tamaño de la población o muestra\n\nEjemplo de Media Aritmétrica con R\nMuestra de 24 registros de población de mariposas cuyo valor corresponde a el largo en cm.\n\nValoresSumaMediaAlternativa MediaHistograma\n\n\n\nW <- c(3.3,3.5,3.6,3.6,3.7,3.8,\n       3.8,3.8,3.9,3.9,3.9,4.0,\n       4.0,4.0,4.0,4.1,4.1,4.1,\n       4.2,4.2,4.3,4.3,4.4,4.5)\n\n\n\n\n\\displaystyle\\sum_{i=1}^{N}X_i=95cm\n\n\nsum(W)\n\n[1] 95\n\n\n\n\n\n\\mu=\\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}=3.96 cm\n\n\nmean(W)\n\n[1] 3.958333\n\n\n\n\n\nma <-  function(vector){\n  N = length(vector)\n  ma = sum(vector)/N\n  return(ma)\n}\nma(W)\n\n[1] 3.958333\n\n\n\n\n\nhist(W, col = \"gray97\")\nabline(v=mean(W), col=\"red\")\n\n\n\n\n\n\n\n\n\n2.3.2 Mediana\n\nDefinición:\n\nEn el ámbito de la estadística, la mediana (del latín medianus ‘del medio’) representa el valor de la variable de posición central en un conjunto de datos ordenados. Se le denota mediana, si la serie tiene un número par de puntuaciones, la mediana es la media entre las dos puntuaciones centrales.\n\n\nDetalles en wikipedia\n\nEs el valor del medio de un set de datos ordenados.\nSe puede entender también como el valor donde está el 50% de los datos.\n\n\n\n\nEncontrar la mediana\n\n\n\nsort(W)\n\n [1] 3.3 3.5 3.6 3.6 3.7 3.8 3.8 3.8 3.9 3.9 3.9 4.0 4.0 4.0 4.0 4.1 4.1 4.1 4.2\n[20] 4.2 4.3 4.3 4.4 4.5\n\n\n\nmedian(W)\n\n[1] 4\n\n\n\n\n2.3.3 Moda\n\nDefinición:\n\nEn la estadística, la moda es el valor que aparece con mayor frecuencia en un conjunto de datos. Esto va en forma de una columna cuando encontremos dos modas, es decir, dos datos que tengan la misma frecuencia absoluta máxima. Una distribución trimodal de los datos es en la que encontramos tres modas. En el caso de la distribución uniforme discreta, cuando todos los datos tienen una misma frecuencia, se puede definir las modas como indicado, pero estos lores no tienen utilidad. Por eso algunos matemáticos califican esta distribución como “sin moda”.\n\n\nDetalles en wikipedia\nValor más frecuente en un set de datos.\n\ntable(W)\n\nW\n3.3 3.5 3.6 3.7 3.8 3.9   4 4.1 4.2 4.3 4.4 4.5 \n  1   1   2   1   3   3   4   3   2   2   1   1 \n\n\nEn R no existe una función específica pero se puede crear una:\n\nmoda <- function(x) {\n  uniqv <- unique(x)\n  uniqv[which.max(tabulate(match(x, uniqv)))]\n}\nmoda(W)\n\n[1] 4"
  },
  {
    "objectID": "fundamentos.html#medidas-de-dispersión-y-variabilidad",
    "href": "fundamentos.html#medidas-de-dispersión-y-variabilidad",
    "title": "2  Fundamendos Básicos",
    "section": "2.4 Medidas de Dispersión y Variabilidad",
    "text": "2.4 Medidas de Dispersión y Variabilidad\n\n2.4.1 Rango\n\n\nDefinición:\n\nDiferencia entre el valor más alto y más bajo de la muestra\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRango de la muestra subestima el rango de la población (problema con los extremos)\n\n\nEj., botánicos lo usan para medir las dimensiones de hojas y flores.\n\n\n\nRango\n\n\n\nCálculo Directo RLa función rango()\n\n\n\nmax(W) - min(W)\n\n[1] 1.2\n\n\n\n\nRetorna los valores mínimos y máximos de la muestra\n\nrange(W) \n\n[1] 3.3 4.5\n\n\n\n\n\n\n\n2.4.2 Cuartiles, Cuantiles y Percentiles\n\n\nCuartiles:\n\nDividen la población en 4 partes iguales, describiendo los valores acumulados al 0%, 25%, 50%, 75% y 100% (steps de 25%).\n\nCuantiles y Percentiles:\n\nDescriben lo mismo, pero no necesariamente se divide la muestra en 4 partes. Ej., se puede dividir en 10: 0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%\n\n\n\n\n\n\n\n\nCuartiles en RAjuste de los porcentajes\n\n\n\nquantile(W)\n\n   0%   25%   50%   75%  100% \n3.300 3.800 4.000 4.125 4.500 \n\n\n\n\n\nquantile(W, probs = c(0.05, 0.25, 0.5, 0.75, 0.95)) #\n\n   5%   25%   50%   75%   95% \n3.515 3.800 4.000 4.125 4.385 \n\n\n\n\n\n\n\n2.4.3 Rango Intercuartil (IQR)\n\nDistancia entre Q1 y Q3, el primer y segundo cuartil (25% y 75%).\nMás robusto que el rango normal\nNo afectan los outliars.\n\n\nIQR = Q3 - Q1\n\nRango intercuantil IQR = 75% - 25%\n\n\n\n\n\n\nCáculo en RAlternativa\n\n\n\nquantile(W, 0.75) - quantile(W, 0.25)\n\n  75% \n0.325 \n\n\n\n\n\nquantile(W)[4] - quantile(W)[2]\n\n  75% \n0.325 \n\n\n\n\n\n\n\n2.4.4 Varianza\n\nSuma de los cuadrados (SS) de las desviaciones de la media.\nDescribe la dispersión media en torno al valor medio\n\nDatos Población Total\n\n\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\mu)^2} {N}\n\nDatos Muestrales\n\nS^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\bar{X})^2} {n-1}\n\n\nWikipedia: (“Varianza” 2022)\nVideo: (Matemáticas profe Alex 2017)\n\n\nvar(W)\n\n[1] 0.08514493\n\n\n\n\n2.4.5 Desviación Estándar\nEs una medida que se utiliza para cuantificar la variación o la dispersión de un conjunto de datos numéricos.\nUna desviación estándar baja indica que la mayor parte de los datos de una muestra tienden a estar agrupados cerca de su media (también denominada el valor esperado), mientras que una desviación estándar alta indica que los datos se extienden sobre un rango de valores más amplio.\n\nDesviación Estándar paraDatos Población Total\n\n\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\mu)^2} {N}}\n\nDesviación Estándar para Datos Muestrales:\n\nS = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\bar{X})^2} {n-1}}\n\n\nValoresFórmulaFunción sd()GráficoCod_Graph\n\n\n\nW <- c(3.3,3.5,3.6,3.6,3.7,3.8,\n       3.8,3.8,3.9,3.9,3.9,4.0,\n       4.0,4.0,4.0,4.1,4.1,4.1,\n       4.2,4.2,4.3,4.3,4.4,4.5)\n\n\n\n\n\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\mu)^2} {N}}\n\n\n\n\nsd(W)\n\n[1] 0.291796\n\n\n\n\n\n\n\n\n\n\n\n\n# graficar la +- 1 DE y +- 2 DE en un histograma?\nhist(W)\nabline(v=mean(W), col='red')\n\n## +- 1 DE ---------------------------------------------------------------\nabline(v=mean(W)+sd(W), col='blue')\nabline(v=mean(W)-sd(W), col='blue')\n\n## +- 2 DE ---------------------------------------------------------------\nabline(v=mean(W)+sd(W)*2, col='green')\nabline(v=mean(W)-sd(W)*2, col='green')\n\n\n\n\n\n\n2.4.6 Coeficiente de Variación\n\nCómo la desviación estándar, pero normalizado a un porcentaje.\nSirve para comparar la variación entre datos de distintas poblaciones/muestras!\n\nV=\\frac{s}{\\bar{X}}\n\nsd(W) / mean(W) * 100\n\n[1] 7.371689\n\n\n\n\n2.4.7 índices de Diversidad\n\nEn el caso de los datos de escala nominal, no existe una media o una mediana que sirva de referencia para hablar de la dispersión\nPodemos invocar el concepto de diversidad, la distribución de las observaciones entre las categorías\nObservaciones distribuidas uniformemente en las categorías tienen Diversidad alta, mientras que observaciones que ocurren en pocas clases tiene Div. baja.\n\n\n2.4.7.1 Shannon-Wiener diversity index\n\nH'= \\sum_{i=1}^k {p_i \\ log \\ p_i}\n\n\nK = número de clases\nP_i proporción de obs. de la clases i\n\n\n\n2.4.7.2 Shannon-Wiener evenness index (índice de uniformidad)\n\nJ' = \\frac{H'}{H_{max}} \\qquad H_{max}= log\\ k\n\n\n\n2.4.7.3 Datos con una dimensión 1D\n\nDataFormulaCódigoResultado\n\n\n\n\n\n\n \n  \n    especies \n    frecuencia \n  \n \n\n  \n    a \n    44 \n  \n  \n    b \n    3 \n  \n  \n    c \n    28 \n  \n  \n    d \n    12 \n  \n  \n    e \n    2 \n  \n  \n    f \n    8 \n  \n\n\n\n\n\n\n\n\nH'= \\sum_{i=1}^k {p_i \\ log \\ p_i}\n\n\n\n\nespecies   <- c('a','b','c','d','e','f')\nfrecuencia <- c(44,3,28,12,2,8)\n\n# funcion manual para vector de 1D\ndiversidad <- function(x){\n  x <- x/(total <- sum(x)) # Proporcion de cada especie\n  x <- -x * log(x, exp(1)) \n  H <- sum(x, na.rm = TRUE)\n  H\n}\n\n\n\n\ndiversidad(frecuencia)\n\n[1] 1.369117\n\n\n\n\n\nEjemplo en R de ídice de diversidad con la función diversity() de la librería vegan.\n\nDataCódigo\n\n\n\n\n\n\n \n  \n    especies \n    frecuencia \n  \n \n\n  \n    a \n    44 \n  \n  \n    b \n    3 \n  \n  \n    c \n    28 \n  \n  \n    d \n    12 \n  \n  \n    e \n    2 \n  \n  \n    f \n    8 \n  \n\n\n\n\n\n\n\n\nlibrary(vegan)\ndiversity(frecuencia) \n\n[1] 1.369117\n\n\n\n\n\n\n\n2.4.7.4 Datos con más de una dimensión\nLectura de datos\nBarro Colorado Island Tree Counts: Tree counts in 1-hectare plots in the Barro Colorado Island and associated site information.\n\ndata(BCI)\ndata(BCI.env)\n\nCálculo de BCI\n\n#### Diversity  ---------------------------------------------------------\ndiv <- diversity(BCI)\ndiv\n\n       1        2        3        4        5        6        7        8 \n4.018412 3.848471 3.814060 3.976563 3.969940 3.776575 3.836811 3.908381 \n       9       10       11       12       13       14       15       16 \n3.761331 3.889803 3.859814 3.698414 3.982373 4.017494 3.956635 3.916821 \n      17       18       19       20       21       22       23       24 \n3.736897 3.944985 4.013094 4.077327 3.969925 3.755413 4.062575 3.979427 \n      25       26       27       28       29       30       31       32 \n4.074718 3.947749 3.980281 3.693896 3.688721 3.851598 3.724967 3.784873 \n      33       34       35       36       37       38       39       40 \n3.740392 3.821669 2.641859 3.846109 3.791703 3.516082 3.530494 3.234849 \n      41       42       43       44       45       46       47       48 \n4.052495 3.966614 3.736254 3.705016 3.609518 3.810489 3.920918 3.913725 \n      49       50 \n3.778851 3.906616 \n\n\nAnalizar gradientes entre diversidad y variables\n\n# analizar gradientes entre diversidad y variables\nplot(x = div, y = BCI.env$Precipitation)\nabline(h=2530, col=\"red\")\n\n\n\n\n\nplot(x = div, y = BCI.env$Habitat)\n\n\n\n\n\n\n\n\nMatemáticas profe Alex. 2017. “Varianza y Desviación Estándar | Introducción,” June. https://www.youtube.com/watch?v=oZRaDwnpXkY.\n\n\nMcClave, J. T., and T. Sincich. 2003. Statistics. Prentice Hall.\n\n\n“Varianza.” 2022. https://es.wikipedia.org/w/index.php?title=Varianza&oldid=144468342.\n\n\nZar, Jerrold H. 1999. Biostatistical Analysis. Pearson Education India."
  },
  {
    "objectID": "d_prob.html",
    "href": "d_prob.html",
    "title": "3  Distr. de Probabilidades",
    "section": "",
    "text": "Espacio muestral: El conjunto de todos los posibles resultados de un experimento aleatorio\nDiscreto: Si cada resultado puede ponerse en correspondencia uno a uno con enteros positivos\nContinuo: Si sus resultados consisten de un intervalo de números reales\n\n(Canavos 1988)"
  },
  {
    "objectID": "d_prob.html#distribución-de-probabilidad-discreta",
    "href": "d_prob.html#distribución-de-probabilidad-discreta",
    "title": "3  Distr. de Probabilidades",
    "section": "3.2 Distribución de Probabilidad Discreta",
    "text": "3.2 Distribución de Probabilidad Discreta\nSi X es una variable aleatoria;\n\nSe llamará a p(x) = P(X=x) función de probabilidad de la variable aleatoria X, si satisface las siguientes propiedades:\n\n\np(x)\\geq 0, \\forall \\ x\\in X\\\\\n\\Sigma_x p(x)=1\n\nLa función de distribución acumulativa de la variable aleatoria X, es la probabilidad de que X sea menor o igual a un valor específico de x y está dada por:\n\nF(x)\\equiv P(X\\leq x) = \\sum_{x_i\\leq x}p(x_i)\n\nPropiedades:\n\n\n0\\leq F(x)\\leq, \\forall x\n\nEntre 0 y 1\n\n\n\n\nF(x_i)\\geq F(x_i) si x_i\\geq x_j\n\nMientras más grande el número X, más probabilidad acumulada\n\n\n\n\nP(X>x)= 1-F(x)\n\nLa P acumulada de x es igual a 1 - la P del número.\n\n\n(Canavos 1988)"
  },
  {
    "objectID": "d_prob.html#distribución-normal",
    "href": "d_prob.html#distribución-normal",
    "title": "3  Distr. de Probabilidades",
    "section": "3.3 Distribución Normal",
    "text": "3.3 Distribución Normal\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\n3.3.1 Gráficar en la Distribución Normal\nDiferentes alternativas\n\nAlternative 1: doing the math ourselvesAlternative 2: using dnorm()alternative 3: using cruve()\n\n\n\nx = seq(-4, 4, length = 200)\ny = 1 / sqrt(2 * pi) * exp(-x ^ 2 / 2)\n\nplot(x, y, type = \"l\", lwd = 4, col = \"red\", las = 1)\nabline(v = mean(x), col=\"gray60\")\n\n\n\n\n\n\n\nx = seq(-4,4,length=200)\ny = dnorm(x)\nplot(x, y, type = \"l\", lwd = 4, col = \"blue\", las = 1) # probar distintos argumentos\n\n\n\n#https://www.learnbyexample.org/r-plot-function/\n\n\n\n\ncurve(dnorm(x), -4, 4, col='green', ylab='y', lwd=4, las=1)\n\n\n\n\n\n\n\ndiferentes media y misma desviación estandar\n\ndiferentes \\mu y misma \\sigmaDiferente \\sigma ymismo \\mu\n\n\n\ncurve(dnorm(x, mean=0, sd=1), -4, 4, col='blue', ylab='f(x)', lwd=2, las=1)\ncurve(dnorm(x, mean=1, sd=1), -4, 4, col='red', lwd=2, add=TRUE)\ncurve(dnorm(x, mean=2, sd=1), -4, 4, col='green', lwd=2, add=TRUE)\nlegend('topleft', legend=c('mean=0; sd=1','mean=1; sd=1','mean=2; sd=1'),\n       lwd=2, col=c('blue','red','green'), bty='n')\n\n\n\n\n\n\n\ncurve(dnorm(x, mean=0, sd=1), -4, 4, col='blue', ylab='f(x)', lwd=2, las=1)\ncurve(dnorm(x, mean=0, sd=1.5), -4, 4, col='red', lwd=2, add=TRUE)\ncurve(dnorm(x, mean=0, sd=2), -4, 4, col='green', lwd=2, add=TRUE)\n#abline(v = 0, lty = 2, col = 'gray')\nlegend('topleft', legend=c('mean=0; sd=1','mean=0; sd=1.5','mean=0; sd=2'),\n       lwd=2, col=c('blue','red','green'), bty='n')\n\n\n\n\n\n\n\nDistribuciópn Acumulada\n\nprob <- pnorm(1, mean=0, sd=1)\nprob # percentage\n\n[1] 0.8413447\n\nxmin <- -4\nxmax <- 1\n\nx = seq(xmin, xmax, length=200)\ny = dnorm(x)\n\ncurve(dnorm(x), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1, main = 'Distribucion')\n\npolygon(c(xmin, x, xmax), c(0, y, 0), col = \"gray\")\ntext(0, 0.1, round(prob, 2), col = \"Red\")\n\n\n\n\n\nmean +- 1 sd = 68% measurementsprobability of having a value over 1.4?\n\n\nP(-1 <= x <= 1)\n\nprob <- pnorm(1) - pnorm(-1)\nprob\n\n[1] 0.6826895\n\nxmin <- -1\nxmax <- 1\n\nx = seq(xmin, xmax, length = 200)\ny = dnorm(x)\n\ncurve(dnorm(x), -4, 4, col = 'red', ylab='y', lwd = 2, las = 1)\npolygon(c(xmin, x, xmax), c(0, y, 0), col = \"gray\")\ntext(0, 0.1, round(prob, 3), col = \"Red\")\n\n\n\n\n\n\nP(x >= 1.4)\n\nprob <- 1-pnorm(1.4)\nprob\n\n[1] 0.08075666\n\nxmin <- 1.4\nxmax <- 4\n\nx = seq(xmin, xmax, length = 200)\ny = dnorm(x)\n\ncurve(dnorm(x), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1)\npolygon(c(xmin, x, xmax), c(0, y, 0), col = \"gray\")\ntext(1.8, 0.03, round(prob, 3), col = \"Red\")"
  },
  {
    "objectID": "d_prob.html#estadígrafos",
    "href": "d_prob.html#estadígrafos",
    "title": "3  Distr. de Probabilidades",
    "section": "3.4 Estadígrafos",
    "text": "3.4 Estadígrafos\nQuantile–quantile plot (Q-Q plot): Gráfico traza las muestras clasificadas de nuestra distribución contra un número similar de cuantiles clasificados tomados de una distribución normal. Si la muestra está distribuida normalmente, la línea será recta. Las desviaciones de la normalidad aparecen como varios tipos de no linealidad (por ejemplo, formas de S o formas de plátano). Las funciones que necesita son qqnorm y qqline (gráfico de cuantiles contra una distribución normal):\n\n\nholaa\n\ndsds"
  },
  {
    "objectID": "d_prob.html#tarea",
    "href": "d_prob.html#tarea",
    "title": "3  Distr. de Probabilidades",
    "section": "3.5 Tarea",
    "text": "3.5 Tarea"
  },
  {
    "objectID": "t_limite_central.html",
    "href": "t_limite_central.html",
    "title": "4  Teorema del Límite Central",
    "section": "",
    "text": "El teorema central del límite (TCL) es una teoría estadística que establece que, dada una muestra aleatoria suficientemente grande de la población, la distribución de las medias muestrales seguirá una distribución normal.\nSi se toman muestras repetidas de una población con varianza ﬁnita y se calculan sus promedios, entonces los promedios se distribuirán normalmente.\nEsto es verdad incluso cuando las muestras son tomadas de una distribución NO normal, siempre y cuando se tomen el suficiente número de muestras."
  },
  {
    "objectID": "t_limite_central.html#demostración-en-r",
    "href": "t_limite_central.html#demostración-en-r",
    "title": "4  Teorema del Límite Central",
    "section": "4.2 Demostración en R",
    "text": "4.2 Demostración en R\nCalculemos la media de cinco números aleatorios distribuidos uniformemente entre 0 y 10. La media será baja cuando obtengamos, ej., 2,3,1,2,1 y alta cuando obtengamos 9,8,9,6,8. Lo normal es que la media se acerque a 5. Hagamos esto 10.000 veces y observamos la distribución de las 10.000 medias. Los datos se distribuyen de forma rectangular (uniforme) en el intervalo de 0 a 10, por lo que la distribución de los datos brutos debería ser plana:\n\n# distribución de 10.000 números \n# aleatorios entre 0-10\nhist(runif(10000)*10, main=\"\")\n\n\n\nset.seed(1234) # fijar semilla para que el proceso aleatorio sea siempre igual\nA <- runif(10000)*10 # distribucion aleatoria uniforme\nhist(A)\n\n\n\n# media de la poblacion\nmediaA <- mean(A)\n\n¿Qué ocurre con la distribución de las medias muestrales, basada en la toma de sólo cinco números aleatorios uniformemente distribuidos?\n\n# creamos un vector numérico vacío de tamaño 10.000\nmeans <- numeric(10000)\n# llenamos el vector vacío con medias de 5 números aleatorios\nfor (i in 1:10000){\nmeans[i] <- mean(runif(5)*10)\n}\n\nhist(means,ylim=c(0,1600),main=\"\")\n\n\n\n\nSe ve bien, pero ¿cuan cerca está de una distribución normal?\n\nDibujar un distribución normal teórica usando X y S de la muestra.\nTest de normalidad.\n\n\nm <- mean(means)\ndesv <- sd(means)\n\nxv <- seq(0,10, 0.1)\nyv <-  dnorm(xv, mean = m, sd = desv)\n\nhist(means,ylim=c(0,1600),main=\"\")\nlines(xv, yv)\n\n\n\n\n\n4.2.1 Test de Normalidad\n\nqqnorm(means)\nqqline(means, lty=2)\n\n\n\nshapiro.test(sample(x = means, 5000))\n\n\n    Shapiro-Wilk normality test\n\ndata:  sample(x = means, 5000)\nW = 0.99905, p-value = 0.006669\n\n\nFunción para generar muestras de medias y visualiza el histograma\n\ngenerar_muestras_de_medias <- function(numero, muestras = 5){\n  means <- numeric(numero)\n  for (i in 1:numero){ means[i] <- mean(runif(muestras)*10) }\n  hist(means, main = paste('Distribucion', i, 'muestras'))\n}\n\nDiferencias entre medias muestrales con diferentes repeticiones\n\n# como se ven las diferencias entre medias muestrales con diferentes repeticiones?\npar(mfrow = c(2, 2))\nfor(i in c(10, 100, 1000, 100000)){\n  generar_muestras_de_medias(i)\n}\n\n\n\n\nDistribuciones en n\n\n\n\n\n\n\n4.2.2 Incrementar el número muestral\nCuando seleccionamos muestras de una distribución normal, la distribución de las medias muestrales de la muestra también tiene una forma “normal”.\nAumentar el tamaño muestral disminuye la dispersión.\n\nmeans <- numeric(5000)\nfor (i in 1:5000){ \n  means[i] <- mean(runif(5)*10) \n  }\n\nhist(means, col = 'lightblue', main = '')\n\n\n\n\nDistribución normal de 5000 muestras\n\n\n\n\n\nplot(density(means), main = '5.000 muestras')\nabline(v = 5, lty = 2, col = \"red\")\n\n\n\n\nvalor de la media de todas estas medias muestreales\n\n\n\nmean(means)\n\n[1] 4.977626\n\nsd(means)\n\n[1] 1.296756\n\n# media de la poblacion?\nmediaA\n\n[1] 5.003123\n\n\nEste comportamiento parece bastante razonable. Se esperaría una estimación más precisa de la media de la población original si tomamos la media de muestras de mayor tamaño.\n\n\n4.2.3 Distribución muestral de X\nMedia de la distribución muestral es = a las media de la población original\n\\mu_{\\bar{x}}=E(\\bar{x})=\\mu\nDesviación estándar de la distribución muestral igual:\n\\sigma_{\\bar{x}}=\\frac{\\sigma}{\\sqrt{n}} Este es el error estándar de la media.\n\n\n\nError estándar de la media\n\n\n\n\n4.2.4 Ajustar una curva normal\n\n# generar datos entre 0-1\nxv <- seq(0,10,0.1)\ndnorm(xv, mean = mean(means), sd = sd(means))\n\n  [1] 0.0001943350 0.0002605044 0.0003471333 0.0004598275 0.0006054955\n  [6] 0.0007925820 0.0010313233 0.0013340214 0.0017153317 0.0021925564\n [11] 0.0027859336 0.0035189095 0.0044183769 0.0055148635 0.0068426465\n [16] 0.0084397733 0.0103479613 0.0126123539 0.0152811078 0.0184047900\n [21] 0.0220355671 0.0262261737 0.0310286566 0.0364928978 0.0426649328\n [26] 0.0495850913 0.0572860011 0.0657905072 0.0751095740 0.0852402473\n [31] 0.0961637610 0.1078438832 0.1202255942 0.1332341894 0.1467748933\n [36] 0.1607330553 0.1749749848 0.1893494580 0.2036899049 0.2178172558\n [41] 0.2315433947 0.2446751414 0.2570186494 0.2683840879 0.2785904518\n [46] 0.2874703311 0.2948744665 0.3006759172 0.3047736796 0.3070956111\n [51] 0.3076005435 0.3062794967 0.3031559445 0.2982851205 0.2917523940\n [56] 0.2836707811 0.2741776932 0.2634310538 0.2516049365 0.2388848918\n [61] 0.2254631380 0.2115337888 0.1972882800 0.1829111425 0.1685762449\n [66] 0.1544436036 0.1406568265 0.1273412300 0.1146026351 0.1025268240\n [71] 0.0911796125 0.0806074751 0.0708386426 0.0618845848 0.0537417828\n [76] 0.0463936984 0.0398128491 0.0339629072 0.0288007499 0.0242784005\n [81] 0.0203448121 0.0169474606 0.0140337237 0.0115520364 0.0094528226\n [86] 0.0076892115 0.0062175523 0.0049977488 0.0039934361 0.0031720234\n [91] 0.0025046288 0.0019659284 0.0015339435 0.0011897846 0.0009173703\n [96] 0.0007031344 0.0005357342 0.0004057679 0.0003055086 0.0002286580\n[101] 0.0001701245\n\nhist(means, main = \"\", ylim = c(1,800)) \nyv <- dnorm(xv, mean = mean(means), sd = 1.28996)*2500\nlines(xv,yv)\n\n\n\n\n\n\n4.2.5 Test de Normalidad\n\nqqnorm(means)\nqqline(means, lty = 2, col = \"red\", lwd = 2)\n\n\n\n\nTest de Normalidad shapiro.test\n\n\n\nshapiro.test(means)\n\n\n    Shapiro-Wilk normality test\n\ndata:  means\nW = 0.99869, p-value = 0.0004339\n\n\np > 0.05 –> NO se rechaza H0 = es normal\np < 0.05 –> se rechaza H0 = NO es normal\nReferencias https://bookdown.org/dietrichson/metodos-cuantitativos/test-de-normalidad.html"
  },
  {
    "objectID": "t_limite_central.html#distribución-t-de-student",
    "href": "t_limite_central.html#distribución-t-de-student",
    "title": "4  Teorema del Límite Central",
    "section": "4.3 Distribución t de Student",
    "text": "4.3 Distribución t de Student\n\n\nt de Student\n\nEn probabilidad y estadística, la distribución t (de Student) es una distribución de probabilidad que surge del problema de estimar la media de una población normalmente distribuida cuando el tamaño de la muestra es pequeño y la desviación estándar poblacional es desconocida.\n\n\n\n\n\n\n\n\nNote\n\n\n\ncompletar formulación wiki\n\n\nSi el tamaño muestral (n) es muy largo (e.g., > 30), la distribución de t Student se aproxima a una distribución Normal.\n\npar(mfrow = c(1, 2))\ncurve(dt(x, df = 15), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1, main = 'Dist. t Student')\ncurve(pt(x, df = 15), -4, 4, col = 'blue', ylab = 'y', lwd = 2, las = 1, main = 'Probabilidad t Student')\n\n\n\n\nlas distribuciones de probabilidad de la t student se generan a partir de dt y pt\n\n\n\n\nLa distribución Normal necesita de valores de \\mu y \\sigma. Acabamos de demostrar que no es posible estimar σ a partir de S:\n\nX es un estimador sin sesgo de \\mu\nS es un estimador sesgado de \\sigma\n\nt Student es una distribución que se describe con dos parámetros:\n\nX\nDF (deegrees of freedom), o grados de libertad\n\nTiene distinta forma según los grados de libertad (Degrees of freedom [DF])\nDF = ν = n - 1\nVariación de la distribucion de t Student con distintos DF\n\ndegf <- c(1, 3, 8, 30)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\", \"black\")\nlabels <- c(\"df = 1\", \"df = 3\", \"df = 8\", \"df = 30\", \"normal\")\n\n\npar(mfrow = c(1, 1))\ncurve(dnorm(x), -4, 4, lty=2, ylab='y', lwd=2, las=1)\n\n# plot t student's\nfor (i in 1:4){\n  curve(dt(x, degf[i]), lwd=2, col=colors[i], add=TRUE)\n}\n\nlegend(\"topright\", inset = .05, title = \"Distributions\", \n       labels, lwd = 2, lty = c(1, 1, 1, 1, 2), col = colors, bty = \"n\")\n\n\n\n\nLa distribución t se utiliza cuando:\n\nQueremos estimar la media de una población normalmente distribuida a partir de una muestra pequeña.\nTamaño de la muestra es inferior a 30 elementos, es decir, n < 30.\n\nNo se conoce la desviación típica o estándar de una población y tiene que ser estimada a partir de las observaciones de la muestra.\n ± 1 S\n67.3% No igual a Dist. Norm., pero Parecida\n\n4.3.1 Funciones para estimar el error\nEl error estándar: ::: {.cell}\nse <- function(x) { \n  sqrt(var(x)/length(x))\n}\n:::\nRango probable de valores para un Estadígrafo\nIntervalo de confianza = estadígrafo ± margen de error\n\nIntervConf <- function(x, alpha = 0.05) {\n  t.value <- qt((1-alpha), length(x)-1) # qt -> quantile function for t distrituion\n  standard.error <- se(x)\n  ci <- t.value*standard.error\n  cat(paste((1-alpha), \"Confidence Interval = \"), mean(x) - ci, \"to \", mean(x) + ci,\"\\n\") # concatenate and print\n  }\n\nIntervalo de confianza para estimar un parámetro de población, ej. la media:\nX ± t_{n-1} \\frac{S}{\\sqrt{n}}\nAplicación de la prueba\n\n# generamos datos de prueba\nx <- rnorm(150, 25, 3) # Recuerdan el orden de rnorm\nhist(x)\n\n\n\nmean(x)\n\n[1] 25.0514\n\n# intervalo deconfianza al 95%\nIntervConf(x)\n\n0.95 Confidence Interval =  24.63201 to  25.47079 \n\n# intervalo deconfianza al 99%\nIntervConf(x, alpha = 0.01)\n\n0.99 Confidence Interval =  24.45553 to  25.64727 \n\n\nNivel de confianza (alpha): Probabilidad que el intervalo de confianza contenga al parámetro de población\n\nEj., 95% de nivel de confianza\n\\alpha = 0.05; 1/20 veces de estar equivocado (Error tipo I)"
  },
  {
    "objectID": "correlaciones.html",
    "href": "correlaciones.html",
    "title": "5  Correlaciones",
    "section": "",
    "text": "https://es.wikipedia.org/wiki/Coeficiente_de_correlación_de_Pearson↩︎\nhttps://es.wikipedia.org/wiki/Coeficiente_de_correlación_de_Spearman↩︎\nhttps://es.wikipedia.org/wiki/Coeficiente_de_correlación_de_rango_de_Kendall↩︎"
  },
  {
    "objectID": "regresiones.html",
    "href": "regresiones.html",
    "title": "6  Regresiones",
    "section": "",
    "text": "Modelo estadístico que relaciona funcionalmente dos variables de forma lineal (una recta o, en su versión generalizada, un plano o un hiperplano). El caso más simple contiene una variable respuesta (Y; i.e. lo que se quiere explicar o predecir), y una variable explicativa o predictor (X; i.e., variables que se usan para explicar o predecir Y). A veces estas variables también son llamadas dependiente e independiente.\ny=b_0+b_1*x_1\nQue exista una relación funcional significativa entre ambas variables no implica una causalidad, pero la puede sugerir.\n\n\n\nDescripción de conceptos de la formula de regresión lineal\n\n\nCreación de una función predictiva específica para el problema planteado, con los datos usados\n\n\n\nEjemplo de Regresión Lineal Simple estima el Salario respecto a la experiencia\n\n\nModelo estadístico que relaciona funcionalmente dos variables de forma lineal (una recta o, en su versión generalizada, un plano o un hiperplano). El caso más simple contiene una variable respuesta (Y; i.e. lo que se quiere explicar o predecir), y una variable explicativa o predictor (X; i.e., variables que se usan para explicar o predecir Y). A veces estas variables también son llamadas dependiente e independiente.\nQue exista una relación funcional significativa entre ambas variables no implica una causalidad, pero la puede sugerir."
  },
  {
    "objectID": "regresiones.html#regresión-lineal-múltiple",
    "href": "regresiones.html#regresión-lineal-múltiple",
    "title": "6  Regresiones",
    "section": "6.2 Regresión lineal múltiple",
    "text": "6.2 Regresión lineal múltiple\ny = b0 + b1*x1 + b2*x2 + b3*x3 + … + bn*xn\n\nLos coeficientes representan el cambio medio en la variable de respuesta para una unidad de cambio en la variable de predicción, manteniendo constantes los demás predictores del modelo. Ej:\nContaminación aire = 0 + 0.8*#Habitantes + 0.4*#Autos\nEl coeficiente indica que por cada habitante que se agregue al sistema hay un aumento de 0.8 (unidad) de contaminación; si se aumenta un auto hay un aumento de 0.5 (unidad) de contaminación, etc.\nSe puede entender también como la importancia de las variables en el modelo\n  ### Métricas de Ajustes de los modelos\nLas métricas de regresiones buscan ver cuán parecido, cuanto error, o cuanto sesgo tienen los valores observados versus los predichos por el modelo. Las métricas más comunes son:\n\nError cuadrático medio (mean square error; MSE)\nRaíz del error cuadrático medio (root mean square error; RMSE)\nRaíz del error cuadrático medio normalizada (normalized root mean square error; nRMSE)\nCoeficiente de determinación (coefficient of determination; R2)\nSesgo (bias)\n\nError cuadrático medio (MSE): Mide el error o distancia media entre los valores predichos y los observados. O entre los puntos y la recta ajustada del modelo (líneas rojas en el ejemplo de abajo). Valores más bajos son deseables.\n\nMSE <- mean((Obs-Pred)^2)\n\nagregar formulas\nRaíz de MSE (RMSE): Es la raíz cuadrada de MSE. La ventaja de RMSE sobre MSE, es que presenta valores de error en la unidad de medida de la variable observada. Por esta razón es una de las métricas más utilizadas.\n\nRMSE <- sqrt(MSE)\n\nagregar formulas\nRaíz de MSE normalizada (nRMSE): Es el RMSE pero normalizado por las observaciones de la variable respuesta. Esta normalización se puede hacer utilizando la media o el rango de las observaciones. La ventaja es que el error es presentado en porcentaje (0-1 o 0-100), con lo cual es mejor para comparar modelos que utilizan distintas variables o set de datos.\n\nNRMSE <- RMSE/max(Obs)-min(Obs)\n\nagregar formulas\n\n\n\nMétricas del error"
  },
  {
    "objectID": "regresiones.html#coeficiente-de-determinación-r2",
    "href": "regresiones.html#coeficiente-de-determinación-r2",
    "title": "6  Regresiones",
    "section": "6.3 Coeficiente de determinación (R^2)",
    "text": "6.3 Coeficiente de determinación (R^2)\nEl coeficiente de determinación (o el cuadrado de la correlación de Pearson) es una de las métricas más utilizadas. Si bien esta es muy útil, pueden haber ocasiones donde valores altos de R² se obtienen cuando la dispersión o error de las predicciones es alta. Los valores van entre 0 y 1. Es una medida de ajuste relativa (porcentual), por lo que puede ser usada para comparar modelos entre sí.\nAgregar formula\n\nT = número de observaciones,\nYt = variables observadas,\nŶt = variables predichas por el modelo,\nY = es la media de las variables observadas."
  },
  {
    "objectID": "regresiones.html#sesgo",
    "href": "regresiones.html#sesgo",
    "title": "6  Regresiones",
    "section": "6.4 Sesgo",
    "text": "6.4 Sesgo\nEl sesgo indica si hay una distribución sistemática de los errores del modelo. Mientras más cercano a cero, menos sesgo (errores aleatorios), mientras más grande, ya sea positivo o negativo, indica que hay errores no aleatorios.\n\nValores negativos: el modelo tiende a subestimar valores de Y\nValores positivos: el modelo tiende a sobrestimar valores de Y\n\nHay muchas formas de estimar el sesgo, no es una fórmula específica\n\n\n\nAnálisis visual de los Sesgos"
  },
  {
    "objectID": "regresiones.html#residuos",
    "href": "regresiones.html#residuos",
    "title": "6  Regresiones",
    "section": "6.5 Residuos",
    "text": "6.5 Residuos\nLos residuos son la diferencia entre los valores observados y los predichos (obs - pred). Los residuos se utilizan mucho en post-hoc tests (o tests para analizar los resultados de los modelos). Los residuos, por un lado, dan estimaciones de posibles sesgos del modelo.\nEs muy importante que los residuos se distribuyan de manera aleatoria en el modelo.\n\nUn modelo con errores altos (ej., RMSE) y sesgos y residuos bajos puede ser considerado bueno bajo algunas circunstancias, ya que sus errores son independientes, y se distribuyen de forma aleatoria.\nUn modelo con ajuste alto (R2) y error bajo (RMSE) pero con sesgos muy altos debe ser descartado ya que comete errores sistemáticos.\n\n\n\n\nVisualización de los residuos\n\n\n\n\n\nTipos de los residuos\n\n\nOutput Modelo de Regresión\n\n\n\nOutput de modelos de regesión"
  },
  {
    "objectID": "regresiones.html#distribución-f-de-fisher",
    "href": "regresiones.html#distribución-f-de-fisher",
    "title": "6  Regresiones",
    "section": "6.6 Distribución F de Fisher",
    "text": "6.6 Distribución F de Fisher\nComparar si hay diferencias significativas entre dos varianzas. En caso de las regresiones proporciona esencialmente una medida de la cantidad de variación que explica el modelo frente a la cantidad de variación no explicada (por grados de libertad restantes).\n\nH0: El modelo NO explica la varianza de los datos Y\nH1: El modelo SI explica la varianza de los datos Y\n\nValores de F altos significa que su modelo explica mucho más de la variación por parámetro que el error por grado de libertad restante. No es sumamente importante este valor por ahora!\nP-valor: probabilidad de que el la H0 sea verdad. P-valores significativos, ej., bajo alpha = 0.05, lleva a interpretar la probabilidad de que el modelo de regresión no explique una porción significativa de la varianza de Y es baja.\nSe pueden comparar dos modelos lineales para ver cual es mejor utilizando un análisis de varianza (ANOVA) y el criterio Akaike.\nANOVA: Análisis de varianza para ver si hay si hay diferencia entre la varianza explicada de los dos modelos (F de Fisher).\n\n# Ej., \nlm1 <- lm(y~x1)\nlm2 <- lm(y~x1+x2+x3)\nanova(lm1, lm2)\n\nConcepto de Parsimonia implica:\n\nMientras más simple, mejor.\nLinear es mejor que no-lineal\nParamétrico es mejor que no-paramétrico\n\nExisten otras formas de comparar tros modelos lineales"
  },
  {
    "objectID": "regresiones.html#akaikes-information-criteria-aic",
    "href": "regresiones.html#akaikes-information-criteria-aic",
    "title": "6  Regresiones",
    "section": "6.7 Akaike’s information criteria (AIC):",
    "text": "6.7 Akaike’s information criteria (AIC):\nAIC busca un balance entre la capacidad predictiva de un modelo (la varianza explicada) y la cantidad de parámetros que este debe considerar para lograr un mejor ajuste.\nEs decir, premia a los modelos a medida que aumentan la varianza explicada, pero simultáneamente los penaliza a medida que aumentan el número de parámetros.\nEl criterio de Akaike es de parsimonia, el mejor ajuste con el menor número de parámetros posibles.\nLos valores más bajos de AIC son preferibles. El valor en sí mismo no tiene mucha importancia, ya que depende del caso de estudio en particular, los datos particulares, etc.\n\nAIC(lm1, lm2)"
  },
  {
    "objectID": "regresiones.html#casos-aplicado",
    "href": "regresiones.html#casos-aplicado",
    "title": "6  Regresiones",
    "section": "6.8 Casos Aplicado",
    "text": "6.8 Casos Aplicado\n\n6.8.1 Lectura de Datos\n\ndata <- read.table('data/Pantanillos.txt', header = T)\n\n\n\n\n\n \n  \n    XUTM \n    YUTM \n    LAT \n    LONG \n    BIOMAS \n    TM1 \n    TM2 \n    TM3 \n    TM4 \n    TM5 \n    TM7 \n    BRIGHT \n    GREEN \n    MOIST \n    NDVI \n    NDVIC \n    PEND \n    ALT \n    H \n  \n \n\n  \n    744797.3 \n    6071183 \n    -35.473 \n    -72.302 \n    164.649 \n    43 \n    29 \n    23 \n    57 \n    26 \n    15 \n    83.854 \n    -0.004 \n    -4.548 \n    0.425 \n    0.321 \n    6.546 \n    472.423 \n    17.106 \n  \n  \n    745007.3 \n    6071183 \n    -35.473 \n    -72.300 \n    88.663 \n    48 \n    36 \n    37 \n    66 \n    53 \n    32 \n    109.035 \n    -9.390 \n    -29.607 \n    0.282 \n    0.141 \n    17.793 \n    491.138 \n    2.838 \n  \n  \n    744587.3 \n    6071243 \n    -35.472 \n    -72.304 \n    127.707 \n    42 \n    31 \n    22 \n    54 \n    29 \n    17 \n    82.817 \n    -2.611 \n    -8.038 \n    0.421 \n    0.306 \n    10.933 \n    466.259 \n    9.288 \n  \n  \n    744797.3 \n    6071363 \n    -35.471 \n    -72.302 \n    203.209 \n    43 \n    29 \n    23 \n    62 \n    28 \n    15 \n    87.794 \n    3.431 \n    -5.745 \n    0.459 \n    0.338 \n    15.306 \n    497.456 \n    13.273 \n  \n  \n    745007.3 \n    6071363 \n    -35.471 \n    -72.300 \n    101.979 \n    43 \n    33 \n    24 \n    84 \n    40 \n    20 \n    108.640 \n    15.278 \n    -15.202 \n    0.556 \n    0.347 \n    28.135 \n    471.417 \n    12.141 \n  \n  \n    744587.3 \n    6071423 \n    -35.471 \n    -72.304 \n    185.372 \n    44 \n    29 \n    22 \n    53 \n    27 \n    16 \n    81.422 \n    -2.956 \n    -5.942 \n    0.413 \n    0.308 \n    18.362 \n    484.353 \n    9.874 \n  \n\n\n\n\n\n\n6.8.1.1 Revisión espacial de los datos\n\ndata_sf <-  data %>%  sf::st_as_sf(coords = c(\"LONG\", \"LAT\"), crs = 4326)\nmapview::mapview(data_sf, zcol=\"BIOMAS\")\n\n\n\n\n\n\nDefinición de Variables Dependiente e Independiente\n\nX <- data[ ,6:19]\nY <- data$BIOMAS\n\n\n\n\n6.8.2 Correlaciones\nVamos a seleccionar una variable X por mientras para ver una regresion simple podemos usar una simple correlacion para ver que predictor se relaciona mas con la biomasa.\n\ncor(X, Y, method = \"pearson\")\n\n              [,1]\nTM1    -0.31361610\nTM2    -0.36579661\nTM3    -0.27179254\nTM4    -0.46393079\nTM5    -0.35940473\nTM7    -0.29321630\nBRIGHT -0.46834630\nGREEN   0.06247448\nMOIST   0.32239600\nNDVI    0.11752383\nNDVIC   0.27767911\nPEND    0.10787286\nALT     0.06590560\nH       0.60544860\n\n# cor(X)\n\nVisualización de las correlaciones\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\ncorr <- cor(data[,5:19])\ncorrplot(corr, type='upper', method = \"square\")\n\n\n\n\n\n\n\n\n\n6.8.3 Regresión Lineal Simple\nCálculo de la Regresión Lineal\n\nlm1 <- lm(BIOMAS ~ H, data = data)\n# lm1 <- lm(Y ~ X$H)lm1 <- lm(Y ~ X$H)\n\nExplorar los resultados del Modelo\n\nsummary(lm1)\n\n\nCall:\nlm(formula = BIOMAS ~ H, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-171.840  -28.994   -9.999   31.554  202.631 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   29.215      8.057   3.626 0.000479 ***\nH              7.464      1.040   7.177 2.05e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.1 on 89 degrees of freedom\nMultiple R-squared:  0.3666,    Adjusted R-squared:  0.3595 \nF-statistic:  51.5 on 1 and 89 DF,  p-value: 2.05e-10\n\n\nReferecias para explicar los modelos en R: (“Explaining the Lm() Summary in R – Learn by Marketing” n.d.)\n\nplot_summs(lm1)\n\nRegistered S3 methods overwritten by 'broom':\n  method            from  \n  tidy.glht         jtools\n  tidy.summary.glht jtools\n\n\nLoading required namespace: broom.mixed\n\n\n\n\neffect_plot(lm1, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\nAtributos del Modelo\n\nfitted(lm1)resid(lm1)coef(lm1)confint(lm1)vcov(lm1)rstandard(lm1)anova(lm1)\n\n\nValores ajustados, equivale a lm1$fitted.values\n\nfitted(lm1)\n\n        1         2         3         4         5         6         7         8 \n156.88779  50.39718  98.53738 128.27982 119.83103 102.91105  63.93614  60.08493 \n        9        10        11        12        13        14        15        16 \n104.23211  83.30418  80.89344  54.32303  70.15332  37.13436  34.45493  56.01727 \n       17        18        19        20        21        22        23        24 \n 49.04627  72.52675  79.38579  95.52209  63.70477  65.24974  71.24301  61.44330 \n       25        26        27        28        29        30        31        32 \n 30.57386  50.92709  51.64360  54.36035  62.19713  36.11185  34.67884  52.58401 \n       33        34        35        36        37        38        39        40 \n 64.34664  35.39534  34.87289  38.82860  58.77133  39.32120  69.58609  78.97529 \n       41        42        43        44        45        46        47        48 \n 35.09680 122.92842  57.30101 137.13911 150.32729  63.81673 141.55010 168.30710 \n       49        50        51        52        53        54        55        56 \n131.89967 108.71773  63.40623  99.51512 137.28839 125.94372 106.60553  32.98460 \n       57        58        59        60        61        62        63        64 \n 41.46325  96.23860  71.73560  29.21549 138.07953  98.91056 150.52135 114.18109 \n       65        66        67        68        69        70        71        72 \n 31.43964  30.87240  62.61509  30.00663  37.47022  35.17144 212.56624 125.07048 \n       73        74        75        76        77        78        79        80 \n 90.35728  29.36476  51.68092  30.38727  31.89492  34.56689  35.62672  36.07453 \n       81        82        83        84        85        86        87        88 \n 46.14293  68.04112  65.66770  57.03232  48.13571  33.66379  49.76277  36.90299 \n       89        90        91 \n 36.38054  50.88977  53.68116 \n\n\n\n\nresiduos, equivale a lm1$residuals\n\nresid(lm1)      \n\n          1           2           3           4           5           6 \n   7.761206   38.265823   29.169615   74.929177  -17.852030   82.460947 \n          7           8           9          10          11          12 \n  58.796856   33.938073  -38.262110  -20.012181   38.520561    9.144971 \n         13          14          15          16          17          18 \n  11.074679   65.181637  -23.405931  -27.581266  -15.812266   58.633255 \n         19          20          21          22          23          24 \n -39.960792  -31.718091  -55.358772    2.211263  -62.109006  -12.198302 \n         25          26          27          28          29          30 \n -25.504860  -44.329092  -38.534598  -44.839347  -23.402125  -26.973850 \n         31          32          33          34          35          36 \n -28.195839   15.671989   39.747358  -32.397345  -31.874893  -23.883600 \n         37          38          39          40          41          42 \n -50.244334  -32.176197  -39.591088    8.008706  -31.092801   71.049577 \n         43          44          45          46          47          48 \n -27.682005  107.308886   55.306708    2.781274   60.096900  -94.215100 \n         49          50          51          52          53          54 \n   5.693332    4.259268    6.460772  -55.793116  -70.469386  202.631283 \n         55          56          57          58          59          60 \n  53.788466  -28.104602  -30.344250  -18.301596  -20.163604   -7.307485 \n         61          62          63          64          65          66 \n -16.941527  -92.306564   -5.982345   -7.136086  -14.867638   -7.617404 \n         67          68          69          70          71          72 \n  24.145913   37.936373   38.423775   11.302563 -171.840236   66.782524 \n         73          74          75          76          77          78 \n  49.858719   39.476243   -6.461916  -18.468270  -19.300917  152.183115 \n         79          80          81          82          83          84 \n  91.183284   66.780468   -9.998926  -26.560123  -37.237699  -19.908316 \n         85          86          87          88          89          90 \n -35.780707  -23.507790   -8.175771  -29.791991   -7.118540    8.905226 \n         91 \n  -1.176160 \n\n\n\n\ncoeficientes, equivale a lm1$coefficients\n\ncoef(lm1)       \n\n(Intercept)           H \n  29.215485    7.463598 \n\n\n\n\nintervalos de confianza para dichos coeficientes\n\nconfint(lm1)    \n\n                2.5 %    97.5 %\n(Intercept) 13.206435 45.224535\nH            5.397175  9.530021\n\n\n\n\ntabla de varianza-covarianza\n\nvcov(lm1)       \n\n            (Intercept)         H\n(Intercept)   64.914946 -6.160668\nH             -6.160668  1.081563\n\n\n\n\nresiduos estandarizados (dist. z)\n\nrstandard(lm1)  \n\n          1           2           3           4           5           6 \n 0.15389729  0.73982298  0.56449928  1.46330265 -0.34749910  1.59728295 \n          7           8           9          10          11          12 \n 1.13514238  0.65539190 -0.74137098 -0.38646113  0.74374731  0.17670935 \n         13          14          15          16          17          18 \n 0.21376464  1.26361310 -0.45406718 -0.53284772 -0.30577684  1.13173782 \n         19          20          21          22          23          24 \n-0.77148418 -0.61347793 -1.06878028  0.04268813 -1.19882496 -0.23554096 \n         25          26          27          28          29          30 \n-0.49533686 -0.85697946 -0.74487989 -0.86643196 -0.45185478 -0.52305285 \n         31          32          33          34          35          36 \n-0.54695653  0.30290150  0.76735215 -0.62833868 -0.61829219 -0.46281511 \n         37          38          39          40          41          42 \n-0.97040227 -0.62343551 -0.76419725  0.15461288 -0.60308534  1.38458456 \n         43          44          45          46          47          48 \n-0.53471896  2.10408491  1.09220942  0.05369612  1.18099673 -1.88317274 \n         49          50          51          52          53          54 \n 0.11136024  0.08262197  0.12473664 -1.07993497 -1.38184634  3.95342959 \n         55          56          57          58          59          60 \n 1.04281942 -0.54544260 -0.58765284 -0.35402625 -0.38919655 -0.14197977 \n         61          62          63          64          65          66 \n-0.33233882 -1.78647561 -0.11815437 -0.13864696 -0.28867393 -0.14792643 \n         67          68          69          70          71          72 \n 0.46620289  0.73689953  0.74482158  0.21922355 -3.58391038  1.30250579 \n         73          74          75          76          77          78 \n 0.96357987  0.76696255 -0.12490918 -0.35869754 -0.37470162  2.95221126 \n         79          80          81          82          83          84 \n 1.76836956  1.29495988 -0.19345720 -0.51268695 -0.71885512 -0.38456953 \n         85          86          87          88          89          90 \n-0.69203146 -0.45614254 -0.15808431 -0.57758225 -0.13802677  0.17215869 \n         91 \n-0.02272895 \n\n\n\n\nsignificancia de la influencia de las variables\n\nanova(lm1)    \n\nAnalysis of Variance Table\n\nResponse: BIOMAS\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nH          1 139779  139779  51.504 2.05e-10 ***\nResiduals 89 241539    2714                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "regresiones.html#modelo-de-regresion-multiple",
    "href": "regresiones.html#modelo-de-regresion-multiple",
    "title": "6  Regresiones",
    "section": "6.9 Modelo de Regresion Multiple",
    "text": "6.9 Modelo de Regresion Multiple\nCálculo de la Regresión Lineal Multiple\n\nlm2 <- lm(BIOMAS ~ H + TM2 + TM5, data = data)\nsummary(lm2)\n\n\nCall:\nlm(formula = BIOMAS ~ H + TM2 + TM5, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-162.26  -31.35  -11.10   28.64  200.80 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 75.50158   68.04392   1.110    0.270    \nH            6.89284    1.19982   5.745 1.33e-07 ***\nTM2         -1.25048    3.03877  -0.412    0.682    \nTM5          0.01689    1.04880   0.016    0.987    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.39 on 87 degrees of freedom\nMultiple R-squared:  0.3737,    Adjusted R-squared:  0.3521 \nF-statistic:  17.3 on 3 and 87 DF,  p-value: 6.754e-09\n\n\n\nplot_summs(lm2, robust = TRUE, plot.distributions = TRUE, inner_ci_level = .9)\n\n\n\n\nComparación de Modelos con Anova\n\nanova(lm1, lm2)\n\nAnalysis of Variance Table\n\nModel 1: BIOMAS ~ H\nModel 2: BIOMAS ~ H + TM2 + TM5\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     89 241539                           \n2     87 238818  2    2721.2 0.4957 0.6109\n\n\nEl p-value del estadistico F es alto (Pr(>F) = 0.6109; mayor a 0.05), es decir, hay una probabilidad muy baja de que lm2 agregue algo a la varianza explicada, por lo que se podria decir que las variables TM2 y TM5 no agregan mas informacion Por lo tanto, el modelo lm1 seria el mejor en este caso por el principio de la parsimonia si dos modelos son iguales estadisticamente, el mas sensillo es mejor.\nComparación de Modelos con Akaike\nOtro criterio para seleccionar modelo es el AIC o Akaike Information Criterion. El AIC busca un balance entre la capacidad predictiva de un modelo (la varianza explicada) y la cantidad de parametros que este debe considerar para lograr un mejor ajuste. Es decir, premia a los modelos a medida que aumentan la varianza explicada, pero simultaneamente los penaliza a medida que aumentan el numero de parametros. El criterio de Akaike es de parsimonia, el mejor ajuste con el menor numero de parametros posibles. Los valores mas bajos de AIC son preferibles.\n\nAIC(lm1, lm2)\n\n    df      AIC\nlm1  3 981.6841\nlm2  5 984.6531\n\n\nAIC concuerda que lm1 es mejor en este caso\n\n\n\n\n“Explaining the Lm() Summary in R – Learn by Marketing.” n.d. Accessed September 2, 2022. https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/."
  },
  {
    "objectID": "val_models.html",
    "href": "val_models.html",
    "title": "7  Validación de Modelos",
    "section": "",
    "text": "Lectura de Datos\n\ndata <- read.table('data/Pantanillos.txt', header = T, sep = '')\n\n\n\n\n\n \n  \n    XUTM \n    YUTM \n    LAT \n    LONG \n    BIOMAS \n    TM1 \n    TM2 \n    TM3 \n    TM4 \n    TM5 \n    TM7 \n    BRIGHT \n    GREEN \n    MOIST \n    NDVI \n    NDVIC \n    PEND \n    ALT \n    H \n  \n \n\n  \n    744797.3 \n    6071183 \n    -35.473 \n    -72.302 \n    164.649 \n    43 \n    29 \n    23 \n    57 \n    26 \n    15 \n    83.854 \n    -0.004 \n    -4.548 \n    0.425 \n    0.321 \n    6.546 \n    472.423 \n    17.106 \n  \n  \n    745007.3 \n    6071183 \n    -35.473 \n    -72.300 \n    88.663 \n    48 \n    36 \n    37 \n    66 \n    53 \n    32 \n    109.035 \n    -9.390 \n    -29.607 \n    0.282 \n    0.141 \n    17.793 \n    491.138 \n    2.838 \n  \n  \n    744587.3 \n    6071243 \n    -35.472 \n    -72.304 \n    127.707 \n    42 \n    31 \n    22 \n    54 \n    29 \n    17 \n    82.817 \n    -2.611 \n    -8.038 \n    0.421 \n    0.306 \n    10.933 \n    466.259 \n    9.288 \n  \n  \n    744797.3 \n    6071363 \n    -35.471 \n    -72.302 \n    203.209 \n    43 \n    29 \n    23 \n    62 \n    28 \n    15 \n    87.794 \n    3.431 \n    -5.745 \n    0.459 \n    0.338 \n    15.306 \n    497.456 \n    13.273 \n  \n  \n    745007.3 \n    6071363 \n    -35.471 \n    -72.300 \n    101.979 \n    43 \n    33 \n    24 \n    84 \n    40 \n    20 \n    108.640 \n    15.278 \n    -15.202 \n    0.556 \n    0.347 \n    28.135 \n    471.417 \n    12.141 \n  \n  \n    744587.3 \n    6071423 \n    -35.471 \n    -72.304 \n    185.372 \n    44 \n    29 \n    22 \n    53 \n    27 \n    16 \n    81.422 \n    -2.956 \n    -5.942 \n    0.413 \n    0.308 \n    18.362 \n    484.353 \n    9.874 \n  \n\n\n\n\n\nFiltrar los datos\n\ndata2 <- data[,-c(1:4)]\n\n\n\n\n\n \n  \n    BIOMAS \n    TM1 \n    TM2 \n    TM3 \n    TM4 \n    TM5 \n    TM7 \n    BRIGHT \n    GREEN \n    MOIST \n    NDVI \n    NDVIC \n    PEND \n    ALT \n    H \n  \n \n\n  \n    164.649 \n    43 \n    29 \n    23 \n    57 \n    26 \n    15 \n    83.854 \n    -0.004 \n    -4.548 \n    0.425 \n    0.321 \n    6.546 \n    472.423 \n    17.106 \n  \n  \n    88.663 \n    48 \n    36 \n    37 \n    66 \n    53 \n    32 \n    109.035 \n    -9.390 \n    -29.607 \n    0.282 \n    0.141 \n    17.793 \n    491.138 \n    2.838 \n  \n  \n    127.707 \n    42 \n    31 \n    22 \n    54 \n    29 \n    17 \n    82.817 \n    -2.611 \n    -8.038 \n    0.421 \n    0.306 \n    10.933 \n    466.259 \n    9.288 \n  \n  \n    203.209 \n    43 \n    29 \n    23 \n    62 \n    28 \n    15 \n    87.794 \n    3.431 \n    -5.745 \n    0.459 \n    0.338 \n    15.306 \n    497.456 \n    13.273 \n  \n  \n    101.979 \n    43 \n    33 \n    24 \n    84 \n    40 \n    20 \n    108.640 \n    15.278 \n    -15.202 \n    0.556 \n    0.347 \n    28.135 \n    471.417 \n    12.141 \n  \n  \n    185.372 \n    44 \n    29 \n    22 \n    53 \n    27 \n    16 \n    81.422 \n    -2.956 \n    -5.942 \n    0.413 \n    0.308 \n    18.362 \n    484.353 \n    9.874 \n  \n\n\n\n\n\nHistograma de variable respuesta\n\n# histograma de variable respuesta\nhist(data$BIOMAS)"
  },
  {
    "objectID": "val_models.html#definición-de-funciones",
    "href": "val_models.html#definición-de-funciones",
    "title": "7  Validación de Modelos",
    "section": "7.2 Definición de Funciones",
    "text": "7.2 Definición de Funciones\nFunción para scatterplot\n\n# funcion para scatterplot\nplot_prediction <- function(obs, pred, main=''){\n  x <- cbind(obs, pred)\n  plot(x, xlab = 'Biomasa observada [kg m-2]', ylab = 'Biomasa predicha [kg m-2]', pch=16, las=1,\n       xlim = c(min(x), max(x)), ylim = c(min(x), max(x)), main=main, col=rgb(0,0,0,0.2), cex=1.5)\n  abline(0,1, lty=2)\n  lm <- lm(pred ~ obs-1)\n  abline(lm)\n  legend('topleft', legend=c('Linea 1:1', 'Linea ajustada'), lty=c(1,2), bty = 'n')\n  # agregar metricas de ajuste de modelo\n  r2 <- round( (cor(pred, obs)^2), 2) # solo dos decimales con funcion round\n  NRMSE <- round((sqrt(mean((obs - pred)^2))/(max(obs) - min(obs))) * 100, 2) # RMSE normalizado\n  bias = round( (1-coef(lm))*-1, 2)\n  mtext(bquote(paste(r^2 == .(r2), \",\", \" %RMSE\" == .(NRMSE), \"%\", \",\", \" bias\" ==\n                       .(bias))), side = 3, line = 0.5, adj = 0, font = 2)\n  \n}\n\nVisualización de Residuos\n\nplot_residuos <- function(res, pred, main='Modelo'){\n  par(mfrow=c(1,2))\n  plot(pred, res, xlab = 'Biomasa predicha [kg m-2]', ylab = 'Residuos [kg m-2]', pch=16, las=1,\n       main=main, col=rgb(0,0,0,0.2), cex=1.5)\n  abline(h=0, lty=2)\n  qqnorm(res)\n  qqline(res, lty=2)\n}"
  },
  {
    "objectID": "val_models.html#analisis",
    "href": "val_models.html#analisis",
    "title": "7  Validación de Modelos",
    "section": "7.3 Analisis",
    "text": "7.3 Analisis\n\n7.3.1 Análisis de Significancia de Corrección\n\ncorr <- cor(data2)\ntestRes = cor.mtest(data2, conf.level = 0.95) # matriz con valores de p\npar(mfrow=c(1,1))\ncorrplot(corr, p.mat = testRes$p, type = 'lower', diag = FALSE) # X a las no sign. con p > 0.05\n\n\n\ncor(data2) # mejor variable segun cor es one_mean\n\n            BIOMAS         TM1        TM2         TM3         TM4        TM5\nBIOMAS  1.00000000 -0.31361610 -0.3657966 -0.27179254 -0.46393079 -0.3594047\nTM1    -0.31361610  1.00000000  0.9620088  0.95921101  0.09765849  0.9063002\nTM2    -0.36579661  0.96200881  1.0000000  0.96123400  0.22164639  0.9364134\nTM3    -0.27179254  0.95921101  0.9612340  1.00000000  0.04443123  0.9426152\nTM4    -0.46393079  0.09765849  0.2216464  0.04443123  1.00000000  0.1900475\nTM5    -0.35940473  0.90630018  0.9364134  0.94261521  0.19004752  1.0000000\nTM7    -0.29321630  0.92326124  0.9328171  0.96913153  0.04712320  0.9762178\nBRIGHT -0.46834630  0.87680231  0.9366557  0.87721991  0.50462364  0.9265610\nGREEN   0.06247448 -0.84581862 -0.7924929 -0.89542924  0.39613113 -0.7977948\nMOIST   0.32239600 -0.89367594 -0.9159402 -0.94344351 -0.10547874 -0.9939164\nNDVI    0.11752383 -0.87593057 -0.8298394 -0.93068575  0.31098157 -0.8262571\nNDVIC   0.27767911 -0.91453558 -0.8983385 -0.95949090  0.08793446 -0.9193543\nPEND    0.10787286 -0.29088550 -0.2667467 -0.30306962  0.05054119 -0.1913806\nALT     0.06590560 -0.34638456 -0.2674291 -0.30541545  0.01988928 -0.2707978\nH       0.60544860 -0.47942172 -0.4819355 -0.43697984 -0.31427651 -0.4823196\n              TM7     BRIGHT       GREEN      MOIST       NDVI       NDVIC\nBIOMAS -0.2932163 -0.4683463  0.06247448  0.3223960  0.1175238  0.27767911\nTM1     0.9232612  0.8768023 -0.84581862 -0.8936759 -0.8759306 -0.91453558\nTM2     0.9328171  0.9366557 -0.79249292 -0.9159402 -0.8298394 -0.89833845\nTM3     0.9691315  0.8772199 -0.89542924 -0.9434435 -0.9306857 -0.95949090\nTM4     0.0471232  0.5046236  0.39613113 -0.1054787  0.3109816  0.08793446\nTM5     0.9762178  0.9265610 -0.79779485 -0.9939164 -0.8262571 -0.91935429\nTM7     1.0000000  0.8752779 -0.88290983 -0.9885743 -0.8979835 -0.94375520\nBRIGHT  0.8752779  1.0000000 -0.59146405 -0.8891844 -0.6518289 -0.79086476\nGREEN  -0.8829098 -0.5914641  1.00000000  0.8369327  0.9869514  0.92129745\nMOIST  -0.9885743 -0.8891844  0.83693272  1.0000000  0.8556265  0.92978569\nNDVI   -0.8979835 -0.6518289  0.98695136  0.8556265  1.0000000  0.95917534\nNDVIC  -0.9437552 -0.7908648  0.92129745  0.9297857  0.9591753  1.00000000\nPEND   -0.2282007 -0.2052176  0.27841863  0.1905210  0.3166394  0.28910470\nALT    -0.2832766 -0.2524166  0.28856127  0.2690036  0.3035372  0.30633676\nH      -0.4304685 -0.5347813  0.27232831  0.4517838  0.3362205  0.46368280\n              PEND         ALT           H\nBIOMAS  0.10787286  0.06590560  0.60544860\nTM1    -0.29088550 -0.34638456 -0.47942172\nTM2    -0.26674670 -0.26742907 -0.48193548\nTM3    -0.30306962 -0.30541545 -0.43697984\nTM4     0.05054119  0.01988928 -0.31427651\nTM5    -0.19138064 -0.27079776 -0.48231958\nTM7    -0.22820067 -0.28327655 -0.43046847\nBRIGHT -0.20521762 -0.25241661 -0.53478130\nGREEN   0.27841863  0.28856127  0.27232831\nMOIST   0.19052104  0.26900363  0.45178385\nNDVI    0.31663942  0.30353719  0.33622053\nNDVIC   0.28910470  0.30633676  0.46368280\nPEND    1.00000000  0.19853031  0.38709465\nALT     0.19853031  1.00000000  0.07529796\nH       0.38709465  0.07529796  1.00000000\n\n#corr\n\n\n\n7.3.2 Validación Cruzada\n\n# separar en set de validacion y entrenamiento: Validacion cruzada simple!\nset.seed(1234)\nidx <- createDataPartition(data2$BIOMAS, p = 0.6, list = F)\nlength(idx)\n\n[1] 56\n\nidx %>% head()\n\n     Resample1\n[1,]         1\n[2,]         5\n[3,]         8\n[4,]         9\n[5,]        11\n[6,]        12\n\n# 91*0.6 --> 54.6\n\n# particionar los datos usando los datos generados\nentrenar <- data2[idx,  ] # 60% de los datos \nvalidar  <- data2[-idx, ] # 40% de los datos"
  },
  {
    "objectID": "val_models.html#regresiones",
    "href": "val_models.html#regresiones",
    "title": "7  Validación de Modelos",
    "section": "7.4 Regresiones",
    "text": "7.4 Regresiones\n\n7.4.1 Regresiones Simples\n\nlm1 <- lm(BIOMAS ~ H, data = entrenar)\nsummary(lm1)\n\n\nCall:\nlm(formula = BIOMAS ~ H, data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-161.91  -31.59  -12.85   18.43  206.26 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   32.623     11.265   2.896  0.00545 ** \nH              6.921      1.430   4.840 1.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.64 on 54 degrees of freedom\nMultiple R-squared:  0.3026,    Adjusted R-squared:  0.2897 \nF-statistic: 23.43 on 1 and 54 DF,  p-value: 1.125e-05\n\n\nReferecias para explicar los modelos en R: (“Explaining the Lm() Summary in R – Learn by Marketing” n.d.)\n\neffect_plot(lm1, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\nlm2 <- glm(BIOMAS ~ H, data = entrenar, family = Gamma(link = \"log\"))\nsummary(lm2)\n\n\nCall:\nglm(formula = BIOMAS ~ H, family = Gamma(link = \"log\"), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.8159  -0.8806  -0.1909   0.3185   2.1156  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.58884    0.17418  20.605  < 2e-16 ***\nH            0.09849    0.02211   4.456 4.25e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.7669877)\n\n    Null deviance: 58.130  on 55  degrees of freedom\nResidual deviance: 43.909  on 54  degrees of freedom\nAIC: 580.9\n\nNumber of Fisher Scoring iterations: 7\n\neffect_plot(lm2, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\n\n7.4.2 Regresión Multiple\n\n## Regression multiple con todas las variables -----------------------------\nlm3 <- lm(BIOMAS ~., data = entrenar)\nsummary(lm3)\n\n\nCall:\nlm(formula = BIOMAS ~ ., data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-100.67  -31.30   -8.14   21.58  182.80 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)\n(Intercept)  4.993e+02  5.815e+02   0.859    0.395\nTM1          9.320e+00  2.906e+01   0.321    0.750\nTM2          1.533e+01  2.822e+01   0.543    0.590\nTM3          1.866e+01  3.699e+01   0.504    0.617\nTM4         -4.582e+00  3.919e+01  -0.117    0.908\nTM5         -1.410e+00  3.274e+01  -0.043    0.966\nTM7         -3.049e+00  2.650e+01  -0.115    0.909\nBRIGHT      -1.498e+01  5.023e+01  -0.298    0.767\nGREEN        2.388e+01  4.312e+01   0.554    0.583\nMOIST       -1.232e+01  4.067e+01  -0.303    0.764\nNDVI        -1.204e+03  1.728e+03  -0.697    0.490\nNDVIC        1.213e+03  8.425e+02   1.440    0.157\nPEND        -2.048e-01  1.008e+00  -0.203    0.840\nALT          1.759e-02  1.066e-01   0.165    0.870\nH            3.802e+00  2.285e+00   1.664    0.104\n\nResidual standard error: 57.21 on 41 degrees of freedom\nMultiple R-squared:  0.4599,    Adjusted R-squared:  0.2755 \nF-statistic: 2.494 on 14 and 41 DF,  p-value: 0.01162\n\neffect_plot(lm3, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\nlm4 <- glm(BIOMAS ~., data = entrenar, family = Gamma(link = log))\nsummary(lm4)\n\n\nCall:\nglm(formula = BIOMAS ~ ., family = Gamma(link = log), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4922  -0.7954  -0.1666   0.4182   1.5964  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  11.099546   9.159715   1.212   0.2325  \nTM1           0.437576   0.457743   0.956   0.3447  \nTM2           0.384137   0.444555   0.864   0.3926  \nTM3           0.448039   0.582720   0.769   0.4464  \nTM4          -0.035895   0.617363  -0.058   0.9539  \nTM5           0.027237   0.515759   0.053   0.9581  \nTM7          -0.018001   0.417409  -0.043   0.9658  \nBRIGHT       -0.503779   0.791271  -0.637   0.5279  \nGREEN         0.627758   0.679168   0.924   0.3607  \nMOIST        -0.271592   0.640674  -0.424   0.6738  \nNDVI        -20.985287  27.223143  -0.771   0.4452  \nNDVIC        15.108460  13.270804   1.138   0.2615  \nPEND          0.001204   0.015875   0.076   0.9399  \nALT          -0.001040   0.001679  -0.619   0.5391  \nH             0.080295   0.035993   2.231   0.0312 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.8120839)\n\n    Null deviance: 58.13  on 55  degrees of freedom\nResidual deviance: 36.52  on 41  degrees of freedom\nAIC: 595.41\n\nNumber of Fisher Scoring iterations: 14\n\neffect_plot(lm4, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\n\n7.4.3 Regresión multiple con seleccion de variables stepwise\nUtilizando train() utilizanndo el método “lmStepAIC”, que va a buscar las conbinaciones de modelos lineales, simples, luego con dos, tres, etc., bajo el criterio AIC . (Kuhn n.d.)\n\nlm5 <- train(BIOMAS ~., data = entrenar, method = \"lmStepAIC\")\nlm5$finalModel\n\nEl objeto caret lm5 guarda perfectamente cual es el mejor modelo, y se puede usar directamente para predecir, etc. Pero no se lleva bein caret con las funciones anova, AIC, así que vamos a usar las mejores variables y a hacer otro modelo\n\nlm5 <- lm(BIOMAS ~ TM3 + BRIGHT + NDVIC + H, data = entrenar)\nsummary(lm5)\n\n\nCall:\nlm(formula = BIOMAS ~ TM3 + BRIGHT + NDVIC + H, data = entrenar)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-99.37 -30.51 -13.02  21.00 181.98 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  105.909    147.888   0.716  0.47717   \nTM3           10.183      4.256   2.393  0.02045 * \nBRIGHT        -4.611      1.340  -3.441  0.00116 **\nNDVIC        487.008    305.084   1.596  0.11660   \nH              3.954      1.717   2.303  0.02538 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.46 on 51 degrees of freedom\nMultiple R-squared:  0.435, Adjusted R-squared:  0.3907 \nF-statistic: 9.818 on 4 and 51 DF,  p-value: 5.74e-06\n\neffect_plot(lm5, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\nFamily: Gamma(link = log)\n\nlm6 <- train(BIOMAS ~., data = entrenar, method = \"glmStepAIC\", family = Gamma(link = log))\nlm6$finalModel\n\n\nlm6 <- glm(BIOMAS ~ TM3 + BRIGHT + H, data = entrenar, family = Gamma(link = \"log\"))\n\neffect_plot(lm6, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)"
  },
  {
    "objectID": "val_models.html#información-de-modelos",
    "href": "val_models.html#información-de-modelos",
    "title": "7  Validación de Modelos",
    "section": "7.5 Información de modelos",
    "text": "7.5 Información de modelos\n\nsummary(lm1)\n\n\nCall:\nlm(formula = BIOMAS ~ H, data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-161.91  -31.59  -12.85   18.43  206.26 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   32.623     11.265   2.896  0.00545 ** \nH              6.921      1.430   4.840 1.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.64 on 54 degrees of freedom\nMultiple R-squared:  0.3026,    Adjusted R-squared:  0.2897 \nF-statistic: 23.43 on 1 and 54 DF,  p-value: 1.125e-05\n\nsummary(lm2)\n\n\nCall:\nglm(formula = BIOMAS ~ H, family = Gamma(link = \"log\"), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.8159  -0.8806  -0.1909   0.3185   2.1156  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.58884    0.17418  20.605  < 2e-16 ***\nH            0.09849    0.02211   4.456 4.25e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.7669877)\n\n    Null deviance: 58.130  on 55  degrees of freedom\nResidual deviance: 43.909  on 54  degrees of freedom\nAIC: 580.9\n\nNumber of Fisher Scoring iterations: 7\n\nsummary(lm3)\n\n\nCall:\nlm(formula = BIOMAS ~ ., data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-100.67  -31.30   -8.14   21.58  182.80 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)\n(Intercept)  4.993e+02  5.815e+02   0.859    0.395\nTM1          9.320e+00  2.906e+01   0.321    0.750\nTM2          1.533e+01  2.822e+01   0.543    0.590\nTM3          1.866e+01  3.699e+01   0.504    0.617\nTM4         -4.582e+00  3.919e+01  -0.117    0.908\nTM5         -1.410e+00  3.274e+01  -0.043    0.966\nTM7         -3.049e+00  2.650e+01  -0.115    0.909\nBRIGHT      -1.498e+01  5.023e+01  -0.298    0.767\nGREEN        2.388e+01  4.312e+01   0.554    0.583\nMOIST       -1.232e+01  4.067e+01  -0.303    0.764\nNDVI        -1.204e+03  1.728e+03  -0.697    0.490\nNDVIC        1.213e+03  8.425e+02   1.440    0.157\nPEND        -2.048e-01  1.008e+00  -0.203    0.840\nALT          1.759e-02  1.066e-01   0.165    0.870\nH            3.802e+00  2.285e+00   1.664    0.104\n\nResidual standard error: 57.21 on 41 degrees of freedom\nMultiple R-squared:  0.4599,    Adjusted R-squared:  0.2755 \nF-statistic: 2.494 on 14 and 41 DF,  p-value: 0.01162\n\nsummary(lm4)\n\n\nCall:\nglm(formula = BIOMAS ~ ., family = Gamma(link = log), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4922  -0.7954  -0.1666   0.4182   1.5964  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  11.099546   9.159715   1.212   0.2325  \nTM1           0.437576   0.457743   0.956   0.3447  \nTM2           0.384137   0.444555   0.864   0.3926  \nTM3           0.448039   0.582720   0.769   0.4464  \nTM4          -0.035895   0.617363  -0.058   0.9539  \nTM5           0.027237   0.515759   0.053   0.9581  \nTM7          -0.018001   0.417409  -0.043   0.9658  \nBRIGHT       -0.503779   0.791271  -0.637   0.5279  \nGREEN         0.627758   0.679168   0.924   0.3607  \nMOIST        -0.271592   0.640674  -0.424   0.6738  \nNDVI        -20.985287  27.223143  -0.771   0.4452  \nNDVIC        15.108460  13.270804   1.138   0.2615  \nPEND          0.001204   0.015875   0.076   0.9399  \nALT          -0.001040   0.001679  -0.619   0.5391  \nH             0.080295   0.035993   2.231   0.0312 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.8120839)\n\n    Null deviance: 58.13  on 55  degrees of freedom\nResidual deviance: 36.52  on 41  degrees of freedom\nAIC: 595.41\n\nNumber of Fisher Scoring iterations: 14\n\nsummary(lm5)\n\n\nCall:\nlm(formula = BIOMAS ~ TM3 + BRIGHT + NDVIC + H, data = entrenar)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-99.37 -30.51 -13.02  21.00 181.98 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  105.909    147.888   0.716  0.47717   \nTM3           10.183      4.256   2.393  0.02045 * \nBRIGHT        -4.611      1.340  -3.441  0.00116 **\nNDVIC        487.008    305.084   1.596  0.11660   \nH              3.954      1.717   2.303  0.02538 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.46 on 51 degrees of freedom\nMultiple R-squared:  0.435, Adjusted R-squared:  0.3907 \nF-statistic: 9.818 on 4 and 51 DF,  p-value: 5.74e-06\n\nsummary(lm6)\n\n\nCall:\nglm(formula = BIOMAS ~ TM3 + BRIGHT + H, family = Gamma(link = \"log\"), \n    data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7612  -0.7162  -0.1862   0.3547   1.6836  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.79928    1.37938   4.929 8.82e-06 ***\nTM3          0.05952    0.02484   2.396  0.02021 *  \nBRIGHT      -0.04705    0.01781  -2.641  0.01088 *  \nH            0.07821    0.02458   3.182  0.00247 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.6614027)\n\n    Null deviance: 58.130  on 55  degrees of freedom\nResidual deviance: 39.293  on 52  degrees of freedom\nAIC: 577.95\n\nNumber of Fisher Scoring iterations: 6\n\n\nPlot de diagnostico\n\npar(mfrow=c(2,2))\nplot(lm1)\n\n\n\nplot(lm2)\n\n\n\nplot(lm3)\n\n\n\nplot(lm4)\n\n\n\nplot(lm5)\n\n\n\nplot(lm6)"
  },
  {
    "objectID": "val_models.html#validación-independientes",
    "href": "val_models.html#validación-independientes",
    "title": "7  Validación de Modelos",
    "section": "7.6 Validación Independientes",
    "text": "7.6 Validación Independientes\n\n7.6.1 Predicción\n\npred1 <- predict(lm1, validar, type = 'response')\npred2 <- predict(lm2, validar, type = 'response')\npred3 <- predict(lm3, validar, type = 'response')\npred4 <- predict(lm4, validar, type = 'response')\npred5 <- predict(lm5, validar, type = 'response')\npred6 <- predict(lm6, validar, type = 'response')\n\n\n\n7.6.2 R^2\n\npostResample(validar$BIOMAS, pred1)\n\n      RMSE   Rsquared        MAE \n44.4093971  0.4945806 36.5128797 \n\npostResample(validar$BIOMAS, pred2)\n\n      RMSE   Rsquared        MAE \n47.5393225  0.4190765 37.4912978 \n\npostResample(validar$BIOMAS, pred3)\n\n      RMSE   Rsquared        MAE \n41.9033685  0.5493197 33.2810130 \n\npostResample(validar$BIOMAS, pred4)\n\n     RMSE  Rsquared       MAE \n51.073834  0.503803 36.899949 \n\npostResample(validar$BIOMAS, pred5)\n\n      RMSE   Rsquared        MAE \n42.2525620  0.5466302 35.0206725 \n\npostResample(validar$BIOMAS, pred6)\n\n      RMSE   Rsquared        MAE \n44.5042861  0.5289186 32.5334253 \n\n\n\n\n7.6.3 Plot de valores predichos vs observados\n\npar(mfrow=c(1,2))\nplot_prediction(validar$BIOMAS, pred1, main='lm simple') # nuestra funcion\nplot_prediction(validar$BIOMAS, pred2, main='GLM simple')\n\n\n\nplot_prediction(validar$BIOMAS, pred3, main='lm todo')\nplot_prediction(validar$BIOMAS, pred4, main='GLM todo')\n\n\n\nplot_prediction(validar$BIOMAS, pred5, main='lm seleccion')\nplot_prediction(validar$BIOMAS, pred6, main='GLM deleccion')\n\n\n\n\n\n\n7.6.4 Residuos\n\nres1 <- validar$BIOMAS - pred1\nres2 <- validar$BIOMAS - pred2\nres3 <- validar$BIOMAS - pred3\nres4 <- validar$BIOMAS - pred4\nres5 <- validar$BIOMAS - pred5\nres6 <- validar$BIOMAS - pred6\n\n\n\n7.6.5 Plot de residuos\nLos observados vs los predichos\n\nplot_residuos(res1, pred1) # nuestra funcion\n\n\n\nplot_residuos(res2, pred2)\n\n\n\nplot_residuos(res3, pred3)\n\n\n\nplot_residuos(res4, pred4)\n\n\n\nplot_residuos(res5, pred5)\n\n\n\nplot_residuos(res6, pred6)\n\n\n\n\n\n\n7.6.6 Histrogramas\n\npar(mfrow=c(1,2))\nhist(res1, main = 'lm simple')\nhist(res2, main = 'GLM simple')\n\n\n\nhist(res3, main = 'lm todo')\nhist(res4, main = 'GLM todo')\n\n\n\nhist(res5, main = 'lm seleccion')\nhist(res6, main = 'GLM seleccion')\n\n\n\n\n\n\n7.6.7 Shapiro Test\n\nH0 -> dist. normal H1 -> dist. no normal\n\n\nshapiro.test(res1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res1\nW = 0.96422, p-value = 0.3049\n\nshapiro.test(res2) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res2\nW = 0.94851, p-value = 0.102\n\nshapiro.test(res3) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res3\nW = 0.97745, p-value = 0.6747\n\nshapiro.test(res4) # no normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  res4\nW = 0.90988, p-value = 0.007368\n\nshapiro.test(res5) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res5\nW = 0.97574, p-value = 0.6182\n\nshapiro.test(res6) # no normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  res6\nW = 0.92007, p-value = 0.01432\n\n\n\n\n7.6.8 Significancia de las diferencias\n\nanova(lm1,lm2,lm3,lm4,lm5, lm6) # diferencias entre gaussianos\n\nAnalysis of Variance Table\n\nModel 1: BIOMAS ~ H\nModel 2: BIOMAS ~ H\nModel 3: BIOMAS ~ TM1 + TM2 + TM3 + TM4 + TM5 + TM7 + BRIGHT + GREEN + \n    MOIST + NDVI + NDVIC + PEND + ALT + H\nModel 4: BIOMAS ~ TM1 + TM2 + TM3 + TM4 + TM5 + TM7 + BRIGHT + GREEN + \n    MOIST + NDVI + NDVIC + PEND + ALT + H\nModel 5: BIOMAS ~ TM3 + BRIGHT + NDVIC + H\nModel 6: BIOMAS ~ TM3 + BRIGHT + H\n  Res.Df    RSS  Df Sum of Sq      F    Pr(>F)    \n1     54 173261                                   \n2     54     44   0    173217                     \n3     41 134181  13   -134137                     \n4     41     37   0    134144                     \n5     51 140355 -10   -140319 4.2876 0.0004042 ***\n6     52     39  -1    140316                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSería al menos 1 es diferentes o significato, no necesariamente es el 5\n\nAIC(lm1, lm2, lm3, lm4, lm5, lm6)\n\n    df      AIC\nlm1  3 615.0045\nlm2  3 580.9045\nlm3 16 626.6902\nlm4 16 595.4066\nlm5  6 609.2097\nlm6  5 577.9501\n\n\nSe puede estar en desacuerdo con esto, todo depende de su objetivo, el modelo 6 (lm6) es parsimonioso, pero no el que da mejores resultados.\nRSS: Df:"
  },
  {
    "objectID": "val_models.html#mejor-modelo-con-re-muestreo",
    "href": "val_models.html#mejor-modelo-con-re-muestreo",
    "title": "7  Validación de Modelos",
    "section": "7.7 Mejor modelo con re-muestreo",
    "text": "7.7 Mejor modelo con re-muestreo\nusamos caret para definir un tipo de metodo de re-muestreo para entrenar modelos mas robustos.\nsavePredictions = TRUE = nos va a guardar los daos internamente en el modelo validacion K-fold, con K=5, y 5 repeticiones aleatoreas\n\ncontrol <- trainControl(method = \"repeatedcv\", \n                        number = 5, # K\n                        repeats = 5, \n                        savePredictions = TRUE)\n\nUsar mejor modelos agregamos el parametro trControl que nos permite pasar la informacion del tipo de vadilacion cruzada a usar todos los datos, no solo los de entrenar, ya que las particiones se hacen internamente.\n\n7.7.1 Entrenar Modelos con cv\nModelos 7\n\n## efecto cantidad de variables en validaciones mas robustas! \nlm7 <- train(BIOMAS ~., \n             method = \"glm\", \n             data = data2, \n             family = Gamma(link = log),\n             trControl = control)\nsummary(lm7)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5663  -0.8534  -0.1446   0.3204   1.6855  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  7.765e+00  5.666e+00   1.370 0.174567    \nTM1          4.150e-01  3.397e-01   1.222 0.225644    \nTM2          2.603e-01  3.413e-01   0.763 0.448091    \nTM3          4.301e-01  4.224e-01   1.018 0.311786    \nTM4         -3.962e-01  4.897e-01  -0.809 0.420965    \nTM5          1.045e-01  3.933e-01   0.266 0.791257    \nTM7          9.071e-02  3.147e-01   0.288 0.773926    \nBRIGHT      -2.014e-01  6.218e-01  -0.324 0.746916    \nGREEN        8.252e-01  5.001e-01   1.650 0.103039    \nMOIST       -7.137e-02  4.807e-01  -0.148 0.882373    \nNDVI        -1.987e+01  1.913e+01  -1.039 0.302292    \nNDVIC        1.530e+01  1.014e+01   1.508 0.135579    \nPEND        -7.538e-03  1.199e-02  -0.629 0.531550    \nALT         -2.434e-04  1.169e-03  -0.208 0.835610    \nH            8.856e-02  2.510e-02   3.528 0.000714 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.7076406)\n\n    Null deviance: 95.048  on 90  degrees of freedom\nResidual deviance: 55.750  on 76  degrees of freedom\nAIC: 937.46\n\nNumber of Fisher Scoring iterations: 11\n\n\nModelo 6\n\nlm8 <- train(BIOMAS ~ TM3 + BRIGHT + H, # los determinados por el train de lm6\n             method = \"glm\", \n             data = data2, \n             family = Gamma(link = log),\n             trControl = control)\nsummary(lm8)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7172  -0.8079  -0.1219   0.3163   1.8271  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.56495    1.02006   6.436 6.46e-09 ***\nTM3          0.05896    0.01869   3.154 0.002210 ** \nBRIGHT      -0.04554    0.01333  -3.417 0.000965 ***\nH            0.08557    0.01904   4.495 2.14e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.6453826)\n\n    Null deviance: 95.048  on 90  degrees of freedom\nResidual deviance: 61.377  on 87  degrees of freedom\nAIC: 925.12\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n7.7.2 Datos de ajuste internos de cada iteración\n\nlm7$resample\n\n        RMSE   Rsquared      MAE   Resample\n1   42.08596 0.55062712 34.34071 Fold1.Rep1\n2  164.24473 0.11760861 93.04358 Fold2.Rep1\n3   62.70291 0.36601711 44.95314 Fold3.Rep1\n4   53.79932 0.25253642 39.66982 Fold4.Rep1\n5   82.24359 0.20767591 60.84382 Fold5.Rep1\n6   64.45791 0.22995763 39.02619 Fold1.Rep2\n7  170.00849 0.07854019 82.37425 Fold2.Rep2\n8   43.10085 0.42965684 35.63650 Fold3.Rep2\n9   39.07610 0.57550108 33.40203 Fold4.Rep2\n10  89.18437 0.13761200 72.19029 Fold5.Rep2\n11  64.32318 0.54899375 42.86009 Fold1.Rep3\n12  73.58456 0.40000220 54.21211 Fold2.Rep3\n13  46.76064 0.54345393 38.59701 Fold3.Rep3\n14  31.23562 0.64675677 26.76364 Fold4.Rep3\n15 158.51760 0.17864936 89.69632 Fold5.Rep3\n16 152.52734 0.15959130 77.79163 Fold1.Rep4\n17  41.18393 0.48586434 29.45265 Fold2.Rep4\n18  61.27450 0.45782888 38.05745 Fold3.Rep4\n19  66.67338 0.31925216 49.10811 Fold4.Rep4\n20  52.02723 0.48809468 40.18278 Fold5.Rep4\n21  48.76703 0.52934030 37.69387 Fold1.Rep5\n22  64.96093 0.26812830 45.72222 Fold2.Rep5\n23  61.23993 0.39640010 42.70253 Fold3.Rep5\n24 110.39498 0.07262132 63.72854 Fold4.Rep5\n25  55.79810 0.49990714 41.85867 Fold5.Rep5\n\n\n\n\n7.7.3 Visualización\nVisualización de R^2\n\npar(mfrow=c(1,2))\nboxplot(lm7$resample[,2], main ='R2 todo', ylim = c(0,1))\nabline(h = median(lm7$resample[,2]), lty = 2, col = \"red\")\nboxplot(lm8$resample[,2], main ='R2 (TM3 + BRIGHT + H)', ylim = c(0,1))\nabline(h = median(lm8$resample[,2]), lty = 2, col = \"red\")\n\n\n\n\nVisualización de RMSE\n\npar(mfrow=c(1,2))\nboxplot(lm7$resample[,1], main ='RMSE todo',  ylim = c(20,120))\nabline(h = median(lm7$resample[,1]), lty = 2, col = \"red\")\nboxplot(lm8$resample[,1], main ='RMSE (TM3 + BRIGHT + H)', ylim = c(20,120))\nabline(h = median(lm8$resample[,1]), lty = 2, col = \"red\")\n\n\n\n\nEn este caso tenemos una sitribución de datos\n\n\n7.7.4 Observados vs predichos\n\n# lm7$pred\n\npar(mfrow=c(1,2))\n\nobs7 <- lm7$pred[,2]\npred7 <- lm7$pred[,1]\n\nplot(obs7, pred7, pch = 16, col = rgb(0,0.5,0,0.3)) # red, green, blue, alpha\nabline(0, 1, lty = 2, col = \"red\") # intercepto, pendiente\n\nlm <- lm(pred7 ~ obs7 - 1)\nabline(lm)\nlegend('topleft', legend=c('Linea 1:1', 'Linea ajustada'), lty = c(2,1), \n       col = c(\"red\", \"black\"), bty = 'n')\n\nobs8 <- lm8$pred[,2]\npred8 <- lm8$pred[,1]\n\nplot(obs8, pred8, pch = 17, col = rgb(0,0,0.5,0.3))\nabline(0, 1, lty = 2, col = \"red\")\n\nlm <- lm(pred8 ~ obs8 - 1)\nabline(lm)\nlegend('topleft', legend=c('Linea 1:1', 'Linea ajustada'), lty = c(2,1), \n       col = c(\"red\", \"black\"), bty = 'n')\n\n\n\n\nEN el Eje x son fijas las predicciones, mientras que en las prediccionesn pueden variar.\n\n\n\n\n“Explaining the Lm() Summary in R – Learn by Marketing.” n.d. Accessed September 2, 2022. https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/.\n\n\nKuhn, Max. n.d. 7 Train Models By Tag | The Caret Package. Accessed September 9, 2022. https://topepo.github.io/caret/train-models-by-tag.html."
  },
  {
    "objectID": "diseno_exp.html",
    "href": "diseno_exp.html",
    "title": "9  Diseño de Experimentos",
    "section": "",
    "text": "El objetivo principal de la estadística es hacer inferencias sobre poblaciones a partir de muestras.\n\n\n\nDescripción de Test de Hipótesis\n\n\nEl objetivo es decidir, basado en una muestra de la población, si existe evidencia suficiente para rechazar la hipótesis nula.\n\n\nNormalmente, un test de hipótesis se especifica en base a un estadístico (ej., Z, t, F). Es decir, una función que determina un valor dada la muestra de datos sobre la H_0. Todo test se hace en base a H_0.\nEl procedimiento de un test de hipótesis debe especificar:\n\nPara que valores la hipótesis H_0 se considera “verdadera”; realmente no existe evidencia suficiente para rechazar H_0.\nPara que valores la hipótesis H_0 se rechaza y H_1 es “aceptada” como verdad; realmente no hay suficiente información para aceptar H_0.\n\nLos valores para los cuales el test de hipótesis se rechaza se denomina región de rechazo o región crítica. El complemento de esta región se denomina región de aceptación.\nColas\nNormalmente existen dos tipos de test de hipótesis, de una cola y de dos colas.\n\n\n\nColas en Test de Hipótesis\n\n\nLa probabilidad de rechazar H_0 se conoce como nivel de significancia (significance level), y se denota con la letra griega alfa. Ej., \\alpha = 0.05 (5%)\nEl valor del estadígrafo utilizado en el test (ej., Z, t, F) correspondiente a α se conoce como valor crítico (critical value)\n\n\n\nEg. Test dos colas\n\n\n\n\n\n\n\n\nEg. Valor Crítico\n\n\n\n\n\nError Tipo 1\nEs muy importante darse cuenta de que una hipótesis nula verdadera en ocasiones será rechazada. Además, este error se cometerá con una frecuencia de \\alpha (e.g. \\alpha = 0.05)\nEl rechazo de una hipótesis nula cuando en realidad es verdadera es lo que se conoce como Error Tipo 1\nError Tipo 2\nThe probability of not rejecting th null hypothesis when it in fact false is represented by \\beta Error Tipo 2\nLa potencia de una prueba estadística se define como 1-\\beta\nConculsión de los Errores\n\n\n\nConculsión de los errores\n\n\n\n\n\nGráfico de errores"
  },
  {
    "objectID": "diseno_exp.html#p-valor",
    "href": "diseno_exp.html#p-valor",
    "title": "9  Diseño de Experimentos",
    "section": "9.2 P-Valor",
    "text": "9.2 P-Valor\nDeterminar la región crítica basado en un valor \\alpha solo podemos tomar una decisión binaria sobre la hipótesis, sin info. suficiente para “rechazar” o “aceptar” H_0.\nDado un estadístico W_{(X)}, el p-valor de un test de hipótesis es la probabilidad de obtener un resultado igual o más extremo que el estadístico observado W(x)=w, asumiendo H_0 como verdad.\n\n\n\nConceptualización Probalística del p-value\n\n\n\nUn p-valor bajo => que es muy poco probable haber obtenido W_{(x)} (ej., p < 0.05 … no hay evidencia suficiente para aceptar …(se rechaza)… H_0).\nUn p-valor alto => que es muy probable haber obtenido W_{(x)} (ej., p > 0.05 … se acepta H_0)"
  },
  {
    "objectID": "diseno_exp.html#aplicabilidad-qué-test-debo-usar",
    "href": "diseno_exp.html#aplicabilidad-qué-test-debo-usar",
    "title": "9  Diseño de Experimentos",
    "section": "9.3 Aplicabilidad: ¿Qué test debo usar?",
    "text": "9.3 Aplicabilidad: ¿Qué test debo usar?\n\n\n\nÁrbol de decisión para seleccionar test\n\n\n\n9.3.1 Comparar dos muestras\n\n\n\nComparar dos muestras\n\n\nComparar dos medias\n¿Qué probabilidad hay de que nuestras dos medias muestrales procedan de dos poblaciones con la misma media?\n\nEs muy probable → Las dos medias muestrales no son signiﬁcativamente diferentes.\nEs bastante improbable → Las medias muestrales son signiﬁcativamente diferentes.\n\nSi esta probabilidad es muy baja (digamos, menos del 5% o menos del 1%), entonces podemos estar razonablemente seguros (95% o 99% en estos dos ejemplos) de que las medias son realmente diferentes entre sí.\nOJO!: hay que tener en cuenta que nunca podemos estar seguros al 100%; la diferencia aparente podría deberse simplemente a un muestreo aleatorio, es decir, que hemos obtenido muchos valores bajos en una muestra y muchos valores altos en la otra (error de diseño muestral)\nt Student:\n\n\n\nt Student\n\n\n\n\n\nError Estandas de las Diferencias\n\n\nEjemplo: Ver si las medias de dos muestras de datos de n=20 difieren:\n\nDF = 20 – 2 = 18 (- 2 por que en este caso son dos poblaciones, no una)\nNivel de significancia: Normalmente utilizamos el 5% como probabilidad de rechazar la hipótesis nula cuando es verdadera (es la tasa de error de tipo I). Puede cambiar dependiendo de la aplicación o el campo de estudio (e.g., 10% o 1%).\nValor crítico: Este test es típicamente de dos colas, y el valor crítico que se usa para ver si se acepta o rechaza H_0 sería:\n\n\n# porqué 0.975 envés de 0.95? por qué el test es de dos colas, \n# y el nivel de significancia se divide en dos \n\nqt(0.975, 18)  \n\n[1] 2.100922\n\n# valor crítico!\n\nEsto significa que nuestro estadístico t de prueba tiene que ser mayor que 2,1 (valor crítico) para rechazar la hipótesis nula y, por tanto concluir que las dos medias son signiﬁcativamente diferentes a α = 0,05.\n\nt.test(gardenA, gardenB)\n\n\n\n\nPrueba visual: Usar boxplot con muescas (notchs)\n\n\nEn R:\n\nboxplot(A, B, notch=TRUE, xlab=\"Garden\", ylab=\"Ozone\")\n\n\n\n\nPrueba visual en R\n\n\nVisualmente las muescas no se sobrelapan, se podría concluir que las medias de las dos distribuciones son significativamente diferentes al nivel de 5%"
  },
  {
    "objectID": "anova.html",
    "href": "anova.html",
    "title": "10  Anova",
    "section": "",
    "text": "Si queremos predecir una variable Y de tipo continua, podemos dividir a grandes rasgos los tipos de modelos predictivos en tres grandes tipo en base a la naturaleza de los predictores o variables (X):"
  },
  {
    "objectID": "anova.html#anova-análisis-de-varianza",
    "href": "anova.html#anova-análisis-de-varianza",
    "title": "10  Anova",
    "section": "10.1 ANOVA: Análisis de Varianza",
    "text": "10.1 ANOVA: Análisis de Varianza\nPredecir Y usando una o más variables factoriales\nY ~ A; Y ~ A+B; Y ~ A+B+C\nH0: μ1 = μ2 = μ3….(todas las medias poblacionales de Y son iguales, o no significativamente distintas)\nH1: Al menos una media poblacional es distinta del resto\n\nNo dice cual es la distinta!\n\nAsume que:\n\nLa selección de valores en los subgrupos es aleatoria e independiente\nTodas los subgrupos tienen una distribución de errores normal (residuos)\nTodas las poblaciones de los subgrupos de Y tienen la misma varianza\n\nEn caso que alguno de estos supuestos no se cumplan: Impactarán directamente sobre los valores p-valor reportados, y por lo tanto sobre la calidad de las conclusiones que finalmente buscamos obtener.\nLa verificación de los supuestos se realiza en la práctica a través de los predictores de los términos de error aleatorio que son los residuos aleatorios asociados a cada observación Por lo tanto los supuestos pueden verificarse mediante el análisis de los RESIDUOS.\n\n\n\nFigure 10.3: Comparación de Análisis de Anova Unidireccional y Multidimensional. La única diferencia entre ANOVA unidireccional y bidireccional es el número de variables independientes. Un ANOVA unidireccional tiene una variable independiente, mientras que un ANOVA bidireccional tiene dos."
  },
  {
    "objectID": "anova.html#on-way-anova",
    "href": "anova.html#on-way-anova",
    "title": "10  Anova",
    "section": "10.2 On-Way ANOVA",
    "text": "10.2 On-Way ANOVA\nANOVA de unas sola cola, o comparación de una variable Y en un variable X de tipo factorial\nOutput del modelo simpre es:\n\n\n\nFigure 10.4: Summary del Modelo de Anova\n\n\n\nFigure 10.5: Definición de Siglas"
  },
  {
    "objectID": "anova.html#experimento-factorial-two-way-anova",
    "href": "anova.html#experimento-factorial-two-way-anova",
    "title": "10  Anova",
    "section": "10.3 Experimento factorial (Two-Way ANOVA)",
    "text": "10.3 Experimento factorial (Two-Way ANOVA)\nEn estas situaciones estimamos los parámetros para los efectos principales de cada nivel de dieta y cada nivel de suplemento, además de los términos para la interacción entre la dieta y el suplemento. Los grados de libertad de la interacción son el producto de los grados de libertad de los términos componentes (es decir, (3 - 1) × (4 - 1) = 6).\nEl modelo es gain~diet+supplement+diet:supplement, pero puede simplificarse utilizando la notación del asterisco así:\nmodel <- aov(gain~diet*supplement)\nsummary(model)\n\nOutput del modelo Two-Way ANOVA :::\nNo hay evidencia de que las diferencias que dieta causa sobre Y (gain) varían en función de los suplementos, y viceversa. En este caso se puede decir entonces que los efectos de dieta y suplementos son Aditivos!"
  },
  {
    "objectID": "anova.html#pseudoreplicación-diseños-anidados-y-parcelas-divididas",
    "href": "anova.html#pseudoreplicación-diseños-anidados-y-parcelas-divididas",
    "title": "10  Anova",
    "section": "10.4 Pseudoreplicación: Diseños anidados y parcelas divididas",
    "text": "10.4 Pseudoreplicación: Diseños anidados y parcelas divididas\nLos modelos ANOVA tienen la facilidad de tratar con estructuras de error complicadas, y es importante que puedan reconocer tales estructuras de error, y por lo tanto evitar posibles trampas de la pseudoreplicación.\nHay dos casos generales:\n\nMuestreo anidado, como cuando se toman medidas repetidas del mismo individuo, o se realizan estudios observacionales donde datos se llevan a cabo en varias escalas espaciales diferentes (principalmente efectos aleatorios);\nAnálisis de parcelas divididas, como cuando los experimentos diseñados tienen diferentes tratamientos aplicados a parcelas de diferentes tamaños (en su mayoría, efectos fijos).\n\n\n10.4.1 Parcelas divididas\nSe aplican diferentes tratamientos a parcelas de diferentes tamaños. Cada tamaño de parcela tiene su propia varianza de error asociada, por lo que en lugar de tener una varianza de error (como en todas las tablas de ANOVA hasta este punto), tenemos tantos términos de error como tamaños de parcela diferentes. El análisis se presenta como una serie de tablas de ANOVA de componentes, una para cada tamaño de parcela, en una jerarquía que va desde el tamaño de parcela más grande con la menor replicación en la parte superior, hasta el tamaño de parcela más pequeño con la mayor replicación en la parte inferior.\nEjemplo: un experimento de campo diseñado sobre el rendimiento de los cultivos con tres tratamientos: riego (con dos niveles, regado o no), densidad de siembra (con tres niveles, bajo, medio y alto), y aplicación de fertilizantes (con tres niveles, bajo, medio y alto).\nLas parcelas más grandes fueron los cuatro campos completos (bloque), cada uno de los cuales se dividió por la mitad, y el riego se asignó al azar a una mitad del campo. Cada parcela de riego se dividió en tres, y se asignó al azar una de las tres densidades de siembra diferentes (baja, media o alta) (independientemente para cada nivel de riego y cada bloque). Por último, cada parcela de densidad se dividió en tres, y se asignó al azar uno de los tres tratamientos de nutrientes fertilizantes (N, P, o N y P juntos).\n\n\n\nFigure 10.6: Parcelas Divididas\n\n\nEl problema de los experimentos con parcelas divididas es la pseudoreplicación.\nEn el ejemplo, hay cuatro bloques, cada uno dividido por la mitad, con una mitad regada y la otra como control. En caso específico del factor riego, el experimento debería contener sólo 8 filas (no 72 filas como en el presente caso). Debería tener d.f. = 7: tres para los bloques, uno para el riego y sólo 7 - 3 - 1 = 3 d.f. para el error.\n\n\n\nFigure 10.7: Estructura de Datos Parcelas Divididas\n\n\nSi no se ha detectado esto, el modelo podría ejecutarse con 51 f.d. que representan una pseudoreplicación masiva (el valor de p-valor correcto para el tratamiento de riego es 0,0247, pero en una ANOVA normal el error pseudoreplicado da p-valor = 2.81 × 10^{-10}).\nEj.,modelo factorial, usando todas las combinaciones entre factores (asteriscos en formula; *)\n\n\n\nFigure 10.8: Summary del Modelo ANOVA factorial Parcelas Divididas\n\n\nPara corregir esto, la estructura del error se deﬁne en el término Error, con los tamaños de parcela enumerados de izquierda a derecha, de mayor a menor, con cada variable separada por el operador de barra diagonal /. Tenga en cuenta que el tamaño de parcela más pequeño, el fertilizante, no necesita aparecer en el término Error:\n\n\n\nFigure 10.9: Efectos entre factores: Densidad al parecer no es sig. por si solo (efecto aditivo), pero sí tiene relevancia en sus efectos sinérgicos con irrigación.\n\n\nNótese que el efecto principal no signiﬁcativo de la densidad (p = 0,053) no significa que la densidad no sea importante, porque la densidad aparece en una interacción signiﬁcativa con el riego (los términos de densidad se anulan, cuando se promedian en los dos tratamientos de riego; véase más adelante). La mejor manera de entender los dos términos de interacción signiﬁcativos es trazarlos utilizando interaction.plot de la siguiente manera:\nirrigation:fertilizer relationship\n\n\n\nFigure 10.10: En las parcelas con riego, el rendimiento con baja densidad, pero en las parcelas de control el rendimiento es menor que en las parcelas de alta densidad.\n\n\n\n\n10.4.2 Muestreo Anidado\nEn este caso, hay un posible gradiente que se quiere ELIMINAR del análisis, para centrarse bien en el gradiente o efecto que SI es interesante. Ejemplo:\nSe tiene una plantación de paltos en una ladera de cerro, y se quiere ver el efecto de fertilizantes y densidad de cultivo. Cómo la ladera de cerro puede tener mucho efecto en los resultados, debido a efectos de pendiente, características del suelo, etc., lo más importante acá es eliminar el efecto ladera-suelo del análisis.\nDiseño de muestreo estratificado por ladera: clasificar 3 tipos de ladera (baja, media y alta) y hacer las MISMAS mediciones de fertilizante y densidad en las 3 clases de ladera. Finalmente, se agrega la info del bloque como factor para ser si efecto independiente.\naov(yield ~ fertilizer + density + block, data = block)\n\n\n\nFigure 10.11: Anova para el caso de muestreo anidado que denota que no hay efecto bloque"
  },
  {
    "objectID": "anova.html#sección-práctica-anova",
    "href": "anova.html#sección-práctica-anova",
    "title": "10  Anova",
    "section": "10.5 Sección Práctica Anova",
    "text": "10.5 Sección Práctica Anova\n\n10.5.1 Tratamiento a los Datos\n\nlibrary(DescTools)\n\ndata <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/yields.txt',\n                    header=T, stringsAsFactors = TRUE)\n\n\n# estructura de los datos\nstr(data)\n\n'data.frame':   10 obs. of  3 variables:\n $ sand: int  6 10 8 6 14 17 9 11 7 11\n $ clay: int  17 15 3 11 14 12 12 8 10 13\n $ loam: int  13 16 9 12 15 16 17 13 18 14\n\nsummary(data)\n\n      sand            clay            loam     \n Min.   : 6.00   Min.   : 3.00   Min.   : 9.0  \n 1st Qu.: 7.25   1st Qu.:10.25   1st Qu.:13.0  \n Median : 9.50   Median :12.00   Median :14.5  \n Mean   : 9.90   Mean   :11.50   Mean   :14.3  \n 3rd Qu.:11.00   3rd Qu.:13.75   3rd Qu.:16.0  \n Max.   :17.00   Max.   :17.00   Max.   :18.0  \n\n\n\n# se pueden juntar las 3 clases en una sola columna y agregar las clases en otra con la\n# funcion stack\n\ndata2 <- stack(data)\ncolnames(data2) <- c(\"yield\",\"soil\") # cambiamos el nombre de las columnas\nstr(data2)\n\n'data.frame':   30 obs. of  2 variables:\n $ yield: int  6 10 8 6 14 17 9 11 7 11 ...\n $ soil : Factor w/ 3 levels \"sand\",\"clay\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\nLa clase soil es de tipo factorial esto es fundamental\n\n\n\n10.5.2 Test de Bartlett\nAnalizar si las varianza por subgrupo es homogeneas con test de Bartlett, este test no necesita hacerse sobre los residuos\n\nH0 = son homogeneas\nH1 = no son homogeneas\n\n\n### Test de Bartlett \n\nbartlett.test(yield ~ soil, data = data2)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  yield by soil\nBartlett's K-squared = 1.2764, df = 2, p-value = 0.5283\n\n\n\n\n10.5.3 one-way ANOVA\nRealizar test anova usando la funcion aov. Esta es la funcion estandar para este tipo de analisis\n\nanov1 <- aov(yield ~ soil, data = data2)\nsummary(anov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nsoil         2   99.2   49.60   4.245  0.025 *\nResiduals   27  315.5   11.69                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(anov1)\n\n\nCall:\naov(formula = yield ~ soil, data = data2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -8.5   -1.8    0.3    1.7    7.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.900      1.081   9.158 9.04e-10 ***\nsoilclay       1.600      1.529   1.047  0.30456    \nsoilloam       4.400      1.529   2.878  0.00773 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.418 on 27 degrees of freedom\nMultiple R-squared:  0.2392,    Adjusted R-squared:  0.1829 \nF-statistic: 4.245 on 2 and 27 DF,  p-value: 0.02495\n\n\n\n\n10.5.4 Normalidad de los Residuos\n\npar(mfrow = c(2, 2))\nplot(anov1)\n\n\n\n\n\n\nnull device \n          1 \n\n\n\nHO = es normal\nH1 = no es normal\n\n\nshapiro.test(anov1$residuals) # si!\n\n\n    Shapiro-Wilk normality test\n\ndata:  anov1$residuals\nW = 0.99131, p-value = 0.9961\n\n\n\n\n10.5.5 Post-Hoc\nNecesitamos saber donde estan las diferencias entre clases\n\ntuk <- TukeyHSD(anov1, conf.level = 0.95)\ntuk\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = yield ~ soil, data = data2)\n\n$soil\n          diff        lwr      upr     p adj\nclay-sand  1.6 -2.1903777 5.390378 0.5546301\nloam-sand  4.4  0.6096223 8.190378 0.0204414\nloam-clay  2.8 -0.9903777 6.590378 0.1785489\n\nplot(tuk, col = \"red\", las = 1, cex.axis = 0.5, \n     cex.lab = 0.5, cex = 0.5)\n\n\n\n\nLa diferencia entre loam y sand (limo y arena) es la unica significativa\n\n\n10.5.6 Visualización\nBoxplot*\n\nboxplot(yield ~ soil, data = data2, col = 'lightblue', notch = T)\n\nWarning in (function (z, notch = FALSE, width = NULL, varwidth = FALSE, : some\nnotches went outside hinges ('box'): maybe set notch=FALSE\n\n\n\n\n\nBarplot con barras de error\nRevisar cuantas observaciones hay por clase. Ya sabemos que son 10, pero se puede revisar con table\n\ntable(data2$soil)\n\n\nsand clay loam \n  10   10   10 \n\n\nError estandar de una media = \\sqrt(\\frac{S2}{N}\n\nsummary(anov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nsoil         2   99.2   49.60   4.245  0.025 *\nResiduals   27  315.5   11.69                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# repetimos este valor por el numero de subclases\nse <- rep( sqrt(11.69/10),3)\n\n# Estimar las medias de los tres subgrupos\n\n# La funcion tapply va a sacar la mean de yield usando como factor soil\nybar <- tapply(data2$yield, data2$soil, mean)\n\n# Nombres de los subgrupos\nlabels <- levels(data2$soil)\n\nNo hay una funcion para crear barras de error en R basico. Hay por su puesto en varios paquetes avanzados de plots, pero en este caso usamos esta funcion casera\n\nerror.bars <- function(yv,z,nn)\n{xv <- barplot(yv,ylim=c(0,(max(yv)+max(z))),\n               col=\"gray\",names=nn,ylab=deparse(substitute(yv)))\nfor (i in 1:length(xv)) {\n  arrows(xv[i],yv[i]+z[i],xv[i],yv[i]-z[i],angle=90,code=3,length=0.15)\n}}\n\n\nerror.bars(ybar, se, labels)"
  },
  {
    "objectID": "anova.html#ejemplo-2",
    "href": "anova.html#ejemplo-2",
    "title": "10  Anova",
    "section": "10.6 Ejemplo 2",
    "text": "10.6 Ejemplo 2\none-way anova con tratamiento con control y post-hoc test de Dun\nEjemplo, examinar si dos nuevas tecnicas de ensenanza tienen potencialmente un beneficio en la nota final de un examen. Se dividen los estudiantes en 30 individuos en los siguientes grupos:\nControl Group: 10 students New Study technique 1: 10 students New Study Technique 2: 10 students\n\ndata <- data.frame(technique = rep(c(\"control\", \"new1\", \"new2\"), each = 10),\n                   score = c(76, 77, 77, 81, 82, 82, 83, 84, 85, 89,\n                             81, 82, 83, 83, 83, 84, 87, 90, 92, 93,\n                             77, 78, 79, 88, 89, 90, 91, 95, 95, 98))\n\n\nhead(data)\n\n  technique score\n1   control    76\n2   control    77\n3   control    77\n4   control    81\n5   control    82\n6   control    82\n\nstr(data)\n\n'data.frame':   30 obs. of  2 variables:\n $ technique: chr  \"control\" \"control\" \"control\" \"control\" ...\n $ score    : num  76 77 77 81 82 82 83 84 85 89 ...\n\n\nAsegurarse que de las clases o tratamientos esten en formato factorial!\n\ndata$technique <- as.factor(data$technique)\nstr(data)\n\n'data.frame':   30 obs. of  2 variables:\n $ technique: Factor w/ 3 levels \"control\",\"new1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ score    : num  76 77 77 81 82 82 83 84 85 89 ...\n\n\n\nboxplot(score ~ technique,\n        data = data,\n        main = \"Exam Scores by Studying Technique\",\n        xlab = \"Studying Technique\",\n        ylab = \"Exam Scores\",\n        col = \"steelblue\",\n        border = \"black\")\n\n\n\n\n\n10.6.1 one-way ANOVA\n\nmodel <- aov(score ~ technique, data = data)\nsummary(model)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ntechnique    2  211.5  105.73   3.415 0.0476 *\nResiduals   27  836.0   30.96                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n10.6.2 Revision de residuos\n\npar(mfrow = c(2, 2))\nplot(model)\n\n\n\nshapiro.test(model$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  model$residuals\nW = 0.97617, p-value = 0.7172\n\n\n\n\nnull device \n          1 \n\n\n\n\n10.6.3 Test de Dunnett\ncompara solo las clases contra el tratamiento control\n\nplot(DunnettTest(x = data$score, g = data$technique))\n\n\n\n\nASEGURARSE siempre que el control tenga el nombre ‘control’ exactamente en la tabla\n\n\n10.6.4 PostHocs\nla libreria DescTools tiene muchos test Post-hoc para hacer\n\n10.6.4.1 Test de Tukey\nDos formas de visualizar el test de tukey\n\n# Usando DescTools\nPostHocTest(model, method = \"hsd\")\n\n\n  Posthoc multiple comparisons of means : Tukey HSD \n    95% family-wise confidence level\n\n$technique\n             diff     lwr.ci    upr.ci   pval    \nnew1-control  4.2 -1.9700112 10.370011 0.2281    \nnew2-control  6.4  0.2299888 12.570011 0.0409 *  \nnew2-new1     2.2 -3.9700112  8.370011 0.6548    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# usando R\nTukeyHSD(model)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = score ~ technique, data = data)\n\n$technique\n             diff        lwr       upr     p adj\nnew1-control  4.2 -1.9700112 10.370011 0.2281369\nnew2-control  6.4  0.2299888 12.570011 0.0409017\nnew2-new1     2.2 -3.9700112  8.370011 0.6547756\n\n\n\nplot(PostHocTest(model, method = \"hsd\"))\n\n\n\nplot(TukeyHSD(model))"
  },
  {
    "objectID": "anova.html#experimento-factorial-two-way-anova-1",
    "href": "anova.html#experimento-factorial-two-way-anova-1",
    "title": "10  Anova",
    "section": "10.7 Experimento Factorial (two-way Anova)",
    "text": "10.7 Experimento Factorial (two-way Anova)\n\n10.7.1 Lectura Data\n\nweights <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/growth.txt',\n                      header=T, stringsAsFactors = TRUE)\n\nstr(weights)\n\n'data.frame':   48 obs. of  3 variables:\n $ supplement: Factor w/ 4 levels \"agrimore\",\"control\",..: 3 3 3 3 2 2 2 2 4 4 ...\n $ diet      : Factor w/ 3 levels \"barley\",\"oats\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ gain      : num  17.4 16.8 18.1 15.8 17.7 ...\n\n\n\n\n10.7.2 Barplot\ninspeccion de datos con barplot. Primero, crear una tabla con promedios por clase usando tapply esta vez en tapply usamos una lista con los dos factores para que los tome a los dos en cuenta\n\nymean <- tapply(weights$gain, list(weights$diet, weights$supplement), mean)\n\nEl parametro beside=TRUE indica que las subcalses (dieta) van como subgrupo del suplemento\n\nbarplot(ymean, beside = TRUE, ylim = c(0, 30), col = c(\"orange\", \"yellow\", \"cornsilk\"))\nlabs <- c(\"Barley\", \"Oats\", \"Wheat\")\nlegend('top', labs, fill= c(\"orange\", \"yellow\", \"cornsilk\"))\n\n\n\n\n\n\n10.7.3 ANOVA\n\nmodel <- aov(gain ~ diet*supplement, data = weights)\nsummary(model)\n\n                Df Sum Sq Mean Sq F value   Pr(>F)    \ndiet             2 287.17  143.59   83.52 3.00e-14 ***\nsupplement       3  91.88   30.63   17.82 2.95e-07 ***\ndiet:supplement  6   3.41    0.57    0.33    0.917    \nResiduals       36  61.89    1.72                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVer interacciones completas\n\nsummary.lm(model)\n\n\nCall:\naov(formula = gain ~ diet * supplement, data = weights)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.48756 -1.00368 -0.07452  1.03496  2.68069 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                    26.3485     0.6556  40.191  < 2e-16 ***\ndietoats                       -3.0501     0.9271  -3.290 0.002248 ** \ndietwheat                      -6.7094     0.9271  -7.237 1.61e-08 ***\nsupplementcontrol              -3.0518     0.9271  -3.292 0.002237 ** \nsupplementsupergain            -3.8824     0.9271  -4.187 0.000174 ***\nsupplementsupersupp            -0.7732     0.9271  -0.834 0.409816    \ndietoats:supplementcontrol      0.2471     1.3112   0.188 0.851571    \ndietwheat:supplementcontrol     0.8183     1.3112   0.624 0.536512    \ndietoats:supplementsupergain    0.2470     1.3112   0.188 0.851652    \ndietwheat:supplementsupergain   1.2557     1.3112   0.958 0.344601    \ndietoats:supplementsupersupp   -0.6650     1.3112  -0.507 0.615135    \ndietwheat:supplementsupersupp   0.8024     1.3112   0.612 0.544381    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.311 on 36 degrees of freedom\nMultiple R-squared:  0.8607,    Adjusted R-squared:  0.8182 \nF-statistic: 20.22 on 11 and 36 DF,  p-value: 3.295e-12\n\n\nModelo muy complejo, por lo que podemos dejar solo los componentes e interacciones significativas e interesantes.\n\n\n10.7.4 Test de varianzas homogeneas\n\nbartlett.test(gain ~ diet, data = weights)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  gain by diet\nBartlett's K-squared = 2.2513, df = 2, p-value = 0.3244\n\nbartlett.test(gain ~ supplement, data = weights)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  gain by supplement\nBartlett's K-squared = 0.57513, df = 3, p-value = 0.9021\n\n\n\nmodel2 <- aov(gain ~ diet + supplement, data = weights)\nsummary(model2) # ya no hay interacciones!\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ndiet         2 287.17  143.59   92.36 4.20e-16 ***\nsupplement   3  91.88   30.63   19.70 3.98e-08 ***\nResiduals   42  65.30    1.55                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(model2)\n\n\nCall:\naov(formula = gain ~ diet + supplement, data = weights)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.30792 -0.85929 -0.07713  0.92052  2.90615 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          26.1230     0.4408  59.258  < 2e-16 ***\ndietoats             -3.0928     0.4408  -7.016 1.38e-08 ***\ndietwheat            -5.9903     0.4408 -13.589  < 2e-16 ***\nsupplementcontrol    -2.6967     0.5090  -5.298 4.03e-06 ***\nsupplementsupergain  -3.3815     0.5090  -6.643 4.72e-08 ***\nsupplementsupersupp  -0.7274     0.5090  -1.429     0.16    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.247 on 42 degrees of freedom\nMultiple R-squared:  0.8531,    Adjusted R-squared:  0.8356 \nF-statistic: 48.76 on 5 and 42 DF,  p-value: < 2.2e-16\n\n\n\n\n10.7.5 Comparación de modelos\n\nmodel: Factorial\nmodel2: Aditivo\n\n\n# diferencias significativas entre los dos modelos?\nanova(model, model2) # No\n\nAnalysis of Variance Table\n\nModel 1: gain ~ diet * supplement\nModel 2: gain ~ diet + supplement\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     36 61.890                           \n2     42 65.296 -6   -3.4058 0.3302 0.9166\n\n\n\nAIC(model, model2)\n\n       df      AIC\nmodel  13 174.4179\nmodel2  7 164.9892\n\n\n\n# plot(PostHocTest(model, method = \"hsd\"))\nTukeyHSD(model)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = gain ~ diet * supplement, data = weights)\n\n$diet\n                  diff       lwr       upr p adj\noats-barley  -3.092817 -4.225918 -1.959715 3e-07\nwheat-barley -5.990298 -7.123399 -4.857196 0e+00\nwheat-oats   -2.897481 -4.030582 -1.764379 1e-06\n\n$supplement\n                          diff       lwr        upr     p adj\ncontrol-agrimore    -2.6967005 -4.138342 -1.2550592 0.0000764\nsupergain-agrimore  -3.3814586 -4.823100 -1.9398173 0.0000015\nsupersupp-agrimore  -0.7273521 -2.168993  0.7142892 0.5326710\nsupergain-control   -0.6847581 -2.126399  0.7568832 0.5817637\nsupersupp-control    1.9693484  0.527707  3.4109897 0.0040534\nsupersupp-supergain  2.6541065  1.212465  4.0957478 0.0000972\n\n$`diet:supplement`\n                                          diff         lwr        upr     p adj\noats:agrimore-barley:agrimore     -3.050093860  -6.2861072  0.1859194 0.0800774\nwheat:agrimore-barley:agrimore    -6.709404652  -9.9454179 -3.4733914 0.0000010\nbarley:control-barley:agrimore    -3.051827710  -6.2878410  0.1841856 0.0797364\noats:control-barley:agrimore      -5.854812782  -9.0908261 -2.6187995 0.0000156\nwheat:control-barley:agrimore     -8.942959440 -12.1789727 -5.7069461 0.0000000\nbarley:supergain-barley:agrimore  -3.882353990  -7.1183673 -0.6463407 0.0081992\noats:supergain-barley:agrimore    -6.685474160  -9.9214875 -3.4494609 0.0000011\nwheat:supergain-barley:agrimore   -9.336046198 -12.5720595 -6.1000329 0.0000000\nbarley:supersupp-barley:agrimore  -0.773175055  -4.0091883  2.4628382 0.9993538\noats:supersupp-barley:agrimore    -4.488243097  -7.7242564 -1.2522298 0.0012832\nwheat:supersupp-barley:agrimore   -6.680136725  -9.9161500 -3.4441234 0.0000011\nwheat:agrimore-oats:agrimore      -3.659310793  -6.8953241 -0.4232975 0.0156910\nbarley:control-oats:agrimore      -0.001733850  -3.2377471  3.2342794 1.0000000\noats:control-oats:agrimore        -2.804718923  -6.0407322  0.4312944 0.1426161\nwheat:control-oats:agrimore       -5.892865580  -9.1288789 -2.6568523 0.0000138\nbarley:supergain-oats:agrimore    -0.832260130  -4.0682734  2.4037532 0.9987355\noats:supergain-oats:agrimore      -3.635380300  -6.8713936 -0.3993670 0.0167992\nwheat:supergain-oats:agrimore     -6.285952338  -9.5219656 -3.0499390 0.0000038\nbarley:supersupp-oats:agrimore     2.276918805  -0.9590945  5.5129321 0.3975577\noats:supersupp-oats:agrimore      -1.438149237  -4.6741625  1.7978641 0.9151137\nwheat:supersupp-oats:agrimore     -3.630042865  -6.8660562 -0.3940296 0.0170562\nbarley:control-wheat:agrimore      3.657576943   0.4215636  6.8935902 0.0157690\noats:control-wheat:agrimore        0.854591870  -2.3814214  4.0906052 0.9983978\nwheat:control-wheat:agrimore      -2.233554788  -5.4695681  1.0024585 0.4258079\nbarley:supergain-wheat:agrimore    2.827050663  -0.4089626  6.0630640 0.1356315\noats:supergain-wheat:agrimore      0.023930493  -3.2120828  3.2599438 1.0000000\nwheat:supergain-wheat:agrimore    -2.626641545  -5.8626548  0.6093717 0.2089804\nbarley:supersupp-wheat:agrimore    5.936229597   2.7002163  9.1722429 0.0000120\noats:supersupp-wheat:agrimore      2.221161555  -1.0148517  5.4571748 0.4340350\nwheat:supersupp-wheat:agrimore     0.029267927  -3.2067454  3.2652812 1.0000000\noats:control-barley:control       -2.802985073  -6.0389984  0.4330282 0.1431702\nwheat:control-barley:control      -5.891131730  -9.1271450 -2.6551184 0.0000139\nbarley:supergain-barley:control   -0.830526280  -4.0665396  2.4054870 0.9987590\noats:supergain-barley:control     -3.633646450  -6.8696597 -0.3976332 0.0168823\nwheat:supergain-barley:control    -6.284218488  -9.5202318 -3.0482052 0.0000039\nbarley:supersupp-barley:control    2.278652655  -0.9573606  5.5146659 0.3964466\noats:supersupp-barley:control     -1.436415387  -4.6724287  1.7995979 0.9157324\nwheat:supersupp-barley:control    -3.628309015  -6.8643223 -0.3922957 0.0171405\nwheat:control-oats:control        -3.088146658  -6.3241600  0.1478666 0.0728783\nbarley:supergain-oats:control      1.972458793  -1.2635545  5.2084721 0.6078579\noats:supergain-oats:control       -0.830661377  -4.0666747  2.4053519 0.9987572\nwheat:supergain-oats:control      -3.481233415  -6.7172467 -0.2452201 0.0258844\nbarley:supersupp-oats:control      5.081637727   1.8456244  8.3176510 0.0001928\noats:supersupp-oats:control        1.366569685  -1.8694436  4.6025830 0.9382729\nwheat:supersupp-oats:control      -0.825323943  -4.0613372  2.4106894 0.9988273\nbarley:supergain-wheat:control     5.060605450   1.8245922  8.2966187 0.0002063\noats:supergain-wheat:control       2.257485280  -0.9785280  5.4934986 0.4101108\nwheat:supergain-wheat:control     -0.393086758  -3.6291001  2.8429265 0.9999993\nbarley:supersupp-wheat:control     8.169784385   4.9337711 11.4057977 0.0000000\noats:supersupp-wheat:control       4.454716343   1.2187030  7.6907296 0.0014257\nwheat:supersupp-wheat:control      2.262822715  -0.9731906  5.4988360 0.4066453\noats:supergain-barley:supergain   -2.803120170  -6.0391335  0.4328931 0.1431270\nwheat:supergain-barley:supergain  -5.453692208  -8.6897055 -2.2176789 0.0000577\nbarley:supersupp-barley:supergain  3.109178935  -0.1268344  6.3451922 0.0691463\noats:supersupp-barley:supergain   -0.605889108  -3.8419024  2.6301242 0.9999375\nwheat:supersupp-barley:supergain  -2.797782735  -6.0337960  0.4382306 0.1448433\nwheat:supergain-oats:supergain    -2.650572038  -5.8865853  0.5854413 0.1989133\nbarley:supersupp-oats:supergain    5.912299105   2.6762858  9.1483124 0.0000130\noats:supersupp-oats:supergain      2.197231062  -1.0387822  5.4332444 0.4500973\nwheat:supersupp-oats:supergain     0.005337435  -3.2306759  3.2413507 1.0000000\nbarley:supersupp-wheat:supergain   8.562871143   5.3268578 11.7988844 0.0000000\noats:supersupp-wheat:supergain     4.847803100   1.6117898  8.0838164 0.0004093\nwheat:supersupp-wheat:supergain    2.655909473  -0.5801038  5.8919228 0.1967179\noats:supersupp-barley:supersupp   -3.715068042  -6.9510813 -0.4790547 0.0133696\nwheat:supersupp-barley:supersupp  -5.906961670  -9.1429750 -2.6709484 0.0000132\nwheat:supersupp-oats:supersupp    -2.191893628  -5.4279069  1.0441197 0.4537097\n\n# plot(TukeyHSD(model))"
  },
  {
    "objectID": "ancova.html",
    "href": "ancova.html",
    "title": "11  Ancova",
    "section": "",
    "text": "Regresión + ANOVA.\nLa idea acá es combinar variables continuas con factores para analizar. Se puede pensar como un ANOVA donde hay una co-variable continua que es interesante para el estudio. O como una regresión con una co-variable factorial…\n\n\n\nFigure 11.1: Datos para análisis One Way Ancova\n\n\nEjemplo:\nExperimento sobre el impacto del pastoreo en la producción de semillas de una planta. 40 plantas fueron asignadas a dos tratamientos, pastoreadas y no pastoreadas. Las plantas pastoreadas fueron expuestas a los conejos durante las dos primeras semanas de elongación del tallo. A continuación, se protegieron del pastoreo posterior mediante la instalación de una valla y se les permitió volver a crecer. Dado que el tamaño inicial de la planta se pensó que podía influir en la producción de fruta, se midió el diámetro de la parte superior del portainjerto (sobre la raíz) antes de plantar en maceta. Al final de la temporada de cultivo, se registró la producción de fruta (peso seco en miligramos) en cada una de las 40 plantas, y esto constituye la variable de respuesta en el siguiente análisis.\nData:\n- Fuit (variable Y, contínua)\n- Root (variable X, contínua)\n- Grazing (variable X, factorial)\n¿Cómo afecta el tipo de pastoreo (factor) y el diámetro del tallo sobre la raíz (continua) a la producción de semilla y fruta de la planta?\n\n\n\nFigure 11.2: Efectos de pastoreo (Grazed)\n\n\n\nFigure 11.3: One-way ANCOVA\n\n\n\n\n\n\n\n\n\n\n\nEjemplo:\nEl siguiente experimento, con el peso como variable de respuesta, incluía el genotipo y el sexo como dos variables explicativas categóricas y la edad como covariable continua. Hay seis niveles de genotipo y dos niveles de sexo.\nPeso ~ genotipo(factor) + sexo(factor) + edad(numérica)\n\n\n\nFigure 11.4: Summary del Ejemplo propuesto\n\n\n\n\nUsar stepwise selección automática para hacer el modelo más simple?\nStep() hace el trabajo similar a lo hecho en caret con los modelos de regresión: prueba todas las combinaciones de variables y elije la mas parsimoniosa según AIC:\n\n\n\n\nm1 <- aov(Weight~Sex*Age*Genotype)\nsummary(m1)\n\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nSex               1  10.37  10.374 183.440 1.06e-15 ***\nAge               1  10.77  10.770 190.450 6.03e-16 ***\nGenotype          5  54.96  10.992 194.371  < 2e-16 ***\nSex:Age           1   0.05   0.049   0.865    0.358    \nSex:Genotype      5   0.15   0.029   0.520    0.760    \nAge:Genotype      5   0.17   0.034   0.595    0.704    \nSex:Age:Genotype  5   0.35   0.070   1.235    0.313    \nResiduals        36   2.04   0.057                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm2 <- step(m1)\n\nStart:  AIC=-155.01\nWeight ~ Sex * Age * Genotype\n\n                   Df Sum of Sq    RSS     AIC\n- Sex:Age:Genotype  5   0.34912 2.3849 -155.51\n<none>                          2.0358 -155.01\n\nStep:  AIC=-155.51\nWeight ~ Sex + Age + Genotype + Sex:Age + Sex:Genotype + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Sex:Genotype  5  0.146901 2.5318 -161.92\n- Age:Genotype  5  0.168136 2.5531 -161.42\n- Sex:Age       1  0.048937 2.4339 -156.29\n<none>                      2.3849 -155.51\n\nStep:  AIC=-161.92\nWeight ~ Sex + Age + Genotype + Sex:Age + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Age:Genotype  5  0.168136 2.7000 -168.07\n- Sex:Age       1  0.048937 2.5808 -162.78\n<none>                      2.5318 -161.92\n\nStep:  AIC=-168.07\nWeight ~ Sex + Age + Genotype + Sex:Age\n\n           Df Sum of Sq    RSS      AIC\n- Sex:Age   1     0.049  2.749 -168.989\n<none>                   2.700 -168.066\n- Genotype  5    54.958 57.658    5.612\n\nStep:  AIC=-168.99\nWeight ~ Sex + Age + Genotype\n\n           Df Sum of Sq    RSS      AIC\n<none>                   2.749 -168.989\n- Sex       1    10.374 13.122  -77.201\n- Age       1    10.770 13.519  -75.415\n- Genotype  5    54.958 57.707    3.662\n\nsummary(m2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nSex          1  10.37  10.374   196.2 <2e-16 ***\nAge          1  10.77  10.770   203.7 <2e-16 ***\nGenotype     5  54.96  10.992   207.9 <2e-16 ***\nResiduals   52   2.75   0.053                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsummary.lm(m2)\n\n\nCall:\naov(formula = Weight ~ Sex + Age + Genotype)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40005 -0.15120 -0.01668  0.16953  0.49227 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     7.93701    0.10066  78.851  < 2e-16 ***\nSexmale        -0.83161    0.05937 -14.008  < 2e-16 ***\nAge             0.29958    0.02099  14.273  < 2e-16 ***\nGenotypeCloneB  0.96778    0.10282   9.412 8.07e-13 ***\nGenotypeCloneC -1.04361    0.10282 -10.149 6.21e-14 ***\nGenotypeCloneD  0.82396    0.10282   8.013 1.21e-10 ***\nGenotypeCloneE -0.87540    0.10282  -8.514 1.98e-11 ***\nGenotypeCloneF  1.53460    0.10282  14.925  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2299 on 52 degrees of freedom\nMultiple R-squared:  0.9651,    Adjusted R-squared:  0.9604 \nF-statistic: 205.7 on 7 and 52 DF,  p-value: < 2.2e-16\n\n\nDiferencias de Modelos\n\nanova(m1, m2)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ Sex * Age * Genotype\nModel 2: Weight ~ Sex + Age + Genotype\n  Res.Df    RSS  Df Sum of Sq      F Pr(>F)\n1     36 2.0358                            \n2     52 2.7489 -16   -0.7131 0.7881 0.6883\n\n\nNormalidad en los Residuos\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98321, p-value = 0.5782\n\n\nDistribución de los residuos\n\n\n\nFigure 11.5: Distribución de Residuos Ancova"
  },
  {
    "objectID": "ancova.html#sección-práctica-ancova",
    "href": "ancova.html#sección-práctica-ancova",
    "title": "11  Ancova",
    "section": "11.2 Sección Práctica Ancova",
    "text": "11.2 Sección Práctica Ancova"
  },
  {
    "objectID": "ancova.html#anova-con-parcelas-dividadas",
    "href": "ancova.html#anova-con-parcelas-dividadas",
    "title": "11  Ancova",
    "section": "11.3 ANOVA con parcelas dividadas",
    "text": "11.3 ANOVA con parcelas dividadas\n\n11.3.1 Carga de datos\nTipos de suelo y cosecha (yield) en cultivos\n\ndata <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/splityield.txt',\n                   header = T, stringsAsFactors = TRUE)\n# estructura de los datos\nstr(data)\n\n'data.frame':   72 obs. of  5 variables:\n $ yield     : int  90 95 107 92 89 92 81 92 93 80 ...\n $ block     : Factor w/ 4 levels \"A\",\"B\",\"C\",\"D\": 1 1 1 1 1 1 1 1 1 1 ...\n $ irrigation: Factor w/ 2 levels \"control\",\"irrigated\": 1 1 1 1 1 1 1 1 1 2 ...\n $ density   : Factor w/ 3 levels \"high\",\"low\",\"medium\": 2 2 2 3 3 3 1 1 1 2 ...\n $ fertilizer: Factor w/ 3 levels \"N\",\"NP\",\"P\": 1 3 2 1 3 2 1 3 2 1 ...\n\nsummary(data)\n\n     yield        block      irrigation   density   fertilizer\n Min.   : 60.00   A:18   control  :36   high  :24   N :24     \n 1st Qu.: 86.00   B:18   irrigated:36   low   :24   NP:24     \n Median : 95.00   C:18                  medium:24   P :24     \n Mean   : 99.72   D:18                                        \n 3rd Qu.:114.00                                               \n Max.   :136.00                                               \n\n\nFertilizantes:\n\nN: Nitrogeno\nP: Fósforo\n\n\n\n11.3.2 Modelo ANOVA\n\n# ANOVA normal que hacemos siempre\n\nmodel1 <- aov(yield ~ irrigation*density*fertilizer, data = data)\nsummary(model1)\n\n                              Df Sum Sq Mean Sq F value   Pr(>F)    \nirrigation                     1   8278    8278  59.575 2.81e-10 ***\ndensity                        2   1758     879   6.328  0.00340 ** \nfertilizer                     2   1977     989   7.116  0.00181 ** \nirrigation:density             2   2747    1374   9.885  0.00022 ***\nirrigation:fertilizer          2    953     477   3.431  0.03956 *  \ndensity:fertilizer             4    305      76   0.549  0.70082    \nirrigation:density:fertilizer  4    235      59   0.422  0.79183    \nResiduals                     54   7503     139                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n11.3.3 Modelo ANOVA con declaracion de Error\nSe debe poner los bloques de mayor a menor tamano separados por un parentesis. El tamano mas pequeno no es necesario ponerlo\n(por defecto se sabe que el que no se pone es el ultimo)\n\nmodel2 <- aov(yield ~ irrigation * density * fertilizer  + Error(block / irrigation / density), data = data)\nsummary(model2)\n\n\nError: block\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  194.4   64.81               \n\nError: block:irrigation\n           Df Sum Sq Mean Sq F value Pr(>F)  \nirrigation  1   8278    8278   17.59 0.0247 *\nResiduals   3   1412     471                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: block:irrigation:density\n                   Df Sum Sq Mean Sq F value Pr(>F)  \ndensity             2   1758   879.2   3.784 0.0532 .\nirrigation:density  2   2747  1373.5   5.912 0.0163 *\nResiduals          12   2788   232.3                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n                              Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer                     2 1977.4   988.7  11.449 0.000142 ***\nirrigation:fertilizer          2  953.4   476.7   5.520 0.008108 ** \ndensity:fertilizer             4  304.9    76.2   0.883 0.484053    \nirrigation:density:fertilizer  4  234.7    58.7   0.680 0.610667    \nResiduals                     36 3108.8    86.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n11.3.4 Graficos de interacción\n\n# ver interacciones entre fertilizacion y riego\ninteraction.plot(data$fertilizer, data$irrigation, data$yield)\n\n\n\n# ver interacciones entre densidad y riego\ninteraction.plot(data$density, data$irrigation, data$yield)\n\n\n\n\n\n\n11.3.5 Interacción entre variables\nInteraccion entre variables usando el paquete effects. Se debe usar modelo lm en este caso\n\n# \nlibrary(effects)\n\nLoading required package: carData\n\n\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n\n# hacer un modelo lm. No es necasario los terminos de error, ya que es solo para ver interacciones en un grafico\nmodel2_b <- lm(yield ~ irrigation*density*fertilizer, data = data) # es el mismo que model1, pero con la funcion lm\neffects <- allEffects(model2_b)\nplot(effects)"
  },
  {
    "objectID": "ancova.html#anova-con-muestreo-anidado-bloque",
    "href": "ancova.html#anova-con-muestreo-anidado-bloque",
    "title": "11  Ancova",
    "section": "11.4 ANOVA con muestreo anidado (bloque)",
    "text": "11.4 ANOVA con muestreo anidado (bloque)\n\n11.4.1 Lectura de Datos\n\n## Carga de datos ---------------------------------------------------------\n\ndata <- read.csv('../data/crop.data.csv')\n\nstr(data)\n\n'data.frame':   96 obs. of  4 variables:\n $ density   : int  1 2 1 2 1 2 1 2 1 2 ...\n $ block     : int  1 2 3 4 1 2 3 4 1 2 ...\n $ fertilizer: int  1 1 1 1 1 1 1 1 1 1 ...\n $ yield     : num  177 178 176 178 177 ...\n\n# se fijan, hay tratamientos de fertilizacion 1, 2, 3 en cada bloque\ndata[data$block == 4, ]\n\n   density block fertilizer    yield\n4        2     4          1 177.7036\n8        2     4          1 177.0612\n12       2     4          1 177.0305\n16       2     4          1 176.0084\n20       2     4          1 176.9188\n24       2     4          1 176.8179\n28       2     4          1 177.1649\n32       2     4          1 175.8828\n36       2     4          2 177.3608\n40       2     4          2 177.9980\n44       2     4          2 177.0341\n48       2     4          2 177.1977\n52       2     4          2 176.8191\n56       2     4          2 176.6683\n60       2     4          2 176.8789\n64       2     4          2 177.3526\n68       2     4          3 177.5403\n72       2     4          3 176.4308\n76       2     4          3 177.3442\n80       2     4          3 179.0609\n84       2     4          3 177.7945\n88       2     4          3 177.6328\n92       2     4          3 177.4053\n96       2     4          3 177.1182\n\n\n\n\n11.4.2 one-way ANOVA\n\nsummary(aov(yield ~ fertilizer, data = data))\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer   1   5.74   5.743   14.91 0.000207 ***\nResiduals   94  36.21   0.385                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTukeyHSD(aov(yield ~ as.factor(fertilizer), data = data))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = yield ~ as.factor(fertilizer), data = data)\n\n$`as.factor(fertilizer)`\n         diff         lwr       upr     p adj\n2-1 0.1761687 -0.19371896 0.5460564 0.4954705\n3-1 0.5991256  0.22923789 0.9690133 0.0006125\n3-2 0.4229569  0.05306916 0.7928445 0.0208735\n\n\n\n\n11.4.3 two-way ANOVA\n\nsummary(aov(yield ~ fertilizer + density, data = data))\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer   1  5.743   5.743   17.18 7.49e-05 ***\ndensity      1  5.122   5.122   15.32 0.000173 ***\nResiduals   93 31.089   0.334                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(yield ~ fertilizer * density, data = data))\n\n                   Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer          1  5.743   5.743  17.078  7.9e-05 ***\ndensity             1  5.122   5.122  15.230 0.000181 ***\nfertilizer:density  1  0.150   0.150   0.447 0.505630    \nResiduals          92 30.939   0.336                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n## Agregar bloque ----------------------------------------------------------\nsummary(aov(yield ~ fertilizer + density + block, data = data))\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer   1  5.743   5.743  17.265 7.27e-05 ***\ndensity      1  5.122   5.122  15.397 0.000168 ***\nblock        1  0.486   0.486   1.461 0.229823    \nResiduals   92 30.603   0.333                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# LO IMPORTANTE ACA ES QUE LA IMPORTANCIA DEL BLOQUE ES BAJA. SE LOGRA ELIMINAR SU EFECTO"
  },
  {
    "objectID": "ancova.html#one-way-ancova-1",
    "href": "ancova.html#one-way-ancova-1",
    "title": "11  Ancova",
    "section": "11.5 one-way ANCOVA",
    "text": "11.5 one-way ANCOVA\n\n11.5.1 Cargar Datos\n\n## Carga de datos ----------------------------------------------------------\n\nregrowth <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/ipomopsis.txt',\n                       header = T, stringsAsFactors = TRUE)\nnames(regrowth)\n\n[1] \"Root\"    \"Fruit\"   \"Grazing\"\n\nstr(regrowth)\n\n'data.frame':   40 obs. of  3 variables:\n $ Root   : num  6.22 6.49 4.92 5.13 5.42 ...\n $ Fruit  : num  59.8 61 14.7 19.3 34.2 ...\n $ Grazing: Factor w/ 2 levels \"Grazed\",\"Ungrazed\": 2 2 2 2 2 2 2 2 2 2 ...\n\nlevels(regrowth$Grazing)\n\n[1] \"Grazed\"   \"Ungrazed\"\n\n\n\n\n11.5.2 Ploteo relacion entre variables\n\n# plot de la relacion entre cantidad de fruta, tamano de raiz y clases de riego\nplot(regrowth$Root, regrowth$Fruit, pch = 16 + as.numeric(regrowth$Grazing),\n     col = c(\"blue\", \"red\")[as.numeric(regrowth$Grazing)],\n     xlab = \"Tamaño de la raíz\", ylab = \"Cantidad de fruta\")\nabline(lm(Fruit[Grazing == \"Grazed\"] ~ Root[Grazing == \"Grazed\"], data = regrowth),\n       lty = 2, col = \"blue\")\nabline(lm(Fruit[Grazing == \"Ungrazed\"] ~ Root[Grazing == \"Ungrazed\"], data = regrowth),\n       lty = 2, col = \"red\")\nlegend('topleft', legend = c('Grazed', 'Ungrazed'), lwd = 2, col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n11.5.3 ANOVA\n\nsummary(aov(Fruit ~ Grazing, data = regrowth))\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nGrazing      1   2910  2910.4   5.309 0.0268 *\nResiduals   38  20833   548.2                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n11.5.4 Regresion\n\nsummary(lm(Fruit ~ Root, data = regrowth))\n\n\nCall:\nlm(formula = Fruit ~ Root, data = regrowth)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.3844 -10.4447  -0.7574  10.7606  23.7556 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -41.286     10.723  -3.850 0.000439 ***\nRoot          14.022      1.463   9.584  1.1e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.52 on 38 degrees of freedom\nMultiple R-squared:  0.7073,    Adjusted R-squared:  0.6996 \nF-statistic: 91.84 on 1 and 38 DF,  p-value: 1.099e-11\n\n\n\n\n11.5.5 ANCOCA\n\n# ANCOVA\nancova <- aov(Fruit ~ Root*Grazing, data = regrowth)\n# Root -> variable continua\n# Grazing -> Factor\n\n\n\n11.5.6 Resumen de los Modelos\n\nsummary(ancova)\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot          1  16795   16795 359.968  < 2e-16 ***\nGrazing       1   5264    5264 112.832 1.21e-12 ***\nRoot:Grazing  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(ancova)\n\n\nCall:\naov(formula = Fruit ~ Root * Grazing, data = regrowth)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.3177  -2.8320   0.1247   3.8511  17.1313 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          -125.173     12.811  -9.771 1.15e-11 ***\nRoot                   23.240      1.531  15.182  < 2e-16 ***\nGrazingUngrazed        30.806     16.842   1.829   0.0757 .  \nRoot:GrazingUngrazed    0.756      2.354   0.321   0.7500    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.831 on 36 degrees of freedom\nMultiple R-squared:  0.9293,    Adjusted R-squared:  0.9234 \nF-statistic: 157.6 on 3 and 36 DF,  p-value: < 2.2e-16\n\n\n\n\n11.5.7 Simplificacion del modelo\nAlternativa 1\n\nancova2 <- aov(Fruit ~ Grazing + Root, data = regrowth)\nsummary(ancova2)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)    \nGrazing      1   2910    2910   63.93 1.4e-09 ***\nRoot         1  19149   19149  420.62 < 2e-16 ***\nResiduals   37   1684      46                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAlternativa 2\n\nancova2 <- update(ancova, ~ . - Grazing:Root)\nsummary(ancova2)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot         1  16795   16795   368.9  < 2e-16 ***\nGrazing      1   5264    5264   115.6 6.11e-13 ***\nResiduals   37   1684      46                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComparación de las simplificaciones\n\n# la diferencia es significativa?\n\nanova(ancova, ancova2)\n\nAnalysis of Variance Table\n\nModel 1: Fruit ~ Root * Grazing\nModel 2: Fruit ~ Root + Grazing\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     36 1679.7                           \n2     37 1684.5 -1   -4.8122 0.1031   0.75\n\nAIC(ancova, ancova2) # AIC ancova2 es menor\n\n        df      AIC\nancova   5 273.0135\nancova2  4 271.1279\n\nsummary(ancova2)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot         1  16795   16795   368.9  < 2e-16 ***\nGrazing      1   5264    5264   115.6 6.11e-13 ***\nResiduals   37   1684      46                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(ancova2) \n\n\nCall:\naov(formula = Fruit ~ Root + Grazing, data = regrowth)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1920  -2.8224   0.3223   3.9144  17.3290 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -127.829      9.664  -13.23 1.35e-15 ***\nRoot              23.560      1.149   20.51  < 2e-16 ***\nGrazingUngrazed   36.103      3.357   10.75 6.11e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.747 on 37 degrees of freedom\nMultiple R-squared:  0.9291,    Adjusted R-squared:  0.9252 \nF-statistic: 242.3 on 2 and 37 DF,  p-value: < 2.2e-16\n\n# Intercept es Grazinggrazed (es la primera variable)\n\nEvaluación de Modelos con la función step()\nSe puede hacer una simplificacion de modelos automaticamente tambien usando la funcion step() la funcion es similar a lo que hicimos anteriormente en regresión, prueba todas las combinaicones de terminos y variables\n\n## step() -----------------------------------------------------------------\n\nstep(ancova)\n\nStart:  AIC=157.5\nFruit ~ Root * Grazing\n\n               Df Sum of Sq    RSS    AIC\n- Root:Grazing  1    4.8122 1684.5 155.61\n<none>                      1679.7 157.50\n\nStep:  AIC=155.61\nFruit ~ Root + Grazing\n\n          Df Sum of Sq     RSS    AIC\n<none>                  1684.5 155.61\n- Grazing  1    5264.4  6948.8 210.30\n- Root     1   19148.9 20833.4 254.22\n\n\nCall:\n   aov(formula = Fruit ~ Root + Grazing, data = regrowth)\n\nTerms:\n                     Root   Grazing Residuals\nSum of Squares  16795.002  5264.374  1684.461\nDeg. of Freedom         1         1        37\n\nResidual standard error: 6.747294\nEstimated effects may be unbalanced\n\nancova2 <- step(ancova)\n\nStart:  AIC=157.5\nFruit ~ Root * Grazing\n\n               Df Sum of Sq    RSS    AIC\n- Root:Grazing  1    4.8122 1684.5 155.61\n<none>                      1679.7 157.50\n\nStep:  AIC=155.61\nFruit ~ Root + Grazing\n\n          Df Sum of Sq     RSS    AIC\n<none>                  1684.5 155.61\n- Grazing  1    5264.4  6948.8 210.30\n- Root     1   19148.9 20833.4 254.22\n\nsummary.aov(ancova2)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot         1  16795   16795   368.9  < 2e-16 ***\nGrazing      1   5264    5264   115.6 6.11e-13 ***\nResiduals   37   1684      46                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "ancova.html#ancova-con-dos-factores-y-una-variable-continua",
    "href": "ancova.html#ancova-con-dos-factores-y-una-variable-continua",
    "title": "11  Ancova",
    "section": "11.6 ANCOVA con dos factores y una variable continua",
    "text": "11.6 ANCOVA con dos factores y una variable continua\n\n11.6.1 Cargar los Datos\n\nGain <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/Gain.txt',\n                   header=T, stringsAsFactors = TRUE)\n\nattach(Gain)\n\nThe following objects are masked from Gain (pos = 5):\n\n    Age, Genotype, Score, Sex, Weight\n\nnames(Gain)\n\n[1] \"Weight\"   \"Sex\"      \"Age\"      \"Genotype\" \"Score\"   \n\nstr(Gain)\n\n'data.frame':   60 obs. of  5 variables:\n $ Weight  : num  7.45 8 7.71 8.35 8.45 ...\n $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Age     : int  1 2 3 4 5 1 2 3 4 5 ...\n $ Genotype: Factor w/ 6 levels \"CloneA\",\"CloneB\",..: 1 1 1 1 1 2 2 2 2 2 ...\n $ Score   : num  4 4 4 4 4 5 5 5 5 5 ...\n\n\n\n\n11.6.2 ANCOVA multiple\n\nm1 <- aov(Weight ~ Sex*Age*Genotype) # argumento data no se utiliza\n# Sex -> factor\n# Age -> variable continua\n# Genotype -> factor\n\n\nsummary(m1)\n\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nSex               1  10.37  10.374 183.440 1.06e-15 ***\nAge               1  10.77  10.770 190.450 6.03e-16 ***\nGenotype          5  54.96  10.992 194.371  < 2e-16 ***\nSex:Age           1   0.05   0.049   0.865    0.358    \nSex:Genotype      5   0.15   0.029   0.520    0.760    \nAge:Genotype      5   0.17   0.034   0.595    0.704    \nSex:Age:Genotype  5   0.35   0.070   1.235    0.313    \nResiduals        36   2.04   0.057                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(m1)\n\n\nCall:\naov(formula = Weight ~ Sex * Age * Genotype)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40218 -0.12043 -0.01065  0.12592  0.44687 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 7.80053    0.24941  31.276  < 2e-16 ***\nSexmale                    -0.51966    0.35272  -1.473  0.14936    \nAge                         0.34950    0.07520   4.648 4.39e-05 ***\nGenotypeCloneB              1.19870    0.35272   3.398  0.00167 ** \nGenotypeCloneC             -0.41751    0.35272  -1.184  0.24429    \nGenotypeCloneD              0.95600    0.35272   2.710  0.01023 *  \nGenotypeCloneE             -0.81604    0.35272  -2.314  0.02651 *  \nGenotypeCloneF              1.66851    0.35272   4.730 3.41e-05 ***\nSexmale:Age                -0.11283    0.10635  -1.061  0.29579    \nSexmale:GenotypeCloneB     -0.31716    0.49882  -0.636  0.52891    \nSexmale:GenotypeCloneC     -1.06234    0.49882  -2.130  0.04010 *  \nSexmale:GenotypeCloneD     -0.73547    0.49882  -1.474  0.14906    \nSexmale:GenotypeCloneE     -0.28533    0.49882  -0.572  0.57087    \nSexmale:GenotypeCloneF     -0.19839    0.49882  -0.398  0.69319    \nAge:GenotypeCloneB         -0.10146    0.10635  -0.954  0.34643    \nAge:GenotypeCloneC         -0.20825    0.10635  -1.958  0.05799 .  \nAge:GenotypeCloneD         -0.01757    0.10635  -0.165  0.86970    \nAge:GenotypeCloneE         -0.03825    0.10635  -0.360  0.72123    \nAge:GenotypeCloneF         -0.05512    0.10635  -0.518  0.60743    \nSexmale:Age:GenotypeCloneB  0.15469    0.15040   1.029  0.31055    \nSexmale:Age:GenotypeCloneC  0.35322    0.15040   2.349  0.02446 *  \nSexmale:Age:GenotypeCloneD  0.19227    0.15040   1.278  0.20929    \nSexmale:Age:GenotypeCloneE  0.13203    0.15040   0.878  0.38585    \nSexmale:Age:GenotypeCloneF  0.08709    0.15040   0.579  0.56616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2378 on 36 degrees of freedom\nMultiple R-squared:  0.9742,    Adjusted R-squared:  0.9577 \nF-statistic: 59.06 on 23 and 36 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "ancova.html#evaluación-de-modelo-ancova-multiple",
    "href": "ancova.html#evaluación-de-modelo-ancova-multiple",
    "title": "11  Ancova",
    "section": "11.7 Evaluación de Modelo Ancova Multiple",
    "text": "11.7 Evaluación de Modelo Ancova Multiple\n\n## step() -----------------------------------------------------------------\nm2 <- step(m1)\n\nStart:  AIC=-155.01\nWeight ~ Sex * Age * Genotype\n\n                   Df Sum of Sq    RSS     AIC\n- Sex:Age:Genotype  5   0.34912 2.3849 -155.51\n<none>                          2.0358 -155.01\n\nStep:  AIC=-155.51\nWeight ~ Sex + Age + Genotype + Sex:Age + Sex:Genotype + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Sex:Genotype  5  0.146901 2.5318 -161.92\n- Age:Genotype  5  0.168136 2.5531 -161.42\n- Sex:Age       1  0.048937 2.4339 -156.29\n<none>                      2.3849 -155.51\n\nStep:  AIC=-161.92\nWeight ~ Sex + Age + Genotype + Sex:Age + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Age:Genotype  5  0.168136 2.7000 -168.07\n- Sex:Age       1  0.048937 2.5808 -162.78\n<none>                      2.5318 -161.92\n\nStep:  AIC=-168.07\nWeight ~ Sex + Age + Genotype + Sex:Age\n\n           Df Sum of Sq    RSS      AIC\n- Sex:Age   1     0.049  2.749 -168.989\n<none>                   2.700 -168.066\n- Genotype  5    54.958 57.658    5.612\n\nStep:  AIC=-168.99\nWeight ~ Sex + Age + Genotype\n\n           Df Sum of Sq    RSS      AIC\n<none>                   2.749 -168.989\n- Sex       1    10.374 13.122  -77.201\n- Age       1    10.770 13.519  -75.415\n- Genotype  5    54.958 57.707    3.662\n\nsummary(m2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nSex          1  10.37  10.374   196.2 <2e-16 ***\nAge          1  10.77  10.770   203.7 <2e-16 ***\nGenotype     5  54.96  10.992   207.9 <2e-16 ***\nResiduals   52   2.75   0.053                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(m2)\n\n\nCall:\naov(formula = Weight ~ Sex + Age + Genotype)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40005 -0.15120 -0.01668  0.16953  0.49227 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     7.93701    0.10066  78.851  < 2e-16 ***\nSexmale        -0.83161    0.05937 -14.008  < 2e-16 ***\nAge             0.29958    0.02099  14.273  < 2e-16 ***\nGenotypeCloneB  0.96778    0.10282   9.412 8.07e-13 ***\nGenotypeCloneC -1.04361    0.10282 -10.149 6.21e-14 ***\nGenotypeCloneD  0.82396    0.10282   8.013 1.21e-10 ***\nGenotypeCloneE -0.87540    0.10282  -8.514 1.98e-11 ***\nGenotypeCloneF  1.53460    0.10282  14.925  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2299 on 52 degrees of freedom\nMultiple R-squared:  0.9651,    Adjusted R-squared:  0.9604 \nF-statistic: 205.7 on 7 and 52 DF,  p-value: < 2.2e-16\n\nanova(m1, m2)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ Sex * Age * Genotype\nModel 2: Weight ~ Sex + Age + Genotype\n  Res.Df    RSS  Df Sum of Sq      F Pr(>F)\n1     36 2.0358                            \n2     52 2.7489 -16   -0.7131 0.7881 0.6883\n\nAIC(m1, m2)\n\n   df       AIC\nm1 25 17.265355\nm2  9  3.283978\n\n\n\n11.7.1 Normalidad de residuos\n\n# shapiro test de normalidad en los residuos\n\nshapiro.test(m2$residuals) # son normales\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98321, p-value = 0.5782\n\npar(mfrow = c(2, 2))\nplot(m2)\n\n\n\ndev.off()\n\nnull device \n          1 \n\n\n\n\n11.7.2 Visualización relación entre variables\nGráfico de las relaciones entre peso y edad en relacion a las clases de genotipo.\n\nplot(Age, Weight, type = \"n\")\ncolours <- c(\"green\", \"red\", \"black\", \"blue\")\nlines <- c(1, 2)\nsymbols <- c(16, 17)\npoints(Age, Weight, pch = symbols[as.numeric(Sex)],\n       col = colours[as.numeric(Genotype)])\nxv <- c(1, 5)\n\nfor (i in 1:2) {\n  for (j in 1:4) {\n    a <- coef(m2)[1]+(i>1)* coef(m2)[2]+(j>1)*coef(m2)[j+2]\n    b <- coef(m2)[3]\n    yv <- a+b*xv\n    lines(xv,yv,lty=lines[i],col=colours[j]) } }"
  },
  {
    "objectID": "non_params.html",
    "href": "non_params.html",
    "title": "12  Est. No Paramétrica",
    "section": "",
    "text": "Existe un amplio conjunto de métodos estadísticos que no requieren la estimación de los parámetros de la población (ej., X, S) y que prueban hipótesis que no son afirmaciones sobre los parámetros de la población. Estos procedimientos estadísticos se denominan pruebas no paramétricas.\nAunque pueden suponer que las poblaciones muestreadas tienen la misma dispersión o forma, los métodos no paramétricos no suelen hacer suposiciones sobre la naturaleza de las distribuciones de las poblaciones (por ejemplo, no hay suposición de normalidad)\n¡Tanto las pruebas paramétricas como las no paramétricas requieren que los datos procedan al azar de las poblaciones muestreadas!\nLas pruebas no paramétricas pueden aplicarse generalmente a cualquier situación en la que estaría justificado emplear una prueba paramétrica. Los tests paramétricos son generalmente más potentes: método paramétrico tendrá normalmente una menor probabilidad de cometer un error de tipo II). Sin embargo, a menudo la diferencia de potencia no es grande y puede compensarse con un pequeño aumento del tamaño de la muestra para la prueba no paramétrica.\nCuando los supuestos subyacentes de una prueba paramétrica se violan gravemente, entonces la contraparte no paramétrica puede ser decididamente más potente.\nLa mayoría de las técnicas estadísticas no paramétricas convierten los datos observados en los rangos de los datos (es decir, su orden numérico).\nPor ejemplo, las medidas de 2,1, 2,3, 2,9 3,6 y 4,0 kg se analizarían mediante sus rangos de 1, 2, 3, 4 y 5. Una posible desventaja de esta transformación de los datos en rangos es que se pierde algo de información (por ejemplo, los mismos rangos resultan de las mediciones de 1,1, 1,3, 2,9, 4,6 y 5,0 kg).\nUna posible ventaja es que los valores atípicos (outliars) tendrán mucha menos influencia (por ejemplo, los mismos rangos resultan de mediciones de 2,1,2,3 2,9,3,6 y 25,0 kg)."
  },
  {
    "objectID": "non_params.html#two-sample-rank-testing",
    "href": "non_params.html#two-sample-rank-testing",
    "title": "12  Est. No Paramétrica",
    "section": "12.1 Two-sample Rank Testing",
    "text": "12.1 Two-sample Rank Testing\nComparar las tendencias centrales de dos poblaciones (es decir, ubicaciones en la escala de medición) cuando los supuestos subyacentes de la prueba t no se cumplen.\nLa prueba de este tipo que se emplea con más frecuencia es la que propuso originalmente, para para tamaños de muestra iguales, por Wilcoxon (1945) e independientemente presentada por Mann y Whitney (1947), para n’s iguales o desiguales. Se denomina prueba de Wilcoxon-Mann-Whitney o, más comúnmente, prueba de Mann-Whitney.\nMann-Whitney: Para esta prueba, como para muchos otros procedimientos no paramétricos, no se emplean las medidas reales, sino que se utilizan los rangos de de las mediciones.\n\n\n\nFigure 12.3: Two-sample Rank Testing en R"
  },
  {
    "objectID": "non_params.html#análisis-de-varianza-no-paramétrico",
    "href": "non_params.html#análisis-de-varianza-no-paramétrico",
    "title": "12  Est. No Paramétrica",
    "section": "12.2 Análisis de varianza no paramétrico",
    "text": "12.2 Análisis de varianza no paramétrico\nSi un conjunto de datos se recoge de acuerdo con un diseño completamente aleatorio en el que k > 2, es posible realizar una prueba no paramétrica de las diferencias entre grupos. Esto puede hacerse mediante la prueba de Kruskal-Wallis (Kruskal y Wallis, 1952).\nEsta prueba puede utilizarse en cualquier situación en la que sea aplicable el ANOVA paramétrico de un solo factor (utilizando F).\nTambién puede emplearse en casos en los que no se puede aplicar ANOVA. El análisis no paramétrico es especialmente deseable cuando las muestras k no proceden de poblaciones normales.\nComo ANOVA, la prueba de Kruskal-Wallis tiende a ser más potente con tamaños de muestra más grandes, y la potencia es menor cuando los n’s no son iguales, especialmente si las medias grandes están asociadas con los n’s pequeños (Boehnke, 1984).\nBoehnke (1984) desaconseja el uso de la prueba de Kruskal-Wallis a menos que N > 20\n\n\n\nFigure 12.4: Test de Kruskal test en R\n\n\n\n\n\nFigure 12.5: Comparación de Clases control y tratamientos\n\n\n\n12.2.1 Post-Hoc tests:\nEn Kruskal-Wallis no se pueden usar los mismos Post-Hoc test que en ANOVA, ej., TukeyHSD.\nPero se puede hacer un test de pares con el mismo Wilcox.test:\n\n\n\nFigure 12.6: Wilcox.test"
  },
  {
    "objectID": "non_params.html#datos-pareados",
    "href": "non_params.html#datos-pareados",
    "title": "12  Est. No Paramétrica",
    "section": "12.3 Datos pareados",
    "text": "12.3 Datos pareados\nEl test de Friedman es la alternativa no paramétrica a la prueba ANOVA de una vía cuando los datos son dependientes (pareados). Se trata de una extensión de la prueba de los rangos con signo de Wilcoxon para más de dos grupos (basada en suma de rangos). Asumiendo ciertas simplificaciones, puede considerarse como una comparación entre las medianas de varios grupos.\nEl test de Friedman es el test adecuado cuando los datos tienen un orden natural, (cuando para darles sentido tienen que estar ordenados) y además son pareados.\nPor ejemplo, si se quiere estudiar la diferencia en el rendimiento de un grupo de corredores dependiendo de la estación del año, se hace correr al mismo grupo de personas una vez en cada estación. Como resultado, se puede disponer de dos tipos de datos: los tiempos de cada participante (análisis con ANOVA pareado) o las posiciones en las que han terminado la carrera cada participante en cada una de las carreras (análisis con Friedman test)."
  },
  {
    "objectID": "non_params.html#datos-pareados-y-two-way-variance",
    "href": "non_params.html#datos-pareados-y-two-way-variance",
    "title": "12  Est. No Paramétrica",
    "section": "12.4 Datos pareados y two-way variance",
    "text": "12.4 Datos pareados y two-way variance\nEl test de Friedman genera un estadístico conocido como Fr o Q que se distribuye:\nSi el número total de individuos (N) es mayor de 10, la distribución de Fr se aproxima a una distribución χ2 con k−1 grados de libertad (siendo k el número de grupos a comparar).\nSi el número de individuos es menor de 10, se recurre a tablas con los valores de significancia para un test de Friedman.\nPost-Hoc: los más comunes son:\nTest de rangos con signo de Wilcoxon entre cada par de grupos con corrección de significancia pairwise.wilcox.test( paried = TRUE ).\nTukey’s range test: en R existe la función friedmanmc() del paquete pgirmess.\n\n\n\nFigure 12.7: Datos pareados y two-way variance, Friedman.test Wilcox.test en R\n\n\n\n\n\nFigure 12.8: Visualizacióin de Friedman-test"
  },
  {
    "objectID": "non_params.html#ajustar-curvas-no-paramétricas-en-scatterplots",
    "href": "non_params.html#ajustar-curvas-no-paramétricas-en-scatterplots",
    "title": "12  Est. No Paramétrica",
    "section": "12.5 Ajustar curvas no-paramétricas en scatterplots",
    "text": "12.5 Ajustar curvas no-paramétricas en scatterplots\nEs común querer ajustar una curva suavizada no paramétrica a través de los datos, especialmente cuando no hay un candidato obvio para una función paramétrica. R ofrece una serie de opciones:\n\nlowess (un ﬁtador de curvas no paramétrico);\nloess (una herramienta de modelización);\ngam (ajusta modelos aditivos generalizados);\nlm para la regresión polinómica (ﬁt un modelo lineal que implica potencias de x).\n\n\n\n\nFigure 12.9: Diferentes tipos de ajustes de curvas de distribución\n\n\nR: Como es una función incorporada y no requiere que se cargue ningún paquete externo, loess (arriba a la derecha) es una buena opción; tiene un ajuste razonable, y no es demasiado curvado. Primero se ajusta un modelo de regresión, y luego utiliza predict con un vector de valores especificado para la variable explicativa, y luego dibuja la curva utilizando líneas.\n\nplot(age, bone, pch=16, main=\"loess\")\nmodel <- loess(bone ~ age)\nxv <- 0:50\nyv <- predict(model, data.frame(age=xv))\nlines(xv, yv, col=\"red\")"
  },
  {
    "objectID": "non_params.html#regresiones-no-paramétricas",
    "href": "non_params.html#regresiones-no-paramétricas",
    "title": "12  Est. No Paramétrica",
    "section": "12.6 Regresiones No Paramétricas",
    "text": "12.6 Regresiones No Paramétricas\nAsí como se puede utilizar la función lm para ajustar regresiones lineales Gaussianos, GLM para ajustar regresiones lineales no Gaussianos, se puede usar modelos GAM para ajustar regresiones no-lineales y no-paramétricas, que es son los modelos GAM?\n\nGAM:\n\nGeneralized Additive Models → similar al concepto de GLM que vimos en regresiones, pero con relaciones no-lineales y no-paramétricas. Los GAM permiten suavizadores no-paramétricos además de las formas paramétricas. Utilizan las mismas familias de GLM (binomial, poisson, Gamma, etc).\n\n\nSe puede predecir y con una variable continua x de forma paramétrica, como GLM, usando:\ny \\sim x\nO usando suavizadores no-paramétricos (smoothers) usando s(x):\ny \\sim s(x)\nO una combinación:\ny \\sim x1 + s(x_2)\nO términos que interaccionan entre sí:\nY \\sim s(x_1) + s(x_2) + s(x_1, x_2)"
  },
  {
    "objectID": "non_params.html#non-parametric-smoothers",
    "href": "non_params.html#non-parametric-smoothers",
    "title": "12  Est. No Paramétrica",
    "section": "12.7 Non-parametric smoothers",
    "text": "12.7 Non-parametric smoothers\nAquí nos ocupamos de la utilización de suavizadores no paramétricos en la modelación estadística, cuyo objetivo es evaluar los méritos relativos de una serie de modelos diferentes para explicar la variación de la variable de respuesta. Una de las funciones de ajuste de modelos más sencillas es loess\nEl siguiente ejemplo muestra el cambio de la población:\nDelta =log\\left(\\frac{N(t + 1)}{N(t)}\\right)\nEn función de la densidad de población (N(t)) en una investigación de la dependencia de la densidad en una población de ovejas.\n\n\n\nFigure 12.10: Distribución del cambio cambio de la población (Delta) en función de la densidad de la población N(t)\n\n\nEl cambio de la población es positivo a bajas densidades Delta > 0 y negativo a altas densidades Delta < 0, pero hay una gran dispersión, y no evidente qué forma de función describiría mejor los datos. Aquí está el loess por defecto:\n\n\n\nFigure 12.11: Evaluación del Modelo loess.\n\n\n\n\n\nFigure 12.12: Plot de Evaluación del Modelo loess.\n\n\nComparar múltiples datos al mismo tiempo con la función pairs. Usemos de ejemplo con mediciones de radiación, velocidad de viento, y concentraciones de ozono:\n\npairs(ozone.data, \n      panel=function(x,y) { points(x,y); lines(lowess(x,y))} )\n\n\n\n\nFigure 12.13: Comparar múltiples datos al mismo tiempo con la función pairs\n\n\nAjustamos un modelo GAM para predecir la concentración de ozono usando predictores suavizados:\n\n\n\nFigure 12.14: Ejecución en R modelo GAM para predecir la concentración de ozono usando predictores suavizados\n\n\nNótese que el intercepto se estima como un coeficiente paramétrico (42,10; tabla superior) y las tres variables explicativas se ajustan como términos suavizados. Las tres son signiﬁcantes, pero la radiación es la menos signiﬁcante con p = 0,00736**.\nPodemos comparar un GAM con y sin un término para la radiación utilizando el ANOVA de la forma normal:\n\n\n\nFigure 12.15: Ejecución en R de comparación un GAM con y sin un término para la radiación utilizando el ANOVA de la forma normal\n\n\nRadiación debe permanecer en el modelo! Aporta información significativa. Podemos ver ahora si variables como temperatura y viento interaccionan entre si usando s(wind, temp):\n\n\n\nFigure 12.16: Ejecución en R de interacción de temperatura y viento entre si usando s(wind, temp)\n\n\nLa interacción parece ser muy signiﬁcativa, pero el efecto principal de la temperatura se anula. Podemos inspeccionar el ajuste del modelo3 así:\n\npar(mfrow=c(2,2))\nplot(model3, residuals=T, pch=1)\n\n\n\n\nFigure 12.17: Visualización de ajuste de modelo 3\n\n\n\nLas figuras muestran las relaciones de las variables lineales con su versión s(x).\nY la interacción al final, la cual muestra relaciones complejas.\nLas líneas punteadas son las desviación estándar, +- 1sdt"
  },
  {
    "objectID": "non_params.html#análisis-de-covarianza-no-paramétrico-o-con-función-de-distribución-específica",
    "href": "non_params.html#análisis-de-covarianza-no-paramétrico-o-con-función-de-distribución-específica",
    "title": "12  Est. No Paramétrica",
    "section": "12.8 Análisis de Covarianza no-paramétrico o con función de distribución específica",
    "text": "12.8 Análisis de Covarianza no-paramétrico o con función de distribución específica\nAsí como se puede hacer un ANCOVA linear usando la función lm envés de aov, se puede hacer un ANCOVA no-paramétrico y no-lineal con GAM y lineal con GLM (GAM NO permite experimento factorial)\nVeamos un ejemplo donde la variable respuesta es el número de especies (riqueza; números enteros positivos) en áreas con distinta biomasa (números continuos positivos) y con diferentes pH (3 clases). Como la variable y es riqueza, vamos a usar la familia de distribución de Poisson.\n\n\n\nFigure 12.18: ANCOVA no-paramétrico y no-lineal con GAM\n\n\nEstá claro que las especies disminuyen con la biomasa, y que el pH del suelo tiene un gran efecto sobre las especies, pero ¿la pendiente de la relación entre las especies y la biomasa depende del pH?\n\n\n Ejecución en R de Modelo GLM. Las relaciones se ven lineales a priori, así que usamos GLM con la familia poisson.\nFigure 12.19: ?(caption)\n\n\nVersión no paramétrica con GAM. Básicamente da =, ya que las relaciones no mostraban no-linealidades desde el principio. Quedarse entonces con el modelo más simple = lineal.\n\nmodel3 <- gam(Species~ s(Biomass) + pH, poisson)\nsummary(model3)\n\n\n\n Versión no paramétrica con GAM\nFigure 12.20: ?(caption)"
  },
  {
    "objectID": "non_params.html#transformación-de-datos",
    "href": "non_params.html#transformación-de-datos",
    "title": "12  Est. No Paramétrica",
    "section": "12.9 Transformación de datos",
    "text": "12.9 Transformación de datos\nEnvés de usar modelos no-lineales, se pueden transformar los datos para obtener mejor linealidad entre sus relaciones entre las variables respuesta y predictivas. Las transformaciones más utilizadas son:\n\nlog(y) frente a x para relaciones exponenciales\nlog(y) contra log(x) para funciones de potencia;\nexp(y) contra x para relaciones logarítmicas;\n1/y contra 1/x para las relaciones asintóticas;\nlog(p/(1 - p)) contra x para datos de proporción.\n\nOtras transformaciones son útiles para la estabilización de la varianza:\n\nsqrt(y) para estabilizar la varianza para datos de recuento;\narcsin(y) para estabilizar la varianza de los datos de porcentaje."
  },
  {
    "objectID": "non_params.html#parte-práctica",
    "href": "non_params.html#parte-práctica",
    "title": "12  Est. No Paramétrica",
    "section": "12.10 Parte Práctica",
    "text": "12.10 Parte Práctica\nImportar data\n\ndata1 <- read.table(\n  'https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/gardens.txt',\n  header = T,\n  stringsAsFactors = TRUE\n)\n\nhead(data1)\n\n  gardenA gardenB gardenC\n1       3       5       3\n2       4       5       3\n3       4       6       2\n4       3       7       1\n5       2       4      10\n6       3       4       4\n\n\nComparacion de variables\n\n# gardenA vs gardenB\nboxplot(data1$gardenA, data1$gardenB, notch = TRUE, ylab = 'Ozono', xlab = \"Garden\")\n\n\n\n# distribucion de los datos\nhist(data1$gardenC)\n\n\n\n\n\n12.10.1 T-Student (Paramétrico)\n\n# Diferencias entre muestras de ozono usando el test parametrico t test\nt.test(data1$gardenA, data1$gardenB) # cual es el valor de p?\n\n\n    Welch Two Sample t-test\n\ndata:  data1$gardenA and data1$gardenB\nt = -3.873, df = 18, p-value = 0.001115\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.0849115 -0.9150885\nsample estimates:\nmean of x mean of y \n        3         5 \n\n\n\n\n12.10.2 Wilcoxon rank-sum test (No Paramétrico)\n\nwilcox.test(data1$gardenA, data1$gardenB)\n\nWarning in wilcox.test.default(data1$gardenA, data1$gardenB): cannot compute\nexact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  data1$gardenA and data1$gardenB\nW = 11, p-value = 0.002988\nalternative hypothesis: true location shift is not equal to 0\n\n\nEsta es una alternativa no parametrica a la prueba t de Student, que podriamos usar si los errores no fueran normales. El test de Wilcoxon rank-sum, W La funcion utiliza un algoritmo de aproximacion normal para calcular un valor z y, a partir de este, un valor p para evaluar la hipotesis de que las dos medias son iguales. Este valor p de 0,002988 es mucho menor que 0,05, por lo que se rechazar la hipotesis nula y concluimos que las concentraciones medias de ozono en los jardines A y B son significativamente diferente. El mensaje de advertencia al final llama la atencion sobre el hecho de que hay correlacion en los datos (repeticiones de la misma medida de ozono), y esto significa que el valor p no se puede calcular exactamente (esto rara vez es preocupacion). Es interesante comparar los valores de p de la prueba t y la prueba de Wilcoxon con los mismos datos:\nT-Student:\n\np = 0.001115\n\nPrueba Wilcox:\n\np = 0.002988\n\nLa prueba no parametrica es mucho mas apropiada que la prueba t cuando los errores no son normales, y la prueba no parametrica es aproximadamente un 95% tan poderosa con errores normales, y puede ser mas mas potente que la prueba t si la distribucion esta fuertemente sesgada por la presencia de valores atipicos. Tipicamente, como aqui, La prueba t dara el valor p mas bajo, por lo que se dice que la prueba de Wilcoxon es conservadora: si una diferencia es significativa bajo una prueba de Wilcoxon seria aun mas significativo bajo una prueba t.\n\n\n12.10.3 Tests on paired samples\nA veces, los datos de dos muestras provienen de observaciones emparejadas. En este caso, podriamos esperar una correlacion entre las dos mediciones, porque se realizaron en el mismo individuo o se tomaron de la misma ubicacion.\nImportar data\nLos siguientes datos son una puntuacion de biodiversidad compuesta basada en una muestra de invertebrados acuaticos. Los elementos estan emparejados porque las dos muestras fueron tomadas en el mismo rio, una aguas arriba y otra aguas abajo del mismo canal de aguas residuales\n\nstreams <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/streams.txt',\n                      header = T, stringsAsFactors = TRUE)\n\nhead(streams)\n\n  down up\n1   20 23\n2   15 16\n3   10 10\n4    5  4\n5   20 22\n6   15 15\n\n\nComparacion de variables\n\nboxplot(streams$down, streams$up, notch = TRUE) # es correcto?\n\n\n\n\nAsumiendo independencia\n\nt.test(streams$down, streams$up) # p = 0.6856\n\n\n    Welch Two Sample t-test\n\ndata:  streams$down and streams$up\nt = -0.40876, df = 29.755, p-value = 0.6856\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.248256  3.498256\nsample estimates:\nmean of x mean of y \n   12.500    13.375 \n\nwilcox.test(streams$down, streams$up) # p = 0.5559\n\nWarning in wilcox.test.default(streams$down, streams$up): cannot compute exact\np-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  streams$down and streams$up\nW = 112, p-value = 0.5559\nalternative hypothesis: true location shift is not equal to 0\n\n\nAsumiendo que son datos pareados\n\nt.test(streams$down, streams$up, paired = TRUE) # p = 0.0081\n\n\n    Paired t-test\n\ndata:  streams$down and streams$up\nt = -3.0502, df = 15, p-value = 0.0081\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.4864388 -0.2635612\nsample estimates:\nmean of the differences \n                 -0.875 \n\nwilcox.test(streams$down, streams$up, paired = TRUE) # p = 0.01406\n\nWarning in wilcox.test.default(streams$down, streams$up, paired = TRUE): cannot\ncompute exact p-value with ties\n\n\nWarning in wilcox.test.default(streams$down, streams$up, paired = TRUE): cannot\ncompute exact p-value with zeroes\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  streams$down and streams$up\nV = 8, p-value = 0.01406\nalternative hypothesis: true location shift is not equal to 0\n\n\nKruskal-Wallis test\nResultados de un experimento para comparar rendimientos (medidos por el peso seco de las plantas) obtenido bajo un control y dos condiciones de tratamiento diferentes.\nImportar data\n\n# dataset = PlantGrowth.csv\nmy_data <- read.csv(\"data/PlantGrowth.csv\", stringsAsFactors = TRUE)\n\nhead(my_data)\n\n  weight group\n1   4.17  ctrl\n2   5.58  ctrl\n3   5.18  ctrl\n4   6.11  ctrl\n5   4.50  ctrl\n6   4.61  ctrl\n\n# str(my_data)\n\n# group levels\nlevels(my_data$group)\n\n[1] \"ctrl\" \"trt1\" \"trt2\"\n\n\nVisualizacion\n\n# no es necesario usar esta libreria, es solo un ejemplo mas bonito\n\n\nlibrary(ggpubr)\nlibrary(rstatix)\nggboxplot(my_data, x = \"group\", y = \"weight\", \n          color = \"group\", palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n          order = c(\"ctrl\", \"trt1\", \"trt2\"),\n          ylab = \"Weight\", xlab = \"Treatment\")\n\n\n\nggline(my_data, x = \"group\", y = \"weight\", \n       color = \"group\", palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n       add = c(\"mean_se\", \"jitter\"), add.params = list(size = 2, alpha = 0.2),\n       order = c(\"ctrl\", \"trt1\", \"trt2\"),\n       ylab = \"Weight\", xlab = \"Treatment\")\n\n\n\n\nComparacion de los tratamientos\n\nsummary(aov(weight ~ group, data = my_data)) # p = 0.0159\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ngroup        2  3.766  1.8832   4.846 0.0159 *\nResiduals   27 10.492  0.3886                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nkruskal.test(weight ~ group, data = my_data) # p = 0.01842\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  weight by group\nKruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842\n\n\nComo el valor p es menor que el nivel de significancia 0.05, podemos concluir que existen diferencias significativas entre los grupos de tratamiento.\nMultiple pairwise-comparison between groups\nA partir del resultado de la prueba de Kruskal-Wallis, sabemos que existe una diferencia entre grupos, pero no sabemos que pares de grupos son diferentes. Es posible usar la funcion pairwise.wilcox.test() para calcular por pares comparaciones entre niveles de grupo con correcciones para pruebas multiples.\n\n# ?pairwise.wilcox.test\n\npairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,\n                     p.adjust.method = \"bonf\")\n\nWarning in wilcox.test.default(xi, xj, paired = paired, ...): cannot compute\nexact p-value with ties\n\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  PlantGrowth$weight and PlantGrowth$group \n\n     ctrl  trt1 \ntrt1 0.596 -    \ntrt2 0.189 0.027\n\nP value adjustment method: bonferroni \n\n\nLa comparacion por pares muestra que solo trt1 y trt2 son significativamente diferentes (p < 0.05).\n\n\n12.10.4 Friedman test\nImportar data\nUsaremos el conjunto de datos de puntaje de autoestima medido en tres puntos de tiempo.Los datos estan disponibles en el paquete datarium.\n\n# dataset = selfesteem.csv\n\nselfesteem <- read.csv(\"data/selfesteem.csv\", stringsAsFactors = TRUE)\n\nhead(selfesteem)\n\n  id time    score\n1  1   t1 4.005027\n2  2   t1 2.558124\n3  3   t1 3.244241\n4  4   t1 3.419538\n5  5   t1 2.871243\n6  6   t1 2.045868\n\n# str(selfesteem)\n\n# trasnfromar id a factor\nselfesteem$id = as.factor(selfesteem$id)\n\n\n# vamos a probar los test que vienen dentro de R basico y \n# de un paquete que se llama rstatix\n\n\nggboxplot(selfesteem, x = \"time\", y = \"score\", add = \"jitter\")\n\n\n\n\n\n## Comparacion de Friedman test, de dos paquetes distintos --------------\n### Basico ------------------------------------------------------------------\n\nfriedman.test(score ~ time | id, data=selfesteem) # p = 0.0001117\n\n\n    Friedman rank sum test\n\ndata:  score and time and id\nFriedman chi-squared = 18.2, df = 2, p-value = 0.0001117\n\n\n\n### rstatix -----------------------------------------------------------------\n\nres.fried <- friedman_test(score ~ time | id, data=selfesteem)\nres.fried # p = 0.000112\n\n# A tibble: 1 × 6\n  .y.       n statistic    df        p method       \n* <chr> <int>     <dbl> <dbl>    <dbl> <chr>        \n1 score    10      18.2     2 0.000112 Friedman test\n\n\nComparacion de Wilcoxon test, de dos paquetes distintos\nBasico\n\npairwise.wilcox.test(selfesteem$score, selfesteem$time, paired = TRUE, \n                     p.adjust.method = \"bonf\")\n\n\n    Pairwise comparisons using Wilcoxon signed rank exact test \n\ndata:  selfesteem$score and selfesteem$time \n\n   t1     t2    \nt2 0.0059 -     \nt3 0.0059 0.0117\n\nP value adjustment method: bonferroni \n\n\nrstatix\n\npwc <- wilcox_test(score ~ time, paired = TRUE, p.adjust.method = \"bonferroni\"\n                   , data=selfesteem)\npwc\n\n# A tibble: 3 × 9\n  .y.   group1 group2    n1    n2 statistic     p p.adj p.adj.signif\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl> <dbl> <chr>       \n1 score t1     t2        10    10         0 0.002 0.006 **          \n2 score t1     t3        10    10         0 0.002 0.006 **          \n3 score t2     t3        10    10         1 0.004 0.012 *           \n\n# agregar coordenadas y posiciones de los valores. Solo necesario para hacer graficos\npwc = add_xy_position(pwc, x = \"time\")\npwc\n\n# A tibble: 3 × 13\n  .y.   group1 group2    n1    n2 statistic     p p.adj p.adj.s…¹ y.pos…² groups\n  <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl> <dbl> <chr>       <dbl> <name>\n1 score t1     t2        10    10         0 0.002 0.006 **           10.5 <chr> \n2 score t1     t3        10    10         0 0.002 0.006 **           11.5 <chr> \n3 score t2     t3        10    10         1 0.004 0.012 *            12.5 <chr> \n# … with 2 more variables: xmin <dbl>, xmax <dbl>, and abbreviated variable\n#   names ¹​p.adj.signif, ²​y.position\n\n\n\nggboxplot(selfesteem, x = \"time\", y = \"score\", add = \"point\") +\n  stat_pvalue_manual(pwc, hide.ns = TRUE) +\n  labs(\n    subtitle = get_test_label(res.fried,  detailed = TRUE),\n    caption = get_pwc_label(pwc)\n  )\n\n\n\n\n\n## Plot --------------------------------------------------------------------\n# Funcion para exportar el plot como svg. Despues de usarla, se debe \n# correr el plot y para finalizar la exportacion, debemos aplicar el\n# dev.off()\n\nsvg('plot.svg', width = 8, height = 8) \n\nplot_box <- ggboxplot(selfesteem, x = \"time\", y = \"score\", add = \"point\") +\n  stat_pvalue_manual(pwc, hide.ns = TRUE) +\n  labs(\n    subtitle = get_test_label(res.fried,  detailed = TRUE),\n    caption = get_pwc_label(pwc)\n  )\n\ndev.off()\n\n# para visualizarlo\nplot_box"
  },
  {
    "objectID": "multivariante.html",
    "href": "multivariante.html",
    "title": "13  Estadísticas Multivariante",
    "section": "",
    "text": "El mundo en el que vivimos no es de una sola dimensión, es multivariante, con múltiples dimensiones, con muchos datos cruzándose todo el tiempo y con medidas de más de una variable aleatoria.\nHay dos aplicaciones típicas de este tipo de estadística:\nPero hay muchas más."
  },
  {
    "objectID": "multivariante.html#la-dimensionalidad",
    "href": "multivariante.html#la-dimensionalidad",
    "title": "13  Estadísticas Multivariante",
    "section": "13.1 La Dimensionalidad",
    "text": "13.1 La Dimensionalidad\nLa maldición de la dimensionalidad\n\nUna cantidad correcta de atributos ayudan a crear mejores modelos.\nLos datos de altas dimensiones se vuelven cada vez más dispersos en su espacio.\nLas definiciones de densidad y distancia entre puntos se vuelven menos significativas a mayor numero de atributos.\n\n\n\n\nLa Maldición de la dimensionalidad"
  },
  {
    "objectID": "multivariante.html#análisis-exploratorio-de-datos-eda",
    "href": "multivariante.html#análisis-exploratorio-de-datos-eda",
    "title": "13  Estadísticas Multivariante",
    "section": "13.2 Análisis exploratorio de datos (EDA)",
    "text": "13.2 Análisis exploratorio de datos (EDA)\nAnálisis del conjunto de datos para resumir sus principales características, mediante métodos estadísticos y visuales.\n\n13.2.1 Objetivos EDA:\n\nDescubrir la estructura subyacente de los datos\nIdentificar variables relevantes Detectar valores atípicos y anomalías Validar supuestos\nGenerar hipótesis a partir de los datos\n\n\n\n\nEjemplo de Análisis exploratorio de datos (EDA)"
  },
  {
    "objectID": "multivariante.html#definición-de-ingeniería-de-atributos",
    "href": "multivariante.html#definición-de-ingeniería-de-atributos",
    "title": "13  Estadísticas Multivariante",
    "section": "13.3 Definición de Ingeniería de Atributos",
    "text": "13.3 Definición de Ingeniería de Atributos\n\nSelección de atributos:\n\nSelección de un subconjunto de atributos según algún criterio específico.\n\n\n\n\n\nSelección de atributos\n\n\n\nExtracción de atributos:\n\nCreación de nuevos atributos a partir de atributos originales\n\n\n\n\n\nExtracción de atributos\n\n\nPueden hacerse con conocimiento del dominio o algorítmicamente"
  },
  {
    "objectID": "multivariante.html#medidas-de-distancia",
    "href": "multivariante.html#medidas-de-distancia",
    "title": "13  Estadísticas Multivariante",
    "section": "13.4 Medidas de distancia",
    "text": "13.4 Medidas de distancia\nUna métrica que mide la distancia entre un par de entidades dados los dos puntos x e y, una función métrica o de distancia debe cumplir las siguientes condiciones:\n\nTabla de Condiciones de Distancias\n\n\nNombre Condición\nCondición\n\n\n\n\nNo negatividad\nd(x,y) >0\n\n\nIdentidad\nd(x,y)=0 <=> x=y\n\n\nSimetría\nd(x,y)=d(y,x)\n\n\nDesigualdad triangular\nd(x,z) <= d(x,y)+d(y,z)\n\n\n\nTodos los métodos de clustering y ordination tienen una cosa en común, para poder llevar a cabo las agrupaciones necesitan definir y cuantificar la similitud entre las observaciones. El término distancia se emplea para cuantificar la similitud (o disimilitud; dissimilarity) entre observaciones.\nSe calcula la “distancia” en una matriz de todos contra todos.\n\n\n\nMatriz de Distancias\n\n\n\n\n\nMatriz de Disimilitud\n\n\nSi se representan las observaciones en un espacio p dimensional, siendo p el número de variables asociadas a cada observación, cuanto más se asemeje dos observaciones, más próximas estarán. Por eso se emplea el término distancia. La característica que hace del clustering y ordenación métodos adaptables a escenarios muy diversos es que puede emplear cualquier tipo de distancia, lo que permite al investigador escoger la más adecuada para el estudio en cuestión. A continuación, se describen algunas de las más utilizadas.\n\n\n\nTipos de Distancias\n\n\n\n13.4.1 Distancia euclidiana\nSe desprende del teorema de Pitágoras\n\n\n\nDistancia Euclediana\n\n\nd_E(P_1, P_2)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\n\nPara: variables continuas con distribución cercana a la normal\n\n\n\n13.4.2 Distancia Manhattan\nDistancia entre dos puntos como la sumatoria de las diferencias absolutas entre cada dimensión. Esta medida se ve menos afectada por outliers (es más robusta) que la distancia euclidiana debido a que no eleva al cuadrado las diferencias.\n\nPara: variables continuas, no normales y con posibles outliars\n\n\n\n13.4.3 Índice de Jaccard\nCuando las variables con las que se pretende determinar la similitud entre observaciones son de tipo binario, a pesar de que es posible codificarlas de forma numérica como 1 o 0, no tiene sentido aplicar operaciones aritméticas sobre ellas (media, suma…)\n\nPara: variables binarias\n\n\n\n13.4.4 Distancia Bray-Curtis\nLa distancia Bray-Curtis se refiere a la diferencia total en la abundancia de especies entre dos sitios, dividido para la abundancia total en cada sitio.\nLa ecuación que permite el cálculo de la distancia de Bray-Curtis: aquí, se comparan dos muestras j y k:\nBC_{jk}= 1- \\frac{2\\sum_{i=1}^{p}min(N_{ij}, N_{ik})}{\\sum_{i=1}^{p}(N_{ij}+N_{ik})}\nDonde es la abundancia de una especie i en la muestra j y la abundancia de la misma especie i en la muestra k. El término min (.,.) Corresponde al mínimo obtenido para dos conteos en las mismas muestras. Las sumas ubicadas en el numerador y denominador se realizan sobre todas las especies presentes en las muestras. N_ {ij}N_{ik}\nLa distancia Bray-Curtis tiende a resultar más intuitiva debido a que las especies comunes y raras tienen pesos relativamente similares, mientras que la distancia euclidiana depende en mayor medida de las especies más abundantes. Esto sucede porque las distancias euclidianas se basan en diferencias al cuadrado, mientras que Bray-Curtis utiliza diferencias absolutas. El elevar un número al cuadrado siempre amplifica la importancia de los valores más grandes\n\nPara: variables porcentajes o proporciones (0-1)\n\nEn resumen:\nResumen, ¿Cuál distancia usar?\nLa distancia ideal a utilizar va a depender completamente de los datos que estamos usando.\n\nSi los datos son continuos y no presentan outliars la distancia euclidiana es suficiente.\nSi la distribución de las variables es no-normal y presenta outliars, es mejor la distancia de Manhattan.\nEn caso de que los datos presentan valores nulos (ej., presencia/ausencia de especies), entonces es mejor usar Jaccard.\nSi las variables son proporciones o porcentajes entre cero y uno, por ejemplo abundancia de especies o otro tipo de frecuencias, es buena la distancia de Bray-Curtis.\n\nPor supuesto, existen muchos otros índices de distancia que pueden buscar y utilizar."
  },
  {
    "objectID": "multivariante.html#ordenación",
    "href": "multivariante.html#ordenación",
    "title": "13  Estadísticas Multivariante",
    "section": "13.5 Ordenación",
    "text": "13.5 Ordenación\nEn ecología es bastante normal que dispongamos de datos que están conformados por un conjunto de sitios o localidades, para los cuales tenemos una serie de variables. Estas variables puede ser cada especie o cada condición que levantemos en el sitio, de esta forma, un sitio va a tener tantas variables como especies o factores ambientales se registren.\nOrdenamos las parcelas en función de la cantidad de individuos de dos especies, de esta forma la distancia a la que se encontraba cada comunidad nos daba información sobre cuanto se parecían. Aunque esta es una forma fácil de ordenar nuestras comunidades, esta forma de graficar es solo posible con dos o máximo tres especies, pero pocas comunidades tienen únicamente tres especies, cuando tenemos más de tres especies es necesario buscar otras formas de ordenación que nos permitan rescatar el gradiente ambiental.\nDe esta forma, el objetivo de los métodos de ordenación es representar los datos a lo largo de un número reducido de ejes ortogonales, construidos de tal manera que representan, en orden, las principales tendencias de los datos (Borcard, Gillet, and Legendre 2011).\nLas ordenaciones pueden ser indirectas y directas (constreñidas). Las ordenaciones indirectas pueden ser utilizadas para interpretarse visualmente o asociadas a otros métodos, como regresión. Por su parte, las ordenaciones directas permiten hacer asociaciones con variables explicativas, generando un orden constreñido pobasado en unas variables explicativas.\nPor ejemplo, si se registran las abundancias de diez especies en diferentes sitios, entonces la variación total entre sitios podría ser representada gráficamente en diez dimensiones (i.e., una por especie). Obviamente, esto no es muy eficiente. Sin embargo, si sólo hubieran unas pocas tendencias o gradientes claves compartidas entre las especies, entonces se podría derivar un conjunto más pequeño de ejes (por ejemplo, dos) que resumiera la mayor parte de la variación en el conjunto de datos.\nEl término “ordenación” refleja la intención original del enfoque - identificar gradientes únicos (es decir, respuestas ordenadas) de variables que podría reflejar los procesos ecológicos.\nPara reducir la dimensionalidad de las variables dentro de una análisis estadístico (i.e., tener menos variables), hay dos formas principales:\n\nFeature selection: Seleccionar variables; ejempo: Stepwise selection\nFeature extraction: Extraer la información relevante de cada variable, y crear un número menor de nuevos componentes con esa información"
  },
  {
    "objectID": "multivariante.html#métodos-de-ordenación",
    "href": "multivariante.html#métodos-de-ordenación",
    "title": "13  Estadísticas Multivariante",
    "section": "13.6 Métodos de ordenación",
    "text": "13.6 Métodos de ordenación\n\n13.6.1 Principal Component Analysis (PCA)\nEsta técnica de ordenación es sencilla de interpretar, las distancias entre las muestras son interpretadas directamente como distancias euclidianas. Este método de ordenación es ampliamente usado con datos ambientales, donde el valor de cero es informativo, aunque se puede usar en datos biológicos previo una transformación. El PCA al usar distancias euclidianas es fuertemente afectado por ceros, y detecta relaciones lineares de los datos.\nAdemás de las limitantes de los dobles ceros, otro inconveniente que puede tener esta ordenación, es que la proyección de las distancias euclidias en un plano puede distorsionar algunas distancias en otros planos.\nLos gráficos de dispersión de la ordenación PCA, los objetos (las comunidades) se representan como puntos y las variables se muestran como flechas.\nUsa matrices de disimilaridad en base a distancias EUCLIDIANAS! Distancias lineales.\nNúmero de Componentes Principales Creados es = el Número de variables iniciales.\nPCA ordena de forma decreciente los componentes de acuerdo a cuánta información de las variables originales contiene. Ej., PC1 es siempre el que contiene más información, y PCn prácticamente nada (muchas veces los últimos componentes se consideran ruido! ): información en los datos no relevante en relación al contexto general de su organización e interacción.\n\n\n\nPrincipal Component Analysis (PCA)\n\n\n\nLoadings:\n\nPueden interpretarse como el peso/importancia que tiene cada variable en cada componente y, por lo tanto, ayudan a conocer que tipo de información recoge cada una de las componentes. Cada variable original no es asignada completamente a un solo componente principal, sino que la varianza de una variable puede ser compartida por muchos componentes.\n\nScores:\n\nLos scores son los componentes principales que el método crea para resumir la información de los datos originales.\n\nEigenvectors y Eigenvalues:\n\nEstos dos conceptos están relacionados con los componentes o loadings. De manera simple, eigenvectors y eigenvalues son en realidad propiedades de la multiplicación de matrices cuadradas realizadas durante el PCA (y otros muchos métodos). Eigenvectors serían las direcciones de rotación de cada componente, mientras que eigenvalue es la cantidad de varianza que cada componente explica. Por lo tanto, el eigenvalue determina el orden de los componentes en PCA.\n\n\nNúmero óptimo de componentes principales\nNormalmente el criterio para seleccionar el número deseado de componentes es graficando la varianza acumulada de los eigenvalues y elegir el punto de inflexión (elbow). La idea es reducir la dimensionalidad de los datos, por lo que un número bajo de componentes es deseado. Además, normalmente los componentes altos (i.e., baja varianza) en general tienen mucho ruido.\nEjemplo: datos foliares de pigmentos (clorofila, carotenoides, contenido de agua, …) con datos hiperespectrales tomados por espectroscopia de campo (datos de reflectancia de teledetección = 2051 variables)\n\n\n\nFigure 13.1: Varianza explicada\n\n\n\n\n\nFigure 13.2: Suma acumulada de la varianza\n\n\nInterpetración Gráfica de PCA\nScatterplot de los dos primeros componentes, PC1 y PC2, los que contienen justos cerca del 75% de la varianza de los datos. Como se puede ver:\nLos componentes, o las variables nuevas creadas, no tienen las mismas unidades de medida originales. Estas son variables sin unidades. Datos de coordenadas en la nueva dimensión. Puntos más lejos del centro (0,0) contribuyen más a la creación del del nuevo espacio de coordenadas.\nLas distancias entre los puntos indican que observaciones (filas) tienen valores parecidos y cuales muy distintos (lejos). En este caso, las distancias SI importan, ya que la distancia euclidiana mantiene las proporciones lineales de los datos originales.\n\n\n\nFigure 13.3: Visualización de dos PCA\n\n\nSe pueden ajustar vectores o factores ambientales en una ordenación. Las proyecciones de los puntos sobre los vectores tienen la máxima correlación con las variables ambientales correspondientes, y los factores muestran las medias de los niveles de los factores.\nEj: el contenido de agua de la hoja (Cw) se relaciona con PC1 (negativo) y con PC2 (positivo). El hecho de que sea positivo o negativo importa poco.\nPuntos cerca de ese vector de Cw son los que tienen más agua, y viceversa.\n\n\n\nFigure 13.4: Visualización de dos PCA con proyección de variables ambientales\n\n\n\n\n13.6.2 Principal coordinates analysis (PCoA)\nPCoA, conocido también como escalado métrico multidimensional (MDS) es conceptualmente similar a PCA y análisis de correspondencia (CA) que preservan distancias Eudlicean y chi-cuadrado entre objetos, respectivamente, la diferencia con estos métodos de ordenación es que el PCoA puede preservar las distancias generadas a partir de cualquier medida de similitud o disimilitud permitiendo un manejo más flexible de datos ecológicos complejos. PCA se usa comúnmente para similitudes y PCoA para diferencias.\nUna ventaja importante es que el PCoA permite manejar matrices de disimilitud calculadas a partir de variables cuantitativas, semicuantitativas, cualitativas y mixtas. En este caso la elección de la medida de similitud o disimilitud es crítica y debe ser adecuada para los datos con los que se está trabajando.\nAunque, este método presenta varias ventajas hay que recordad que el PCoA representa en el plano los componentes euclidianos de la matriz, incluso si la matriz contiene distancias no euclidianas.\nPrincipal coordinates analysis (PCoA) es una extensión conceptual de la técnica de PCA descrita anteriormente. De manera similar, busca ordenar los objetos a lo largo de los ejes de las coordenadas principales para maximizar la varianza del conjunto de datos original. Sin embargo, mientras que el PCA organiza los objetos linealmente mediante medidas de distancia euclidianas, el PCoA puede aplicarse con cualquier matriz de distancia (dissimilarity) (Gower 1966).\nPCoA utiliza matrices de distancia como input.\nLas distancias entre puntos no representan distancias reales entre las variables, ya que no usa distancia euclidiana\nTambién genera Número de Componentes Principales Creados es = el Número de variables iniciales.\n\n\n\nFigure 13.5: Visualización de Principal coordinates analysis (PCoA)\n\n\n\nEs una técnica de ordenación única, ya que se elige explícitamente un (pequeño) número de ejes de ordenación antes del análisis y los datos se ajustan a esas dimensiones.\nPor ej., el total de la variación de los datos de entrada se puede transformar en 2-3 componentes.\nDe manera similar al PCoA, se calcula primero una matriz de diferencias de objetos utilizando una métrica de distancia elegida (lineal, no-lineal, etc).\nEn NMDS, se calculan los rangos de estas distancias entre todos los objetos. El algoritmo encuentra entonces una configuración de objetos en el espacio ordinal elegido de N-dimensiones que se ajusta mejor a las diferencias de rangos (Kruskal 1964). Se usa una métrica de costo k para identificar el mejor número de componentes a crear. Los costos bajo 1.2 se consideran buenos.\nEn este caso, la distancia y ubicación en las coordenadas no importa, únicamente dice si: si dos puntos están cerca de si = contienen información similar, si están lejos = información distinta.\n\n\n\nFigure 13.6: Visualización de Nonmetric multidimensional scaling (NMDS)"
  },
  {
    "objectID": "multivariante.html#referencias-teóricas",
    "href": "multivariante.html#referencias-teóricas",
    "title": "13  Estadísticas Multivariante",
    "section": "13.7 Referencias Teóricas",
    "text": "13.7 Referencias Teóricas\nAnálisis multivariante de la comunidad"
  },
  {
    "objectID": "multivariante.html#parte-práctica",
    "href": "multivariante.html#parte-práctica",
    "title": "13  Estadísticas Multivariante",
    "section": "13.8 Parte Práctica",
    "text": "13.8 Parte Práctica\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n13.8.1 Insumos\nCargar foliares de pigmentos (clorofila, carotenoides, contenido de agua, …) con datos hiperespectrales tomados por espectroscopia de campo (datos de reflectancia de teledetección = 2051 variables)\n\n# datos de rasgos de hojas + reflectancia\ndata1 = read.csv('https://raw.githubusercontent.com/JavierLopatin/Clases/master/M%C3%A9todos_avanzados_en_R/dataset/angers-leaf-optical-properties-database--2003.csv')\n\n\n\n\nSolamente utilizar los datos de reflectancia, los de transmitancia no los utilizaremos.\n\ndata1 = data1 %>% \n  filter(Measurement_type == 'reflectance')\n\n# primero verificar que los datos no tengan NaNs\nany( is.na(data1) )\n\n[1] FALSE\n\n# data1 = na.omit(data1)\n\nObtener los los rasgos y cambiar el nombre de las columnas, corresponde a las variables que no queremeos que se reduzcan.\n\ntraits = data1 %>% \n  dplyr::select(2,4,7,9,15)\n\ncolnames(traits) = c('Car', 'Cab', 'Cw', 'Cm', 'N')\ntraits %>% head()\n\n   Car      Cab         Cw         Cm        N\n1 4.33 12.54078 0.01222310 0.00550680 1.313594\n2 3.65 12.41369 0.01200028 0.00525210 1.425785\n3 6.50 25.81402 0.01059972 0.00445635 1.549407\n4 6.90 24.13499 0.01085436 0.00432900 1.652313\n5 4.91 17.12158 0.01037691 0.00401070 1.437254\n6 3.85 13.54378 0.01021775 0.00401070 1.531708\n\n\nVariables que nos interesa reducir, correspondiente a los valores de reflectancia.\n\n# obtener la reflectancia\nreflec <- data1 %>% \n  select(22:ncol(.))\n\nHagamos un gráfico de la reflectancia media solo para visualización\n\nplot(seq(400,2450), colMeans(reflec), type='l', las=1, lwd=2, ylab='Reflectance',\n     xlab='Wavelength [nm]', main=\"\", ylim = c(0, 0.5))\nlines(seq(400,2450), colMeans(reflec)-sapply(reflec, sd), ltw=2, lty=2)\nlines(seq(400,2450), colMeans(reflec)+sapply(reflec, sd), ltw=2, lty=2)\nlegend('topright', legend=c('Reflectacia media', 'Desviacion estandar'), lty=c(1,2), bty = 'n')\n\n\n\n\n\ndat <- data.frame(x= seq(400,2450), y =colMeans(reflec))\nlibrary(ggplot2)\nggplot(dat, aes(x=x,y=y)) +\n  stat_smooth(method=\"loess\", span=0.1, se=TRUE, alpha=0.3) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Transformacion PCA a la reflectancia\nhist( scale(reflec$X400) )\n\n\n\n\n\n\n13.8.2 PCA\n\npca <- prcomp(reflec, scale=TRUE)\nnames(pca)\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\n\nLos elementos center y scale almacenados en el objeto pca contienen la media y desviación típica de las variables previa estandarización (en la escala original). Rotation contiene el valor de los loadings ϕ para cada componente (eigenvector).\n\npca$rotation[1:10,1:6]\n\n              PC1         PC2         PC3        PC4         PC5         PC6\nX400 -0.006628879 0.005318331 -0.04160382 0.03819106 -0.07121438 0.010068086\nX401 -0.006452994 0.005255895 -0.04218019 0.03788624 -0.07159453 0.009762666\nX402 -0.006262953 0.005140386 -0.04276546 0.03742642 -0.07196624 0.009631123\nX403 -0.006086615 0.004983599 -0.04332606 0.03696927 -0.07237624 0.009483581\nX404 -0.005898293 0.004841682 -0.04386878 0.03649034 -0.07278967 0.009382514\nX405 -0.005680474 0.004691313 -0.04441987 0.03605830 -0.07308285 0.009345734\nX406 -0.005473701 0.004547283 -0.04495702 0.03560430 -0.07337684 0.009361069\nX407 -0.005275117 0.004419073 -0.04548110 0.03510984 -0.07358472 0.009318459\nX408 -0.005081329 0.004305750 -0.04600954 0.03451344 -0.07372950 0.009286098\nX409 -0.004905777 0.004225221 -0.04651380 0.03380798 -0.07391815 0.009068955\n\n\nCaculamos la proporción de varianza total de los datos contenido en cada componente\n\nprop_varianza <- pca$sdev^2 / sum(pca$sdev^2)\nprop_varianza[1:10]\n\n [1] 0.456050786 0.321837997 0.138329255 0.025464522 0.017351791 0.006846017\n [7] 0.005462898 0.003616478 0.002234013 0.001649435\n\n\nEjemplo: PC1 explica el 46% de toda la informacion, PC2 32%, …\nPlot de los primeros 10 componentes\n\nbarplot(prop_varianza[1:10], las=1, ylab='Variamza explicada [%]', xlab='Componentes',\n        main='Varianza explicada de los primeros 10 comp.')\n\n\n\n\nvarianza acumulada y plot\n\nprop_varianza_acum <- cumsum(prop_varianza)\n\nplot(seq(1,20), prop_varianza_acum[1:20], las=1, type='l',\n     xlab='Componentes', ylab=\"Prop. varianza explicada acumulada [%]\")\nabline(v=3, lty=2)\n\n\n\nprop_varianza_acum\n\n  [1] 0.4560508 0.7778888 0.9162180 0.9416826 0.9590344 0.9658804 0.9713433\n  [8] 0.9749597 0.9771938 0.9788432 0.9803195 0.9817553 0.9830602 0.9842584\n [15] 0.9853523 0.9863463 0.9872446 0.9880876 0.9888183 0.9894673 0.9900842\n [22] 0.9906678 0.9911896 0.9916342 0.9920692 0.9924730 0.9928704 0.9932518\n [29] 0.9936089 0.9939298 0.9942392 0.9945110 0.9947651 0.9950071 0.9952379\n [36] 0.9954623 0.9956670 0.9958620 0.9960439 0.9962170 0.9963858 0.9965401\n [43] 0.9966887 0.9968275 0.9969574 0.9970758 0.9971891 0.9973001 0.9974108\n [50] 0.9975162 0.9976152 0.9977081 0.9977982 0.9978850 0.9979675 0.9980432\n [57] 0.9981179 0.9981903 0.9982537 0.9983168 0.9983783 0.9984371 0.9984926\n [64] 0.9985430 0.9985921 0.9986407 0.9986883 0.9987340 0.9987780 0.9988210\n [71] 0.9988627 0.9989021 0.9989393 0.9989759 0.9990120 0.9990456 0.9990775\n [78] 0.9991086 0.9991379 0.9991667 0.9991945 0.9992210 0.9992469 0.9992721\n [85] 0.9992966 0.9993196 0.9993418 0.9993628 0.9993835 0.9994037 0.9994233\n [92] 0.9994424 0.9994608 0.9994790 0.9994962 0.9995131 0.9995294 0.9995451\n [99] 0.9995607 0.9995759 0.9995907 0.9996046 0.9996181 0.9996314 0.9996441\n[106] 0.9996565 0.9996686 0.9996804 0.9996921 0.9997031 0.9997136 0.9997235\n[113] 0.9997330 0.9997423 0.9997512 0.9997600 0.9997685 0.9997766 0.9997841\n[120] 0.9997916 0.9997988 0.9998059 0.9998124 0.9998187 0.9998248 0.9998308\n[127] 0.9998365 0.9998419 0.9998472 0.9998524 0.9998575 0.9998624 0.9998670\n[134] 0.9998715 0.9998759 0.9998802 0.9998844 0.9998883 0.9998921 0.9998958\n[141] 0.9998994 0.9999029 0.9999063 0.9999096 0.9999129 0.9999160 0.9999190\n[148] 0.9999220 0.9999249 0.9999277 0.9999304 0.9999331 0.9999357 0.9999381\n[155] 0.9999405 0.9999429 0.9999450 0.9999472 0.9999492 0.9999512 0.9999531\n[162] 0.9999550 0.9999568 0.9999586 0.9999603 0.9999619 0.9999634 0.9999649\n[169] 0.9999663 0.9999677 0.9999690 0.9999703 0.9999716 0.9999728 0.9999740\n[176] 0.9999751 0.9999761 0.9999771 0.9999781 0.9999790 0.9999799 0.9999807\n[183] 0.9999816 0.9999823 0.9999831 0.9999838 0.9999845 0.9999851 0.9999858\n[190] 0.9999864 0.9999869 0.9999875 0.9999880 0.9999885 0.9999890 0.9999895\n[197] 0.9999899 0.9999903 0.9999907 0.9999911 0.9999915 0.9999918 0.9999922\n[204] 0.9999925 0.9999928 0.9999931 0.9999934 0.9999937 0.9999939 0.9999942\n[211] 0.9999944 0.9999947 0.9999949 0.9999951 0.9999953 0.9999955 0.9999957\n[218] 0.9999959 0.9999960 0.9999962 0.9999963 0.9999965 0.9999966 0.9999968\n[225] 0.9999969 0.9999971 0.9999972 0.9999973 0.9999974 0.9999975 0.9999977\n[232] 0.9999978 0.9999979 0.9999980 0.9999981 0.9999981 0.9999982 0.9999983\n[239] 0.9999984 0.9999985 0.9999985 0.9999986 0.9999987 0.9999988 0.9999988\n[246] 0.9999989 0.9999989 0.9999990 0.9999991 0.9999991 0.9999992 0.9999992\n[253] 0.9999993 0.9999993 0.9999994 0.9999994 0.9999994 0.9999995 0.9999995\n[260] 0.9999996 0.9999996 0.9999996 0.9999997 0.9999997 0.9999997 0.9999998\n[267] 0.9999998 0.9999998 0.9999999 0.9999999 0.9999999 0.9999999 1.0000000\n[274] 1.0000000 1.0000000 1.0000000\n\n\nSolo 3 componentes tienen >90% de la informacion de las 2051 variables\n\n\n13.8.3 Features Spaces\n\n# analizas si distribución en el espacio muestral (feature space)\nlibrary(vegan)\n\nLoading required package: permute\n\n\nLoading required package: lattice\n\n\nThis is vegan 2.6-4\n\n# ordiplot es una funcion especifica para este tipo de datos. Tiene parametros inetresantes\nordiplot(pca)\n\n\n\n# lo mismo que \nplot(pca$x[,1:2])\n\n\n\n# PC2 contra PC3\nordiplot(pca, choices = c(2,3))\n\n\n\n# ver que observación es cada punto\nordiplot(pca, type = \"text\")\n\n\n\n\n\n# crear modelo que ajusta otras variables al gradiente de coordenadas creado\nenv = envfit(pca, traits)\nenv\n\n\n***VECTORS\n\n         PC1      PC2     r2 Pr(>r)    \nCar -0.17252  0.98501 0.1018  0.001 ***\nCab -0.00033  1.00000 0.1272  0.001 ***\nCw  -0.77766  0.62868 0.8078  0.001 ***\nCm  -0.56468  0.82531 0.5803  0.001 ***\nN    0.00416  0.99999 0.8857  0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nPermutation: free\nNumber of permutations: 999\n\n# plot\nordiplot(pca, type = \"text\")\nplot(env)\n\n\n\n\nLa distribución espacial de los datos esta dado por la variabilidad (información) que explica.\nVisualización 3d de los PCA\n\ndata <-  pca$x[,1:3] %>% scale() %>% as.data.frame() %>% \n  mutate(sd = pca$sdev)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nfig <- plot_ly(data, x = ~PC1, y = ~PC2, z = ~PC3\n               # marker = list(color = ~sd, \n               #               colorscale = c('#FFE1A1', '#683531'),\n               #               showscale = TRUE)\n               )\nfig <- fig %>% add_markers()\nfig <- fig %>% layout(scene = list(\n  xaxis = list(title = 'PC1'),\n  yaxis = list(title = 'PC2'),\n  zaxis = list(title = 'PC3')))\n\nfig\n\n\n\n\n\n\n\n13.8.4 PCoA\n\nlibrary(ape)\nlibrary(vegan)\n\nBase de datos contenida en vegan, de cobertura (0-100%) especies en praderas europeas y\n\ndata(varespec)\nvarespec %>% head()\n\n   Callvulg Empenigr Rhodtome Vaccmyrt Vaccviti Pinusylv Descflex Betupube\n18     0.55    11.13     0.00     0.00    17.80     0.07     0.00        0\n15     0.67     0.17     0.00     0.35    12.13     0.12     0.00        0\n24     0.10     1.55     0.00     0.00    13.47     0.25     0.00        0\n27     0.00    15.13     2.42     5.92    15.97     0.00     3.70        0\n23     0.00    12.68     0.00     0.00    23.73     0.03     0.00        0\n19     0.00     8.92     0.00     2.42    10.28     0.12     0.02        0\n   Vacculig Diphcomp Dicrsp Dicrfusc Dicrpoly Hylosple Pleuschr Polypili\n18     1.60     2.07   0.00     1.62     0.00      0.0     4.67     0.02\n15     0.00     0.00   0.33    10.92     0.02      0.0    37.75     0.02\n24     0.00     0.00  23.43     0.00     1.68      0.0    32.92     0.00\n27     1.12     0.00   0.00     3.63     0.00      6.7    58.07     0.00\n23     0.00     0.00   0.00     3.42     0.02      0.0    19.42     0.02\n19     0.00     0.00   0.00     0.32     0.02      0.0    21.03     0.02\n   Polyjuni Polycomm Pohlnuta Ptilcili Barbhatc Cladarbu Cladrang Cladstel\n18     0.13     0.00     0.13     0.12     0.00    21.73    21.47     3.50\n15     0.23     0.00     0.03     0.02     0.00    12.05     8.13     0.18\n24     0.23     0.00     0.32     0.03     0.00     3.58     5.52     0.07\n27     0.00     0.13     0.02     0.08     0.08     1.42     7.63     2.55\n23     2.12     0.00     0.17     1.80     0.02     9.08     9.22     0.05\n19     1.58     0.18     0.07     0.27     0.02     7.23     4.95    22.08\n   Cladunci Cladcocc Cladcorn Cladgrac Cladfimb Cladcris Cladchlo Cladbotr\n18     0.30     0.18     0.23     0.25     0.25     0.23     0.00     0.00\n15     2.65     0.13     0.18     0.23     0.25     1.23     0.00     0.00\n24     8.93     0.00     0.20     0.48     0.00     0.07     0.10     0.02\n27     0.15     0.00     0.38     0.12     0.10     0.03     0.00     0.02\n23     0.73     0.08     1.42     0.50     0.17     1.78     0.05     0.05\n19     0.25     0.10     0.25     0.18     0.10     0.12     0.05     0.02\n   Cladamau Cladsp Cetreric Cetrisla Flavniva Nepharct Stersp Peltapht Icmaeric\n18     0.08   0.02     0.02     0.00     0.12     0.02   0.62     0.02        0\n15     0.00   0.00     0.15     0.03     0.00     0.00   0.85     0.00        0\n24     0.00   0.00     0.78     0.12     0.00     0.00   0.03     0.00        0\n27     0.00   0.02     0.00     0.00     0.00     0.00   0.00     0.07        0\n23     0.00   0.00     0.00     0.00     0.02     0.00   1.58     0.33        0\n19     0.00   0.00     0.00     0.00     0.02     0.00   0.28     0.00        0\n   Cladcerv Claddefo Cladphyl\n18        0     0.25        0\n15        0     1.00        0\n24        0     0.33        0\n27        0     0.15        0\n23        0     1.97        0\n19        0     0.37        0\n\n\n\n# datos ambientales en esa pradera\ndata(varechem)\nvarechem %>% head()\n\n      N    P     K    Ca    Mg    S    Al   Fe    Mn   Zn  Mo Baresoil Humdepth\n18 19.8 42.1 139.9 519.4  90.0 32.3  39.0 40.9  58.1  4.5 0.3     43.9      2.2\n15 13.4 39.1 167.3 356.7  70.7 35.2  88.1 39.0  52.4  5.4 0.3     23.6      2.2\n24 20.2 67.7 207.1 973.3 209.1 58.1 138.0 35.4  32.1 16.8 0.8     21.2      2.0\n27 20.6 60.8 233.7 834.0 127.2 40.7  15.4  4.4 132.0 10.7 0.2     18.7      2.9\n23 23.8 54.5 180.6 777.0 125.8 39.5  24.2  3.0  50.1  6.6 0.3     46.0      3.0\n19 22.8 40.9 171.4 691.8 151.4 40.8 104.8 17.6  43.6  9.1 0.4     40.5      3.8\n    pH\n18 2.7\n15 2.8\n24 3.0\n27 2.8\n23 2.7\n19 2.7\n\n\n\n# Calluna vulgaris\nhist(varespec$Callvulg)\n\n\n\n\nAquí tendríamos muchos problemas con PCA u otro método usando distancias eclidianas\n\n# calcular disimiridad usando Bray-Curtis\nvarespec.bray <- vegdist(varespec, method = \"bray\") \nvarespec.bray\n\n          18        15        24        27        23        19        22\n15 0.5310021                                                            \n24 0.6680661 0.3597783                                                  \n27 0.5621247 0.4055610 0.4934947                                        \n23 0.3747078 0.3652097 0.5020306 0.4286111                              \n19 0.5094738 0.4560757 0.5092318 0.4878190 0.3606242                    \n22 0.6234419 0.3579517 0.5010050 0.4655224 0.4812706 0.4726483          \n16 0.5337610 0.3976674 0.5907623 0.5683930 0.4094312 0.4496731 0.2678031\n28 0.8418209 0.5225414 0.5736665 0.3027802 0.6979519 0.6431734 0.5985666\n13 0.3453347 0.6063846 0.7576747 0.7543736 0.6221471 0.5739244 0.6948736\n14 0.5449810 0.4803756 0.6533606 0.7467915 0.5645808 0.6331942 0.5357609\n20 0.3879069 0.3784188 0.4346892 0.4957833 0.2877014 0.3953776 0.4627020\n25 0.6318891 0.3376115 0.3369098 0.5001593 0.4258617 0.4311299 0.3822981\n7  0.3603697 0.6717391 0.7931069 0.7792917 0.6390838 0.6958570 0.7459886\n5  0.4955699 0.7178612 0.8561753 0.8732190 0.7295255 0.7898205 0.8611451\n6  0.3382309 0.6355122 0.7441373 0.7496935 0.6252483 0.5684030 0.7249162\n3  0.5277480 0.7578503 0.8382119 0.8090236 0.7128798 0.5302756 0.8026152\n4  0.4694018 0.6843974 0.8309875 0.8413800 0.7117919 0.5177604 0.8015314\n2  0.5724092 0.8206269 0.8372551 0.7581924 0.7249869 0.5389222 0.8321464\n9  0.6583569 0.7761039 0.7590517 0.7415898 0.6693889 0.5393143 0.7725082\n12 0.4688038 0.6794199 0.6894538 0.6253616 0.5384762 0.4288556 0.7051751\n10 0.6248996 0.7644564 0.7842829 0.7096540 0.6625476 0.5059910 0.7875328\n11 0.4458523 0.4716274 0.5677373 0.6322919 0.4710280 0.3293493 0.5812219\n21 0.5560864 0.7607281 0.7272727 0.5456001 0.4951221 0.5315894 0.6771167\n          16        28        13        14        20        25         7\n15                                                                      \n24                                                                      \n27                                                                      \n23                                                                      \n19                                                                      \n22                                                                      \n16                                                                      \n28 0.7015360                                                            \n13 0.5514941 0.8600122                                                  \n14 0.4826350 0.8239667 0.5547565                                        \n20 0.3737797 0.6963560 0.5785542 0.5115258                              \n25 0.4306058 0.6086150 0.7412605 0.5541517 0.4518556                    \n7  0.6596144 0.8960202 0.4533054 0.6550830 0.5959162 0.7556726          \n5  0.7184789 0.9539592 0.5148988 0.7257681 0.7153827 0.8600858 0.3237446\n6  0.6509879 0.9014440 0.3515673 0.6227473 0.5439118 0.7343872 0.1754713\n3  0.6837953 0.9234485 0.4965478 0.7836661 0.6690479 0.8168684 0.5154487\n4  0.6462648 0.9381169 0.3881748 0.6734743 0.6771854 0.8400134 0.5601721\n2  0.7354202 0.9053213 0.5968691 0.8592489 0.6951539 0.8179089 0.6465777\n9  0.8185866 0.8686670 0.7292530 0.8282497 0.6982486 0.7884243 0.8318435\n12 0.6342166 0.8543167 0.5902386 0.7507074 0.5182426 0.7062564 0.6991666\n10 0.7656598 0.9016604 0.7160439 0.8304088 0.6706349 0.7845955 0.7697453\n11 0.5172825 0.7544064 0.4272808 0.6743277 0.4461712 0.6175930 0.5262233\n21 0.7474559 0.7248773 0.7212772 0.8096450 0.6320431 0.7466232 0.7933350\n           5         6         3         4         2         9        12\n15                                                                      \n24                                                                      \n27                                                                      \n23                                                                      \n19                                                                      \n22                                                                      \n16                                                                      \n28                                                                      \n13                                                                      \n14                                                                      \n20                                                                      \n25                                                                      \n7                                                                       \n5                                                                       \n6  0.3984538                                                            \n3  0.5634432 0.4517627                                                  \n4  0.5377506 0.4665100 0.3592689                                        \n2  0.7257597 0.5552754 0.2099203 0.4841145                              \n9  0.9014583 0.7223126 0.3885811 0.6222340 0.2330286                    \n12 0.7808641 0.5762462 0.2641851 0.4870742 0.1846147 0.2277228          \n10 0.8504191 0.6567926 0.3413378 0.5776062 0.1456729 0.1117280 0.1793368\n11 0.5563798 0.4077948 0.3002597 0.3215966 0.4209596 0.5145260 0.3688102\n21 0.8888316 0.6720141 0.7507773 0.7641304 0.6779661 0.5952563 0.5602137\n          10        11\n15                    \n24                    \n27                    \n23                    \n19                    \n22                    \n16                    \n28                    \n13                    \n14                    \n20                    \n25                    \n7                     \n5                     \n6                     \n3                     \n4                     \n2                     \n9                     \n12                    \n10                    \n11 0.5043578          \n21 0.6147874 0.6713363\n\n\n\n# PCoA\npcoa <- pcoa(varespec.bray)\nnames(pcoa)\n\n[1] \"correction\" \"note\"       \"values\"     \"vectors\"    \"trace\"     \n\nbiplot(pcoa, plot.axes = c(2,3))#ordiplot no funciona con esta funcion, pero si biplot()\n\n\n\nbiplot(pcoa, varechem)\n\n\n\n# varianza o otra informacion\nnames(pcoa$values)\n\n[1] \"Eigenvalues\"    \"Relative_eig\"   \"Rel_corr_eig\"   \"Broken_stick\"  \n[5] \"Cum_corr_eig\"   \"Cumul_br_stick\"\n\n# varianza acumulada\nplot(seq(1,24), pcoa$values$Cum_corr_eig, las=1, type='l',\n     xlab='Componentes', ylab=\"Prop. varianza explicada acumulada [%]\")\n\n\n\n### PCoA en los valores de reflectancia\nnorm.reflec <- apply(reflec, 2, scale, center=TRUE, scale=TRUE)\n# reflec[,1]\n# norm.reflec[,1]\n\nreflec.euclid <- vegdist(norm.reflec, method = \"euclidean\") \npcoa2 <- pcoa(reflec.euclid)\nbiplot(pcoa2, traits)\n\n\n\n# varianza acumulada de los componentes\npcoa2$values[,2]\n\n  [1] 4.560508e-01 3.218380e-01 1.383293e-01 2.546452e-02 1.735179e-02\n  [6] 6.846017e-03 5.462898e-03 3.616478e-03 2.234013e-03 1.649435e-03\n [11] 1.476259e-03 1.435876e-03 1.304862e-03 1.198212e-03 1.093945e-03\n [16] 9.939519e-04 8.983466e-04 8.429480e-04 7.306589e-04 6.490902e-04\n [21] 6.168674e-04 5.836293e-04 5.218073e-04 4.445388e-04 4.349852e-04\n [26] 4.037839e-04 3.974563e-04 3.813729e-04 3.571207e-04 3.209020e-04\n [31] 3.094196e-04 2.717250e-04 2.541212e-04 2.420565e-04 2.307918e-04\n [36] 2.244188e-04 2.047058e-04 1.949351e-04 1.819421e-04 1.731060e-04\n [41] 1.687303e-04 1.543348e-04 1.486321e-04 1.387929e-04 1.299182e-04\n [46] 1.183975e-04 1.132464e-04 1.110240e-04 1.107046e-04 1.053877e-04\n [51] 9.896249e-05 9.295175e-05 9.011024e-05 8.675865e-05 8.251886e-05\n [56] 7.570298e-05 7.469680e-05 7.237362e-05 6.338756e-05 6.313081e-05\n [61] 6.146383e-05 5.881598e-05 5.554237e-05 5.038870e-05 4.912571e-05\n [66] 4.857935e-05 4.764303e-05 4.560481e-05 4.408109e-05 4.295041e-05\n [71] 4.171522e-05 3.937944e-05 3.717072e-05 3.664157e-05 3.609617e-05\n [76] 3.356350e-05 3.199667e-05 3.109998e-05 2.929536e-05 2.871983e-05\n [81] 2.787995e-05 2.647449e-05 2.590881e-05 2.512759e-05 2.450626e-05\n [86] 2.308824e-05 2.214979e-05 2.099315e-05 2.074221e-05 2.014857e-05\n [91] 1.958325e-05 1.918015e-05 1.837066e-05 1.818512e-05 1.722095e-05\n [96] 1.683427e-05 1.629775e-05 1.578852e-05 1.553246e-05 1.522474e-05\n[101] 1.475460e-05 1.390396e-05 1.356887e-05 1.324025e-05 1.272309e-05\n[106] 1.241279e-05 1.213025e-05 1.179806e-05 1.164115e-05 1.102660e-05\n[111] 1.047433e-05 9.908433e-06 9.528612e-06 9.309610e-06 8.906339e-06\n[116] 8.789355e-06 8.509373e-06 8.034915e-06 7.557140e-06 7.494888e-06\n[121] 7.221785e-06 7.021719e-06 6.555412e-06 6.336345e-06 6.069977e-06\n[126] 5.988619e-06 5.681559e-06 5.441250e-06 5.304630e-06 5.193719e-06\n[131] 5.093590e-06 4.876060e-06 4.605875e-06 4.467919e-06 4.388076e-06\n[136] 4.293476e-06 4.216531e-06 3.902439e-06 3.824601e-06 3.689180e-06\n[141] 3.640943e-06 3.481446e-06 3.394284e-06 3.340555e-06 3.227580e-06\n[146] 3.115797e-06 3.013396e-06 2.971608e-06 2.908347e-06 2.839058e-06\n[151] 2.724947e-06 2.682001e-06 2.535752e-06 2.459155e-06 2.394446e-06\n[156] 2.335654e-06 2.196507e-06 2.114063e-06 2.037876e-06 1.994347e-06\n[161] 1.919870e-06 1.914949e-06 1.815555e-06 1.726223e-06 1.685242e-06\n[166] 1.639838e-06 1.527103e-06 1.456869e-06 1.415282e-06 1.390012e-06\n[171] 1.351156e-06 1.303696e-06 1.258990e-06 1.199232e-06 1.156238e-06\n[176] 1.133455e-06 1.051082e-06 1.006920e-06 9.363858e-07 9.262740e-07\n[181] 8.791972e-07 8.544296e-07 8.208705e-07 7.661062e-07 7.518760e-07\n[186] 7.145199e-07 6.870460e-07 6.606631e-07 6.291401e-07 5.816209e-07\n[191] 5.709944e-07 5.602866e-07 5.239054e-07 4.997710e-07 4.761835e-07\n[196] 4.732237e-07 4.398977e-07 4.041318e-07 3.909554e-07 3.864062e-07\n[201] 3.704129e-07 3.603055e-07 3.510277e-07 3.365122e-07 3.173817e-07\n[206] 2.982585e-07 2.830149e-07 2.677918e-07 2.658946e-07 2.528738e-07\n[211] 2.466423e-07 2.368520e-07 2.299626e-07 2.188495e-07 2.008480e-07\n[216] 1.865464e-07 1.805601e-07 1.739120e-07 1.724537e-07 1.649147e-07\n[221] 1.550133e-07 1.517301e-07 1.450113e-07 1.389093e-07 1.348611e-07\n[226] 1.316255e-07 1.293839e-07 1.233538e-07 1.193350e-07 1.173066e-07\n[231] 1.118370e-07 1.057387e-07 1.031572e-07 9.597950e-08 9.384536e-08\n[236] 8.910777e-08 8.634800e-08 8.076149e-08 7.970343e-08 7.819658e-08\n[241] 7.471827e-08 7.350296e-08 7.210800e-08 6.647312e-08 6.447544e-08\n[246] 6.171825e-08 5.991921e-08 5.887891e-08 5.764701e-08 5.611659e-08\n[251] 5.502039e-08 5.198532e-08 4.964987e-08 4.733071e-08 4.641339e-08\n[256] 4.294225e-08 4.219493e-08 4.139155e-08 3.989002e-08 3.858370e-08\n[261] 3.690747e-08 3.626762e-08 3.573295e-08 3.428036e-08 3.231117e-08\n[266] 3.143038e-08 2.975318e-08 2.823677e-08 2.703791e-08 2.641629e-08\n[271] 2.630691e-08 2.358029e-08 2.261352e-08 2.198754e-08 2.033906e-08\n\n# varianza acumulada primeros 10 comp\nplot(seq(1,10), pcoa2$values$Cum_corr_eig[1:10], las=1, type='l',\n     xlab='Componentes', ylab=\"Prop. varianza explicada acumulada [%]\")\nabline(v=3, lty=2)\n\n\n\n# tres componentes sigue siendo el punto optimo\n\n\n\n13.8.5 NMDS\nCon distancia euclineada y normalizado con scale(), como pca toda la varianza de los datos a 2 componentes\n\ndata(\"varechem\")\nnMDS <- metaMDS(norm.reflec, distance='euclidean', k=2, trymax=1000)\n\n'comm' has negative data: 'autotransform', 'noshare' and 'wascores' set to FALSE\n\n\nRun 0 stress 0.08567827 \nRun 1 stress 0.1021017 \nRun 2 stress 0.09520376 \nRun 3 stress 0.09727104 \nRun 4 stress 0.1132037 \nRun 5 stress 0.0970323 \nRun 6 stress 0.08700266 \nRun 7 stress 0.08706721 \nRun 8 stress 0.09881695 \nRun 9 stress 0.08575633 \n... Procrustes: rmse 0.002436618  max resid 0.03933993 \nRun 10 stress 0.09454315 \nRun 11 stress 0.0991179 \nRun 12 stress 0.1232208 \nRun 13 stress 0.09994333 \nRun 14 stress 0.08570663 \n... Procrustes: rmse 0.002201738  max resid 0.03091258 \nRun 15 stress 0.09454294 \nRun 16 stress 0.08706714 \nRun 17 stress 0.09994337 \nRun 18 stress 0.1156368 \nRun 19 stress 0.09454313 \nRun 20 stress 0.09198683 \nRun 21 stress 0.1124999 \nRun 22 stress 0.09198687 \nRun 23 stress 0.09703061 \nRun 24 stress 0.09460858 \nRun 25 stress 0.08570697 \n... Procrustes: rmse 0.002277762  max resid 0.03197135 \nRun 26 stress 0.08706723 \nRun 27 stress 0.09198692 \nRun 28 stress 0.09250597 \nRun 29 stress 0.08700988 \nRun 30 stress 0.097597 \nRun 31 stress 0.0970316 \nRun 32 stress 0.08570805 \n... Procrustes: rmse 0.0009178983  max resid 0.0120496 \nRun 33 stress 0.0870029 \nRun 34 stress 0.08706738 \nRun 35 stress 0.08706696 \nRun 36 stress 0.09881735 \nRun 37 stress 0.09198713 \nRun 38 stress 0.09250706 \nRun 39 stress 0.11702 \nRun 40 stress 0.08700282 \nRun 41 stress 0.4174846 \nRun 42 stress 0.08567789 \n... New best solution\n... Procrustes: rmse 0.001762641  max resid 0.02854054 \nRun 43 stress 0.0857567 \n... Procrustes: rmse 0.00406363  max resid 0.06632206 \nRun 44 stress 0.09252196 \nRun 45 stress 0.09755589 \nRun 46 stress 0.1170771 \nRun 47 stress 0.1224376 \nRun 48 stress 0.09198677 \nRun 49 stress 0.09520333 \nRun 50 stress 0.09424864 \nRun 51 stress 0.08575633 \n... Procrustes: rmse 0.004099182  max resid 0.06677981 \nRun 52 stress 0.08706708 \nRun 53 stress 0.08700277 \nRun 54 stress 0.09703081 \nRun 55 stress 0.09703134 \nRun 56 stress 0.09713313 \nRun 57 stress 0.09454384 \nRun 58 stress 0.08706699 \nRun 59 stress 0.08578592 \n... Procrustes: rmse 0.004226624  max resid 0.06711876 \nRun 60 stress 0.09738517 \nRun 61 stress 0.09961456 \nRun 62 stress 0.09045534 \nRun 63 stress 0.0856782 \n... Procrustes: rmse 7.691539e-05  max resid 0.0009472007 \n... Similar to previous best\n*** Best solution repeated 1 times\n\nenv2 = envfit(nMDS, traits)\n# ordiplot(nMDS)\n# plot(env2)\n\n\n# con los datos de especies, y usando la distancia Bray-Curtis\nnMDS2 <- metaMDS(varespec, distance='bray', k=2, trymax=1000)\n\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.1843196 \nRun 1 stress 0.195049 \nRun 2 stress 0.2109001 \nRun 3 stress 0.2234314 \nRun 4 stress 0.1948413 \nRun 5 stress 0.2276827 \nRun 6 stress 0.1858401 \nRun 7 stress 0.2044986 \nRun 8 stress 0.2061122 \nRun 9 stress 0.2245479 \nRun 10 stress 0.2297609 \nRun 11 stress 0.1967393 \nRun 12 stress 0.2088294 \nRun 13 stress 0.2109611 \nRun 14 stress 0.1974407 \nRun 15 stress 0.2088293 \nRun 16 stress 0.1962451 \nRun 17 stress 0.2174506 \nRun 18 stress 0.1948413 \nRun 19 stress 0.2173475 \nRun 20 stress 0.1967393 \nRun 21 stress 0.2289598 \nRun 22 stress 0.18584 \nRun 23 stress 0.1962451 \nRun 24 stress 0.2109003 \nRun 25 stress 0.1825658 \n... New best solution\n... Procrustes: rmse 0.04161612  max resid 0.1517505 \nRun 26 stress 0.2436879 \nRun 27 stress 0.2092456 \nRun 28 stress 0.1967393 \nRun 29 stress 0.1948413 \nRun 30 stress 0.2048307 \nRun 31 stress 0.213676 \nRun 32 stress 0.18584 \nRun 33 stress 0.195049 \nRun 34 stress 0.1825658 \n... New best solution\n... Procrustes: rmse 2.798688e-05  max resid 9.731252e-05 \n... Similar to previous best\n*** Best solution repeated 1 times\n\nenv3 = envfit(nMDS2, varechem)\nordiplot(nMDS2, type = 'text', las=1, main='NMDS para especies con Bray-Curtis')\nplot(env3)\n\n\n\n# En NMDS es stress debe ser < 1.3\n\n\n\n13.8.6 MANOVA\nMultivariate Analysis of Variance\n\ndata <- read.table(\"https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/manova.txt\", header=T, stringsAsFactors = TRUE)\nattach(data)\nnames(data)\n\n[1] \"tear\"     \"gloss\"    \"opacity\"  \"rate\"     \"additive\"\n\n\nPrimero, cree una variable de respuesta multivariada, Y, uniendo las tres variables de respuesta separadas (lagrima, brillo y opacidad), asi:\n\nY <- cbind(tear, gloss, opacity)\n\nAjuste modelo Luego ajuste el analisis de varianza multivariado usando la funcion manova:\n\nmodel <- manova(Y ~ rate * additive)\nsummary(model)\n\n              Df  Pillai approx F num Df den Df   Pr(>F)   \nrate           1 0.61814   7.5543      3     14 0.003034 **\nadditive       1 0.47697   4.2556      3     14 0.024745 * \nrate:additive  1 0.22289   1.3385      3     14 0.301782   \nResiduals     16                                           \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEsto muestra efectos significativos tanto para la tasa como para el aditivo, pero no para la interaccion. Tenga en cuenta que las pruebas F se basan en 3 y 14 grados de libertad (no en 1 y 16).\nEl metodo predeterminado en summary.manova es el Estadistico de Pillai-Bartlett. Otras opciones incluyen Wilks, Hotelling-Lawley y Roy.\nEn segundo lugar, observar cada una de las tres variables de respuesta por separado:\n\nsummary.aov(model)\n\n Response tear :\n              Df Sum Sq Mean Sq F value   Pr(>F)   \nrate           1 1.7405 1.74050 15.7868 0.001092 **\nadditive       1 0.7605 0.76050  6.8980 0.018330 * \nrate:additive  1 0.0005 0.00050  0.0045 0.947143   \nResiduals     16 1.7640 0.11025                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response gloss :\n              Df Sum Sq Mean Sq F value  Pr(>F)  \nrate           1 1.3005 1.30050  7.9178 0.01248 *\nadditive       1 0.6125 0.61250  3.7291 0.07139 .\nrate:additive  1 0.5445 0.54450  3.3151 0.08740 .\nResiduals     16 2.6280 0.16425                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response opacity :\n              Df Sum Sq Mean Sq F value Pr(>F)\nrate           1  0.421  0.4205  0.1036 0.7517\nadditive       1  4.901  4.9005  1.2077 0.2881\nrate:additive  1  3.960  3.9605  0.9760 0.3379\nResiduals     16 64.924  4.0578               \n\n\nHomogeneidad multivariante de las dispersiones de los grupos\n\nlibrary(vegan)\n\n\ndata <- read.csv('data/data_ts.csv', sep = ',', dec=',', \n                 stringsAsFactors = TRUE)\nstr(data)\n\n'data.frame':   36 obs. of  39 variables:\n $ piso        : Factor w/ 4 levels \"AndInf\",\"AndSup\",..: 3 3 3 3 3 3 3 3 3 4 ...\n $ degra       : int  1 1 1 2 2 2 3 3 3 1 ...\n $ plot        : int  1 2 3 1 2 3 1 2 3 1 ...\n $ CobTot      : num  94 89 81 90 90 ...\n $ CobArbo     : num  47 64 51 22 40 ...\n $ CobArbu     : num  35 8 18 33 15 ...\n $ CobHerb     : num  81 72 49 78 69 64 44 33 58 1 ...\n $ AltArbo     : num  3.49 2.56 3.93 3.26 3.93 ...\n $ AltArbu     : num  0.992 1.364 0.844 0.768 1.343 ...\n $ AltHerb     : num  0.3 0.156 0.26 0.249 0.22 ...\n $ FitoTot     : num  1.063 0.787 1.067 0.923 1.184 ...\n $ FitoArbo    : num  0.605 0.644 0.88 0.476 0.91 ...\n $ FitoArbu    : num  0.2145 0.0297 0.0596 0.2535 0.1222 ...\n $ FitoHerb    : num  0.243 0.112 0.127 0.194 0.152 ...\n $ CobHoj      : num  70 55.8 60 33.8 16.2 ...\n $ ProfHoj     : num  3.25 2.75 3.75 0.875 1.125 ...\n $ MasaHoj     : num  567 268 261 159 196 ...\n $ Riqueza     : int  23 21 25 23 23 20 21 13 20 9 ...\n $ Diversidad  : num  2.68 2.37 2.6 2.67 2.64 ...\n $ CSII_norm   : num  0.552 0.666 0.572 0.277 0.444 ...\n $ Arena       : num  56.8 50.8 58.8 55.8 62.8 ...\n $ Limo        : num  30 33 24 25 24 ...\n $ Arcilla     : num  13.2 16.2 17.2 19.2 13.2 ...\n $ DA          : num  1.11 1.09 1.32 1.04 1.04 ...\n $ DA_FF       : num  0.75 0.852 0.915 0.732 0.695 ...\n $ Porosidad   : num  58 58.9 50 60.6 60.9 ...\n $ Pedregosidad: num  18.6 12.9 23.5 20 17.5 ...\n $ C_tot       : num  1.94 2.17 1.09 3.16 3.77 ...\n $ N_tot       : num  0.142 0.1473 0.0901 0.2086 0.2267 ...\n $ CN          : num  13.7 14.8 12.1 15.2 16.6 ...\n $ HumApr      : num  12.85 17.93 17.92 11.08 9.25 ...\n $ CC          : num  39.6 31.5 36.3 22.1 22.4 ...\n $ PMP         : num  26.7 13.6 18.4 11 13.1 ...\n $ R10         : num  0.442 0.203 0.464 0.482 0.395 ...\n $ Infiltr     : num  0.436 0.174 0.739 0.626 0.259 ...\n $ ProdTot     : num  890 457 970 569 392 ...\n $ ProdArbo    : num  372.8 181.1 542.9 44 45.3 ...\n $ ProdArbu    : num  249.82 7.46 220.8 245.76 39.26 ...\n $ ProdHerb    : num  268 268 206 280 308 ...\n\n\n\n# subset de las columnas 4 a la 20\nvar <- data[, 4:20]\nstr(var)\n\n'data.frame':   36 obs. of  17 variables:\n $ CobTot    : num  94 89 81 90 90 ...\n $ CobArbo   : num  47 64 51 22 40 ...\n $ CobArbu   : num  35 8 18 33 15 ...\n $ CobHerb   : num  81 72 49 78 69 64 44 33 58 1 ...\n $ AltArbo   : num  3.49 2.56 3.93 3.26 3.93 ...\n $ AltArbu   : num  0.992 1.364 0.844 0.768 1.343 ...\n $ AltHerb   : num  0.3 0.156 0.26 0.249 0.22 ...\n $ FitoTot   : num  1.063 0.787 1.067 0.923 1.184 ...\n $ FitoArbo  : num  0.605 0.644 0.88 0.476 0.91 ...\n $ FitoArbu  : num  0.2145 0.0297 0.0596 0.2535 0.1222 ...\n $ FitoHerb  : num  0.243 0.112 0.127 0.194 0.152 ...\n $ CobHoj    : num  70 55.8 60 33.8 16.2 ...\n $ ProfHoj   : num  3.25 2.75 3.75 0.875 1.125 ...\n $ MasaHoj   : num  567 268 261 159 196 ...\n $ Riqueza   : int  23 21 25 23 23 20 21 13 20 9 ...\n $ Diversidad: num  2.68 2.37 2.6 2.67 2.64 ...\n $ CSII_norm : num  0.552 0.666 0.572 0.277 0.444 ...\n\n\nQueremos saber que variables (vegetación) influyen en el tipo de piso.\n\n# aov1 <-  manova(as.matrix(var)~data$piso)\n# summary(aov1)\n\n\n# escalar valores\nvar <- scale(var)\n\nMatriz de disimilaridad\n\ndis_veg <- dist(var)\nplot(dis_veg)\n\n\n\n# clases factoriales a usar en el analisis\ngroups <- data$piso\n\nDispersiones de los grupos\nAnova en el espacio de dimensiones reducido de Principal Coordinates Analysis (PCoA)\n\nbdisp_veg <- betadisper(dis_veg, groups) \nbdisp_veg\n\n\n    Homogeneity of multivariate dispersions\n\nCall: betadisper(d = dis_veg, group = groups)\n\nNo. of Positive Eigenvalues: 16\nNo. of Negative Eigenvalues: 0\n\nAverage distance to median:\nAndInf AndSup BosEsc EscAnd \n 2.704  1.458  2.578  3.895 \n\nEigenvalues for PCoA axes:\n(Showing 8 of 16 eigenvalues)\n  PCoA1   PCoA2   PCoA3   PCoA4   PCoA5   PCoA6   PCoA7   PCoA8 \n261.061 131.653  74.745  39.483  28.895  18.756  14.086   8.011 \n\n\nVisualización de los Componentes\n\nplot(bdisp_veg, axes = c(1, 2)) \n\n\n\nplot(bdisp_veg, axes = c(1, 3))\n\n\n\nplot(bdisp_veg, axes = c(2, 3))\n\n\n\n\n\ncon el argumento axes accedemos a los distintos componentes\n\nRealizar prueba de significancia entre grupos\n\nanova(bdisp_veg)\n\nAnalysis of Variance Table\n\nResponse: Distances\n          Df Sum Sq Mean Sq F value  Pr(>F)  \nGroups     3 26.825  8.9418  4.2713 0.01206 *\nResiduals 32 66.990  2.0935                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTukey test\n\nCompute Tukey Honest Significant Differences:\n\nCrea un conjunto de intervalos de confianza sobre las diferencias entre las medias de los niveles de un factor con la probabilidad de cobertura especificada por familia. Los intervalos se basan en el estadístico de rango estudiado, el método de “diferencia significativa honesta” de Tukey.\n\n\n\nHSD_veg <- TukeyHSD(bdisp_veg); HSD_veg\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = distances ~ group, data = df)\n\n$group\n                   diff        lwr       upr     p adj\nAndSup-AndInf -1.246255 -3.0942139 0.6017035 0.2796160\nBosEsc-AndInf -0.125818 -1.9737767 1.7221407 0.9977250\nEscAnd-AndInf  1.191543 -0.6564160 3.0395015 0.3170619\nBosEsc-AndSup  1.120437 -0.7275215 2.9683959 0.3699883\nEscAnd-AndSup  2.437798  0.5898392 4.2857567 0.0059602\nEscAnd-BosEsc  1.317361 -0.5305980 3.1653195 0.2354402\n\n\nLower y upper deben tener mismo signo (no pase por 0) para que sea significativas.\nEscAnd-AndSup p-adj < 0.05\n\nplot(HSD_veg)"
  },
  {
    "objectID": "series_tiempo.html",
    "href": "series_tiempo.html",
    "title": "14  Series de Tiempo",
    "section": "",
    "text": "Los datos de las series temporales son vectores de números, normalmente espaciados regularmente en el tiempo. Los recuentos anuales de animales, los precios diarios de las acciones, las medias mensuales de la temperatura y los detalles minuto a minuto de la presión sanguínea son ejemplos de series temporales, pero se miden en diferentes escalas de tiempo.\nA veces, el interés está en la propia serie temporal (por ejemplo serie temporal en sí misma; si es cíclica o no, o si los datos se ajustan a un modelo teórico concreto), y a veces la serie temporal es incidental a un experimento diseñado (por ejemplo, medidas repetidas).\nLos tres conceptos clave del análisis de series temporales son\nEjemplo: El ecologista australiano A.J. Nicholson crió larvas de moscas en trozos de hígado en cultivos de laboratorio que sus técnicos mantuvieron en funcionamiento continuo durante casi 7 años (361 semanas, para ser exactos). Las series temporales para número de moscas adultas tiene el siguiente aspecto:\nHay dos temas importantes a tener en consideración en el análisis de series temporales: autocorrelación y autocorrelación parcial.\nAutocorrelación: describe cómo la población de esta semana está relacionada con la población de la semana pasada. Esta es la autocorrelación en el lag 1.\nAutocorrelación parcial: describe la relación entre la población de esta semana y la población en el lag t una vez que hemos controlado las correlaciones entre todas las semanas sucesivas entre esta semana y la semana t. Ejemplo, la autocorrelación parcial con lag 2 es solo aquella que lag 1 no explica. (es importante en muchos modelos predictivos, ej. ARIMA)\nOJO: los lags no tienen por que se ser semanales, depende la unidad de tiempo\nEn series cíclicas, las relaciones lejanas pueden ser negativas.\nPor lo que la autocorrelación puede variar entre -1 y 1\nVeamos la estructura de las autocorrelaciones con la función acf (autocorrelation function)"
  },
  {
    "objectID": "series_tiempo.html#regresión-en-series-de-tiempo",
    "href": "series_tiempo.html#regresión-en-series-de-tiempo",
    "title": "14  Series de Tiempo",
    "section": "14.1 Regresión en Series de Tiempo",
    "text": "14.1 Regresión en Series de Tiempo\nRegresión de la serie contra el tiempo (length()), repesenta de forma general la Tendencia de la serie de tiempo.\n\nfit = lm(flies~I(1:length(flies)))\nsummary(fit)\n\nTendencia significativa (***); al aumentar en promedio 11 moscas cada semana"
  },
  {
    "objectID": "series_tiempo.html#práctica",
    "href": "series_tiempo.html#práctica",
    "title": "14  Series de Tiempo",
    "section": "14.2 Práctica",
    "text": "14.2 Práctica\nCargar Datos de series de tiempo (semanal)\n\nblowfly <- read.table(\"https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/blowfly.txt\", header=T, nrows = 361)\nnames(blowfly) # Solo una columna\n\n[1] \"flies\"\n\n\n\n# crear objeto de serie de tiempo con ts() \n\nflies <- ts(blowfly$flies[1:nrow(blowfly)-1])\nsummary(flies)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     60    1444    3339    3487    4892   14683 \n\n\n\nplot(flies)\n\n\n\n\n\n14.2.1 Relación de Lags (>0) con Lag 0\n\npar(mfrow = c(2, 2))\n\nfor (i in 1:4) {\n  plot(flies[-c(360:(360 - i + 1))], flies[-c(1:i)], xlab = 'lag 0', \n       ylab = paste0('lag ', i))\n}\n\n\n\npar(mfrow = c(2, 2))\n\nfor (i in 7:10){\n  plot(flies[-c(360: (360-i+1))], flies[-c(1:i)], xlab='lag 0', ylab=paste0('lag ',i) )\n}\n\n\n\npar(mfrow = c(1, 1))\n\n\n\n14.2.2 Autocorrelación Espacial Completa\n\n# plot de relaciones de autocorrelacion\nacf(flies, main = \"Autocorrelaciones\", col = \"red\")\n\n\n\n\nNo vera evidencia mas convincente de los ciclos que esta. Los blowflies exhiben ciclos regulares altamente significativos con un periodo de 19 semanas. Las lineas discontinuas azules indican los valores de umbral para la correlacion significativa.\n\n\n14.2.3 Autocorrelación Parcial\n\n# plot de relaciones de autocorrelacion\nacf(flies, main = \"Autocorrelaciones parciales\", type = \"p\", col = \"red\")\n\n\n\n\nLos efectos significativos dependientes de la densidad se manifiestan con retrasos de 2 y 3 semanas con otros, marginalmente. los efectos negativos significativos con desfases de 4 y 5 semanas.\nEstos retrasos reflejan la duracion de la larva y la pupa periodo (1 y 2 periodos, respectivamente). Los ciclos son claramente causados por la sobrecompensacion de la dependencia de la densidad, como resultado de la competencia intraespecifica entre las larvas por el alimento (lo que Nicholson bautizo como “scramble”. Hay una curiosa retroalimentacion positiva con un retraso de 12 semanas (12 a 16 semanas, de hecho). ¿Quizas puedas pensar en una posible causa para esto?\n\n\n14.2.4 Tendencia de la serie de tiempo (lm)\n\n# regresion de la serie contra el tiempo (length())\nfit = lm(flies ~ I(1:length(flies)))\nsummary(fit)\n\n\nCall:\nlm(formula = flies ~ I(1:length(flies)))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4125.3 -1656.1  -445.4  1131.9  9747.2 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        1512.742    227.246   6.657 1.05e-10 ***\nI(1:length(flies))   10.936      1.091  10.024  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2151 on 358 degrees of freedom\nMultiple R-squared:  0.2191,    Adjusted R-squared:  0.217 \nF-statistic: 100.5 on 1 and 358 DF,  p-value: < 2.2e-16\n\n\nEsto muestra que hay una tendencia al alza altamente significativa de alrededor de 11 flies adicionales promedio cada semana.\n\nplot(flies)\nlines(predict(fit), col = \"red\", lty = 2, lwd = 1.5)\n\n\n\n\nPodemos eliminar la tendencia de los datos restando los valores ajustados de la regresion lineal de segundo en el numero de dia:\n\ndetrended <- flies - predict(fit)\npar(mfrow = c(2, 2))\nplot(detrended)\nabline(h = 0, lty = 2, col = \"blue\", lwd = 2)\n\n\n\n\nSe evalua la autocorrelacion con las tendencias eliminadas (detrended) completa\n\nacf(detrended, main = \"\")\n\n\n\n# parcial\n# acf(detrended, main = \"\", type=\"p\")\npar(mfrow = c(1, 1))\n\n\n\n14.2.5 Medias Móviles\n\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\ntemperature <- read.table(\"https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/temp.txt\",header=T)\n\n\nattach(temperature)\n\ntemps = ts(temps)\n\npar(mfrow = c(1, 1))\nplot(temps)\n\n\nprom3 = rollapply(temps, width = 3, mean) # argumento width especifica el ancho de la ventana (n° observaciones) \n                                          # que se alinea con la muestra original \nlines(prom3, col=\"blue\")\n\nprom5 = rollapply(temps, width = 5, mean)\nlines(prom5, col=\"green\")\n\nprom7 = rollapply(temps, width = 7, mean)\nlines(prom7, col=\"red\")\n\n\n\n\nContinuar"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Canavos, George C. 1988. “The Sensitivity of the One-Sample and\nTwo-Sample Student t Statistics.” Computational Statistics\n& Data Analysis 6 (1): 39–46. https://doi.org/10.1016/0167-9473(88)90061-8.\n\n\n“Explaining the Lm() Summary in R –\nLearn by Marketing.” n.d. Accessed\nSeptember 2, 2022. https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/.\n\n\nKuhn, Max. n.d. 7 Train Models By Tag |\nThe Caret Package. Accessed September 9,\n2022. https://topepo.github.io/caret/train-models-by-tag.html.\n\n\nMatemáticas profe Alex. 2017. “Varianza y Desviación Estándar |\nIntroducción,” June. https://www.youtube.com/watch?v=oZRaDwnpXkY.\n\n\nMcClave, J. T., and T. Sincich. 2003. Statistics. Prentice\nHall.\n\n\n“Varianza.” 2022. https://es.wikipedia.org/w/index.php?title=Varianza&oldid=144468342.\n\n\nZar, Jerrold H. 1999. Biostatistical Analysis. Pearson\nEducation India."
  }
]