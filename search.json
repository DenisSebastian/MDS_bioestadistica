[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso: Bioestadística 2022",
    "section": "",
    "text": "Este libro que contiene los apuntes personales del curso de Bioestadística. Master of Science, de la Universidad Adolfo Ibañez. Chile 2022.\nPorfesor Titular: Prof. Javier Lopatin | javier.lopatin@uai.cl\nPrincipalmente para los procesos análisis de datos y visualización de resultados se usará R Project\n\n\n\nIntroducción al lenguaje de programación R: Instalación del programa R y RStudio. Lectura de archivos externos. Gráficos y estadística descriptiva. Tipos básicos de herramientas estadísticas.\nRegresión lineal y no lineal: Correlación, estimación y predicción. Intervalos de confianza. Diagnósticos y Análisis de residuos. Calibración\nAnálisis multivariante: Métodos de reducción de dimensionalidad en los datos. PCA. Análisis de Clusters.\nAnálisis de varianza de un factor (one-way ANOVA): Fundamentos, métricas y ejemplos de uso.\nAnálisis de varianza de dos o más factores (two-way ANOVA): Diferencia con ANOVA de un factor. Ejemplos de uso.\nAnálisis de covarianza (ANCOVA): Fundamentos, métricas y ejemplos de uso.\nDiseños de muestreo: Muestreo aleatorio simple, estratificado, y sistemático. Muestreo de dos etapas. Determinación del tamaño de la muestra.\nEstadística no paramétrica: Introducción a la estadística no paramétrica. Cuando utilizarla. Principio de parsimonia.\nSeries de tiempo: Ajuste estacional, media móvil, suavizado exponencial, extrapolación, predicción lineal, Estimación de tendencias, estacionalidad y modelado ARIMA."
  },
  {
    "objectID": "fundamentos.html",
    "href": "fundamentos.html",
    "title": "2  Fundamendos Básicos",
    "section": "",
    "text": "Estadística:\n\nLa estadística es la ciencia de los datos. Consiste en recoger, clasificar, resumir, organizar analizar e interpretar la información numérica. (McClave and Sincich 2003)\n\n\n\n\nLa estadística es el análisis y la interpretación de los datos con vistas a una evaluación objetiva de la fiabilidad de las conclusiones basadas en los datos. (Zar 1999)\n\n\n\n\nLa capacidad de utilizar el pensamiento racional para interpretar el significado de los datos\nEsta capacidad puede ayudarle a tomar decisiones inteligentes, inferencias y generalizaciones\n(McClave and Sincich 2003)\n\n\n\n\nEl objetivo principal del análisis estadístico es inferir los parámetros de la población a partir de una muestra.\n\nPalabra “Parámetro” se refiere a las Poblaciones, e.j., µ, σ (i.e., letras Griegas)\nPalabra “Estadígrafo” (Statistics) se refiere a las Muestras, e.j., X, Sx (i.e., letras latinas)\n\nEstadígrafos pueden variar de muestra a muestra.\nQueremos que estos Estadígrafos sean buenas representaciones de los parámetros de la población.\n\n\n\n\n\nParámetros en estadística (población y muestra)\n\n\n\n\n\nDos tipos principales de estadística:\n\n\nDescriptiva\n\nUtiliza métodos numéricos y gráficos para buscar patrones en un conjunto de datos, para resumir la información revelada en un conjunto de datos y presentar esa información en una forma conveniente.\n\n\n\n\n\nInferencial\n\nEs una estimación, predicción o alguna otra generalización sobre una población basada en la información contenida en una muestra.\n\n\n\n(McClave and Sincich 2003)"
  },
  {
    "objectID": "fundamentos.html#e-descriptiva",
    "href": "fundamentos.html#e-descriptiva",
    "title": "2  Fundamendos Básicos",
    "section": "2.2 Estadística Descriptiva",
    "text": "2.2 Estadística Descriptiva\n\n\n\nEjemplos Estadísticas descriptiva con datos\n\n\n\n\n\nRepresentación de tipos de datos\n\n\n\n2.2.1 Muestras reperesentativas\n\nContiene características similares o típicas de la población.\nLa forma más común de obtener muestras representativas es mediante selección aleatoria.\nUna muestra aleatoria garantiza que cada subconjunto de tamaño fijo de la población tiene la misma probabilidad de ser incluido en la muestra\n\n\n\n2.2.2 Consideraciones de la Estadísticas Descriptiva\n\nDefinir la población o muestra de interés\nDefinir las variables o características de la población que se van a investigar.\nDefinir el tipo de estadística descriptiva a usar: gráficos, tablas, valores de resumen\nIdentificar patrones en los datos.\n\n(McClave and Sincich 2003)"
  },
  {
    "objectID": "fundamentos.html#m-tendencia-central",
    "href": "fundamentos.html#m-tendencia-central",
    "title": "2  Fundamendos Básicos",
    "section": "2.3 Medidas de Tendencias Central",
    "text": "2.3 Medidas de Tendencias Central\n\n\n\n\n\n\nflowchart LR\n  A{Medidas de Tendencia Central}\n  A --> C[Moda]:::class_c1\n  A --> D[Mediana]:::class_c1\n  A --> E[Media]:::class_c1\nstyle A fill:#5D6D7E,color:#fff\nclassDef class_c1 fill:#1ABC9C,color:#fff\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuciones Normales y Sesgadas\n\n\n(Zar 1999)\n\n2.3.1 Media Aritmética\n\nDefinición:\n\nLa media aritmética es un concepto matemático usado en estadística. También llamada promedio o simplemente media, se obtiene con la suma de un conjunto de valores dividida entre el número total de sumandos. Detalles en Wikipedia.\n\n\n\n\\mu=\\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}\n\n\nX_i: cada observación de la población/muestra\nN: tamaño de la población o muestra\n\nEjemplo de Media Aritmétrica con R\nMuestra de 24 registros de población de mariposas cuyo valor corresponde a el largo en cm.\n\nValoresSumaMediaAlternativa MediaHistograma\n\n\n\nW <- c(3.3,3.5,3.6,3.6,3.7,3.8,\n       3.8,3.8,3.9,3.9,3.9,4.0,\n       4.0,4.0,4.0,4.1,4.1,4.1,\n       4.2,4.2,4.3,4.3,4.4,4.5)\n\n\n\n\n\\displaystyle\\sum_{i=1}^{N}X_i=95cm\n\n\nsum(W)\n\n[1] 95\n\n\n\n\n\n\\mu=\\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}=3.96 cm\n\n\nmean(W)\n\n[1] 3.958333\n\n\n\n\n\nma <-  function(vector){\n  N = length(vector)\n  ma = sum(vector)/N\n  return(ma)\n}\nma(W)\n\n[1] 3.958333\n\n\n\n\n\nhist(W, col = \"gray97\")\nabline(v=mean(W), col=\"red\")\n\n\n\n\n\n\n\n\n\n2.3.2 Mediana\n\nDefinición:\n\nEn el ámbito de la estadística, la mediana (del latín medianus ‘del medio’) representa el valor de la variable de posición central en un conjunto de datos ordenados. Se le denota mediana, si la serie tiene un número par de puntuaciones, la mediana es la media entre las dos puntuaciones centrales.\n\n\nDetalles en wikipedia\n\nEs el valor del medio de un set de datos ordenados.\nSe puede entender también como el valor donde está el 50% de los datos.\n\n\n\n\nEncontrar la mediana\n\n\n\nsort(W)\n\n [1] 3.3 3.5 3.6 3.6 3.7 3.8 3.8 3.8 3.9 3.9 3.9 4.0 4.0 4.0 4.0 4.1 4.1 4.1 4.2\n[20] 4.2 4.3 4.3 4.4 4.5\n\n\n\nmedian(W)\n\n[1] 4\n\n\n\n\n2.3.3 Moda\n\nDefinición:\n\nEn la estadística, la moda es el valor que aparece con mayor frecuencia en un conjunto de datos. Esto va en forma de una columna cuando encontremos dos modas, es decir, dos datos que tengan la misma frecuencia absoluta máxima. Una distribución trimodal de los datos es en la que encontramos tres modas. En el caso de la distribución uniforme discreta, cuando todos los datos tienen una misma frecuencia, se puede definir las modas como indicado, pero estos lores no tienen utilidad. Por eso algunos matemáticos califican esta distribución como “sin moda”.\n\n\nDetalles en wikipedia\nValor más frecuente en un set de datos.\n\ntable(W)\n\nW\n3.3 3.5 3.6 3.7 3.8 3.9   4 4.1 4.2 4.3 4.4 4.5 \n  1   1   2   1   3   3   4   3   2   2   1   1 \n\n\nEn R no existe una función específica pero se puede crear una:\n\nmoda <- function(x) {\n  uniqv <- unique(x)\n  uniqv[which.max(tabulate(match(x, uniqv)))]\n}\nmoda(W)\n\n[1] 4"
  },
  {
    "objectID": "fundamentos.html#medidas-de-dispersión-y-variabilidad",
    "href": "fundamentos.html#medidas-de-dispersión-y-variabilidad",
    "title": "2  Fundamendos Básicos",
    "section": "2.4 Medidas de Dispersión y Variabilidad",
    "text": "2.4 Medidas de Dispersión y Variabilidad\n\n2.4.1 Rango\n\n\nDefinición:\n\nDiferencia entre el valor más alto y más bajo de la muestra\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRango de la muestra subestima el rango de la población (problema con los extremos)\n\n\nEj., botánicos lo usan para medir las dimensiones de hojas y flores.\n\n\n\nRango\n\n\n\nCálculo Directo RLa función rango()\n\n\n\nmax(W) - min(W)\n\n[1] 1.2\n\n\n\n\nRetorna los valores mínimos y máximos de la muestra\n\nrange(W) \n\n[1] 3.3 4.5\n\n\n\n\n\n\n\n2.4.2 Cuartiles, Cuantiles y Percentiles\n\n\nCuartiles:\n\nDividen la población en 4 partes iguales, describiendo los valores acumulados al 0%, 25%, 50%, 75% y 100% (steps de 25%).\n\nCuantiles y Percentiles:\n\nDescriben lo mismo, pero no necesariamente se divide la muestra en 4 partes. Ej., se puede dividir en 10: 0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%\n\n\n\n\n\n\n\n\nCuartiles en RAjuste de los porcentajes\n\n\n\nquantile(W)\n\n   0%   25%   50%   75%  100% \n3.300 3.800 4.000 4.125 4.500 \n\n\n\n\n\nquantile(W, probs = c(0.05, 0.25, 0.5, 0.75, 0.95)) #\n\n   5%   25%   50%   75%   95% \n3.515 3.800 4.000 4.125 4.385 \n\n\n\n\n\n\n\n2.4.3 Rango Intercuartil (IQR)\n\nDistancia entre Q1 y Q3, el primer y segundo cuartil (25% y 75%).\nMás robusto que el rango normal\nNo afectan los outliars.\n\n\nIQR = Q3 - Q1\n\nRango intercuantil IQR = 75% - 25%\n\n\n\n\n\n\nCáculo en RAlternativa\n\n\n\nquantile(W, 0.75) - quantile(W, 0.25)\n\n  75% \n0.325 \n\n\n\n\n\nquantile(W)[4] - quantile(W)[2]\n\n  75% \n0.325 \n\n\n\n\n\n\n\n2.4.4 Varianza\n\nSuma de los cuadrados (SS) de las desviaciones de la media.\nDescribe la dispersión media en torno al valor medio\n\nDatos Población Total\n\n\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\mu)^2} {N}\n\nDatos Muestrales\n\nS^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\bar{X})^2} {n-1}\n\n\nWikipedia: (“Varianza” 2022)\nVideo: (Matemáticas profe Alex 2017)\n\n\nvar(W)\n\n[1] 0.08514493\n\n\n\n\n2.4.5 Desviación Estándar\nEs una medida que se utiliza para cuantificar la variación o la dispersión de un conjunto de datos numéricos.\nUna desviación estándar baja indica que la mayor parte de los datos de una muestra tienden a estar agrupados cerca de su media (también denominada el valor esperado), mientras que una desviación estándar alta indica que los datos se extienden sobre un rango de valores más amplio.\n\nDesviación Estándar paraDatos Población Total\n\n\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\mu)^2} {N}}\n\nDesviación Estándar para Datos Muestrales:\n\nS = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\bar{X})^2} {n-1}}\n\n\nValoresFórmulaFunción sd()GráficoCod_Graph\n\n\n\nW <- c(3.3,3.5,3.6,3.6,3.7,3.8,\n       3.8,3.8,3.9,3.9,3.9,4.0,\n       4.0,4.0,4.0,4.1,4.1,4.1,\n       4.2,4.2,4.3,4.3,4.4,4.5)\n\n\n\n\n\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(X_i - \\mu)^2} {N}}\n\n\n\n\nsd(W)\n\n[1] 0.291796\n\n\n\n\n\n\n\n\n\n\n\n\n# graficar la +- 1 DE y +- 2 DE en un histograma?\nhist(W)\nabline(v=mean(W), col='red')\n\n## +- 1 DE ---------------------------------------------------------------\nabline(v=mean(W)+sd(W), col='blue')\nabline(v=mean(W)-sd(W), col='blue')\n\n## +- 2 DE ---------------------------------------------------------------\nabline(v=mean(W)+sd(W)*2, col='green')\nabline(v=mean(W)-sd(W)*2, col='green')\n\n\n\n\n\n\n2.4.6 Coeficiente de Variación\n\nCómo la desviación estándar, pero normalizado a un porcentaje.\nSirve para comparar la variación entre datos de distintas poblaciones/muestras!\n\nV=\\frac{s}{\\bar{X}}\n\nsd(W) / mean(W) * 100\n\n[1] 7.371689\n\n\n\n\n2.4.7 índices de Diversidad\n\nEn el caso de los datos de escala nominal, no existe una media o una mediana que sirva de referencia para hablar de la dispersión\nPodemos invocar el concepto de diversidad, la distribución de las observaciones entre las categorías\nObservaciones distribuidas uniformemente en las categorías tienen Diversidad alta, mientras que observaciones que ocurren en pocas clases tiene Div. baja.\n\n\n2.4.7.1 Shannon-Wiener diversity index\n\nH'= \\sum_{i=1}^k {p_i \\ log \\ p_i}\n\n\nK = número de clases\nP_i proporción de obs. de la clases i\n\n\n\n2.4.7.2 Shannon-Wiener evenness index (índice de uniformidad)\n\nJ' = \\frac{H'}{H_{max}} \\qquad H_{max}= log\\ k\n\n\n\n2.4.7.3 Datos con una dimensión 1D\n\nDataFormulaCódigoResultado\n\n\n\n\n\n\n \n  \n    especies \n    frecuencia \n  \n \n\n  \n    a \n    44 \n  \n  \n    b \n    3 \n  \n  \n    c \n    28 \n  \n  \n    d \n    12 \n  \n  \n    e \n    2 \n  \n  \n    f \n    8 \n  \n\n\n\n\n\n\n\n\nH'= \\sum_{i=1}^k {p_i \\ log \\ p_i}\n\n\n\n\nespecies   <- c('a','b','c','d','e','f')\nfrecuencia <- c(44,3,28,12,2,8)\n\n# funcion manual para vector de 1D\ndiversidad <- function(x){\n  x <- x/(total <- sum(x)) # Proporcion de cada especie\n  x <- -x * log(x, exp(1)) \n  H <- sum(x, na.rm = TRUE)\n  H\n}\n\n\n\n\ndiversidad(frecuencia)\n\n[1] 1.369117\n\n\n\n\n\nEjemplo en R de ídice de diversidad con la función diversity() de la librería vegan.\n\nDataCódigo\n\n\n\n\n\n\n \n  \n    especies \n    frecuencia \n  \n \n\n  \n    a \n    44 \n  \n  \n    b \n    3 \n  \n  \n    c \n    28 \n  \n  \n    d \n    12 \n  \n  \n    e \n    2 \n  \n  \n    f \n    8 \n  \n\n\n\n\n\n\n\n\nlibrary(vegan)\ndiversity(frecuencia) \n\n[1] 1.369117\n\n\n\n\n\n\n\n2.4.7.4 Datos con más de una dimensión\nLectura de datos\nBarro Colorado Island Tree Counts: Tree counts in 1-hectare plots in the Barro Colorado Island and associated site information.\n\ndata(BCI)\ndata(BCI.env)\n\nCálculo de BCI\n\n#### Diversity  ---------------------------------------------------------\ndiv <- diversity(BCI)\ndiv\n\n       1        2        3        4        5        6        7        8 \n4.018412 3.848471 3.814060 3.976563 3.969940 3.776575 3.836811 3.908381 \n       9       10       11       12       13       14       15       16 \n3.761331 3.889803 3.859814 3.698414 3.982373 4.017494 3.956635 3.916821 \n      17       18       19       20       21       22       23       24 \n3.736897 3.944985 4.013094 4.077327 3.969925 3.755413 4.062575 3.979427 \n      25       26       27       28       29       30       31       32 \n4.074718 3.947749 3.980281 3.693896 3.688721 3.851598 3.724967 3.784873 \n      33       34       35       36       37       38       39       40 \n3.740392 3.821669 2.641859 3.846109 3.791703 3.516082 3.530494 3.234849 \n      41       42       43       44       45       46       47       48 \n4.052495 3.966614 3.736254 3.705016 3.609518 3.810489 3.920918 3.913725 \n      49       50 \n3.778851 3.906616 \n\n\nAnalizar gradientes entre diversidad y variables\n\n# analizar gradientes entre diversidad y variables\nplot(x = div, y = BCI.env$Precipitation)\nabline(h=2530, col=\"red\")\n\n\n\n\n\nplot(x = div, y = BCI.env$Habitat)\n\n\n\n\n\n\n\n\nMatemáticas profe Alex. 2017. “Varianza y Desviación Estándar | Introducción,” June. https://www.youtube.com/watch?v=oZRaDwnpXkY.\n\n\nMcClave, J. T., and T. Sincich. 2003. Statistics. Prentice Hall.\n\n\n“Varianza.” 2022. https://es.wikipedia.org/w/index.php?title=Varianza&oldid=144468342.\n\n\nZar, Jerrold H. 1999. Biostatistical Analysis. Pearson Education India."
  },
  {
    "objectID": "d_prob.html",
    "href": "d_prob.html",
    "title": "3  Distr. de Probabilidades",
    "section": "",
    "text": "Espacio muestral: El conjunto de todos los posibles resultados de un experimento aleatorio\nDiscreto: Si cada resultado puede ponerse en correspondencia uno a uno con enteros positivos\nContinuo: Si sus resultados consisten de un intervalo de números reales\n\n(Canavos 1988)"
  },
  {
    "objectID": "d_prob.html#distribución-de-probabilidad-discreta",
    "href": "d_prob.html#distribución-de-probabilidad-discreta",
    "title": "3  Distr. de Probabilidades",
    "section": "3.2 Distribución de Probabilidad Discreta",
    "text": "3.2 Distribución de Probabilidad Discreta\nSi X es una variable aleatoria;\n\nSe llamará a p(x) = P(X=x) función de probabilidad de la variable aleatoria X, si satisface las siguientes propiedades:\n\n\np(x)\\geq 0, \\forall \\ x\\in X\\\\\n\\Sigma_x p(x)=1\n\nLa función de distribución acumulativa de la variable aleatoria X, es la probabilidad de que X sea menor o igual a un valor específico de x y está dada por:\n\nF(x)\\equiv P(X\\leq x) = \\sum_{x_i\\leq x}p(x_i)\n\nPropiedades:\n\n\n0\\leq F(x)\\leq, \\forall x\n\nEntre 0 y 1\n\n\n\n\nF(x_i)\\geq F(x_i) si x_i\\geq x_j\n\nMientras más grande el número X, más probabilidad acumulada\n\n\n\n\nP(X>x)= 1-F(x)\n\nLa P acumulada de x es igual a 1 - la P del número.\n\n\n(Canavos 1988)"
  },
  {
    "objectID": "d_prob.html#distribución-normal",
    "href": "d_prob.html#distribución-normal",
    "title": "3  Distr. de Probabilidades",
    "section": "3.3 Distribución Normal",
    "text": "3.3 Distribución Normal\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\n3.3.1 Gráficar en la Distribución Normal\nDiferentes alternativas\n\nAlternative 1: doing the math ourselvesAlternative 2: using dnorm()alternative 3: using cruve()\n\n\n\nx = seq(-4, 4, length = 200)\ny = 1 / sqrt(2 * pi) * exp(-x ^ 2 / 2)\n\nplot(x, y, type = \"l\", lwd = 4, col = \"red\", las = 1)\nabline(v = mean(x), col=\"gray60\")\n\n\n\n\n\n\n\nx = seq(-4,4,length=200)\ny = dnorm(x)\nplot(x, y, type = \"l\", lwd = 4, col = \"blue\", las = 1) # probar distintos argumentos\n\n\n\n#https://www.learnbyexample.org/r-plot-function/\n\n\n\n\ncurve(dnorm(x), -4, 4, col='green', ylab='y', lwd=4, las=1)\n\n\n\n\n\n\n\ndiferentes media y misma desviación estandar\n\ndiferentes \\mu y misma \\sigmaDiferente \\sigma ymismo \\mu\n\n\n\ncurve(dnorm(x, mean=0, sd=1), -4, 4, col='blue', ylab='f(x)', lwd=2, las=1)\ncurve(dnorm(x, mean=1, sd=1), -4, 4, col='red', lwd=2, add=TRUE)\ncurve(dnorm(x, mean=2, sd=1), -4, 4, col='green', lwd=2, add=TRUE)\nlegend('topleft', legend=c('mean=0; sd=1','mean=1; sd=1','mean=2; sd=1'),\n       lwd=2, col=c('blue','red','green'), bty='n')\n\n\n\n\n\n\n\ncurve(dnorm(x, mean=0, sd=1), -4, 4, col='blue', ylab='f(x)', lwd=2, las=1)\ncurve(dnorm(x, mean=0, sd=1.5), -4, 4, col='red', lwd=2, add=TRUE)\ncurve(dnorm(x, mean=0, sd=2), -4, 4, col='green', lwd=2, add=TRUE)\n#abline(v = 0, lty = 2, col = 'gray')\nlegend('topleft', legend=c('mean=0; sd=1','mean=0; sd=1.5','mean=0; sd=2'),\n       lwd=2, col=c('blue','red','green'), bty='n')\n\n\n\n\n\n\n\nDistribuciópn Acumulada\n\nprob <- pnorm(1, mean=0, sd=1)\nprob # percentage\n\n[1] 0.8413447\n\nxmin <- -4\nxmax <- 1\n\nx = seq(xmin, xmax, length=200)\ny = dnorm(x)\n\ncurve(dnorm(x), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1, main = 'Distribucion')\n\npolygon(c(xmin, x, xmax), c(0, y, 0), col = \"gray\")\ntext(0, 0.1, round(prob, 2), col = \"Red\")\n\n\n\n\n\nmean +- 1 sd = 68% measurementsprobability of having a value over 1.4?\n\n\nP(-1 <= x <= 1)\n\nprob <- pnorm(1) - pnorm(-1)\nprob\n\n[1] 0.6826895\n\nxmin <- -1\nxmax <- 1\n\nx = seq(xmin, xmax, length = 200)\ny = dnorm(x)\n\ncurve(dnorm(x), -4, 4, col = 'red', ylab='y', lwd = 2, las = 1)\npolygon(c(xmin, x, xmax), c(0, y, 0), col = \"gray\")\ntext(0, 0.1, round(prob, 3), col = \"Red\")\n\n\n\n\n\n\nP(x >= 1.4)\n\nprob <- 1-pnorm(1.4)\nprob\n\n[1] 0.08075666\n\nxmin <- 1.4\nxmax <- 4\n\nx = seq(xmin, xmax, length = 200)\ny = dnorm(x)\n\ncurve(dnorm(x), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1)\npolygon(c(xmin, x, xmax), c(0, y, 0), col = \"gray\")\ntext(1.8, 0.03, round(prob, 3), col = \"Red\")"
  },
  {
    "objectID": "d_prob.html#estadígrafos",
    "href": "d_prob.html#estadígrafos",
    "title": "3  Distr. de Probabilidades",
    "section": "3.4 Estadígrafos",
    "text": "3.4 Estadígrafos\nQuantile–quantile plot (Q-Q plot): Gráfico traza las muestras clasificadas de nuestra distribución contra un número similar de cuantiles clasificados tomados de una distribución normal. Si la muestra está distribuida normalmente, la línea será recta. Las desviaciones de la normalidad aparecen como varios tipos de no linealidad (por ejemplo, formas de S o formas de plátano). Las funciones que necesita son qqnorm y qqline (gráfico de cuantiles contra una distribución normal):\n\n\nholaa\n\ndsds"
  },
  {
    "objectID": "d_prob.html#tarea",
    "href": "d_prob.html#tarea",
    "title": "3  Distr. de Probabilidades",
    "section": "3.5 Tarea",
    "text": "3.5 Tarea"
  },
  {
    "objectID": "t_limite_central.html",
    "href": "t_limite_central.html",
    "title": "4  Teorema del Límite Central",
    "section": "",
    "text": "El teorema central del límite (TCL) es una teoría estadística que establece que, dada una muestra aleatoria suficientemente grande de la población, la distribución de las medias muestrales seguirá una distribución normal.\nSi se toman muestras repetidas de una población con varianza ﬁnita y se calculan sus promedios, entonces los promedios se distribuirán normalmente.\nEsto es verdad incluso cuando las muestras son tomadas de una distribución NO normal, siempre y cuando se tomen el suficiente número de muestras."
  },
  {
    "objectID": "t_limite_central.html#demostración-en-r",
    "href": "t_limite_central.html#demostración-en-r",
    "title": "4  Teorema del Límite Central",
    "section": "4.2 Demostración en R",
    "text": "4.2 Demostración en R\nCalculemos la media de cinco números aleatorios distribuidos uniformemente entre 0 y 10. La media será baja cuando obtengamos, ej., 2,3,1,2,1 y alta cuando obtengamos 9,8,9,6,8. Lo normal es que la media se acerque a 5. Hagamos esto 10.000 veces y observamos la distribución de las 10.000 medias. Los datos se distribuyen de forma rectangular (uniforme) en el intervalo de 0 a 10, por lo que la distribución de los datos brutos debería ser plana:\n\n# distribución de 10.000 números \n# aleatorios entre 0-10\nhist(runif(10000)*10, main=\"\")\n\n\n\nset.seed(1234) # fijar semilla para que el proceso aleatorio sea siempre igual\nA <- runif(10000)*10 # distribucion aleatoria uniforme\nhist(A)\n\n\n\n# media de la poblacion\nmediaA <- mean(A)\n\n¿Qué ocurre con la distribución de las medias muestrales, basada en la toma de sólo cinco números aleatorios uniformemente distribuidos?\n\n# creamos un vector numérico vacío de tamaño 10.000\nmeans <- numeric(10000)\n# llenamos el vector vacío con medias de 5 números aleatorios\nfor (i in 1:10000){\nmeans[i] <- mean(runif(5)*10)\n}\n\nhist(means,ylim=c(0,1600),main=\"\")\n\n\n\n\nSe ve bien, pero ¿cuan cerca está de una distribución normal?\n\nDibujar un distribución normal teórica usando X y S de la muestra.\nTest de normalidad.\n\n\nm <- mean(means)\ndesv <- sd(means)\n\nxv <- seq(0,10, 0.1)\nyv <-  dnorm(xv, mean = m, sd = desv)\n\nhist(means,ylim=c(0,1600),main=\"\")\nlines(xv, yv)\n\n\n\n\n\n4.2.1 Test de Normalidad\n\nqqnorm(means)\nqqline(means, lty=2)\n\n\n\nshapiro.test(sample(x = means, 5000))\n\n\n    Shapiro-Wilk normality test\n\ndata:  sample(x = means, 5000)\nW = 0.99905, p-value = 0.006669\n\n\nFunción para generar muestras de medias y visualiza el histograma\n\ngenerar_muestras_de_medias <- function(numero, muestras = 5){\n  means <- numeric(numero)\n  for (i in 1:numero){ means[i] <- mean(runif(muestras)*10) }\n  hist(means, main = paste('Distribucion', i, 'muestras'))\n}\n\nDiferencias entre medias muestrales con diferentes repeticiones\n\n# como se ven las diferencias entre medias muestrales con diferentes repeticiones?\npar(mfrow = c(2, 2))\nfor(i in c(10, 100, 1000, 100000)){\n  generar_muestras_de_medias(i)\n}\n\n\n\n\nDistribuciones en n\n\n\n\n\n\n\n4.2.2 Incrementar el número muestral\nCuando seleccionamos muestras de una distribución normal, la distribución de las medias muestrales de la muestra también tiene una forma “normal”.\nAumentar el tamaño muestral disminuye la dispersión.\n\nmeans <- numeric(5000)\nfor (i in 1:5000){ \n  means[i] <- mean(runif(5)*10) \n  }\n\nhist(means, col = 'lightblue', main = '')\n\n\n\n\nDistribución normal de 5000 muestras\n\n\n\n\n\nplot(density(means), main = '5.000 muestras')\nabline(v = 5, lty = 2, col = \"red\")\n\n\n\n\nvalor de la media de todas estas medias muestreales\n\n\n\nmean(means)\n\n[1] 4.977626\n\nsd(means)\n\n[1] 1.296756\n\n# media de la poblacion?\nmediaA\n\n[1] 5.003123\n\n\nEste comportamiento parece bastante razonable. Se esperaría una estimación más precisa de la media de la población original si tomamos la media de muestras de mayor tamaño.\n\n\n4.2.3 Distribución muestral de X\nMedia de la distribución muestral es = a las media de la población original\n\\mu_{\\bar{x}}=E(\\bar{x})=\\mu\nDesviación estándar de la distribución muestral igual:\n\\sigma_{\\bar{x}}=\\frac{\\sigma}{\\sqrt{n}} Este es el error estándar de la media.\n\n\n\nError estándar de la media\n\n\n\n\n4.2.4 Ajustar una curva normal\n\n# generar datos entre 0-1\nxv <- seq(0,10,0.1)\ndnorm(xv, mean = mean(means), sd = sd(means))\n\n  [1] 0.0001943350 0.0002605044 0.0003471333 0.0004598275 0.0006054955\n  [6] 0.0007925820 0.0010313233 0.0013340214 0.0017153317 0.0021925564\n [11] 0.0027859336 0.0035189095 0.0044183769 0.0055148635 0.0068426465\n [16] 0.0084397733 0.0103479613 0.0126123539 0.0152811078 0.0184047900\n [21] 0.0220355671 0.0262261737 0.0310286566 0.0364928978 0.0426649328\n [26] 0.0495850913 0.0572860011 0.0657905072 0.0751095740 0.0852402473\n [31] 0.0961637610 0.1078438832 0.1202255942 0.1332341894 0.1467748933\n [36] 0.1607330553 0.1749749848 0.1893494580 0.2036899049 0.2178172558\n [41] 0.2315433947 0.2446751414 0.2570186494 0.2683840879 0.2785904518\n [46] 0.2874703311 0.2948744665 0.3006759172 0.3047736796 0.3070956111\n [51] 0.3076005435 0.3062794967 0.3031559445 0.2982851205 0.2917523940\n [56] 0.2836707811 0.2741776932 0.2634310538 0.2516049365 0.2388848918\n [61] 0.2254631380 0.2115337888 0.1972882800 0.1829111425 0.1685762449\n [66] 0.1544436036 0.1406568265 0.1273412300 0.1146026351 0.1025268240\n [71] 0.0911796125 0.0806074751 0.0708386426 0.0618845848 0.0537417828\n [76] 0.0463936984 0.0398128491 0.0339629072 0.0288007499 0.0242784005\n [81] 0.0203448121 0.0169474606 0.0140337237 0.0115520364 0.0094528226\n [86] 0.0076892115 0.0062175523 0.0049977488 0.0039934361 0.0031720234\n [91] 0.0025046288 0.0019659284 0.0015339435 0.0011897846 0.0009173703\n [96] 0.0007031344 0.0005357342 0.0004057679 0.0003055086 0.0002286580\n[101] 0.0001701245\n\nhist(means, main = \"\", ylim = c(1,800)) \nyv <- dnorm(xv, mean = mean(means), sd = 1.28996)*2500\nlines(xv,yv)\n\n\n\n\n\n\n4.2.5 Test de Normalidad\n\nqqnorm(means)\nqqline(means, lty = 2, col = \"red\", lwd = 2)\n\n\n\n\nTest de Normalidad shapiro.test\n\n\n\nshapiro.test(means)\n\n\n    Shapiro-Wilk normality test\n\ndata:  means\nW = 0.99869, p-value = 0.0004339\n\n\np > 0.05 –> NO se rechaza H0 = es normal\np < 0.05 –> se rechaza H0 = NO es normal\nReferencias https://bookdown.org/dietrichson/metodos-cuantitativos/test-de-normalidad.html"
  },
  {
    "objectID": "t_limite_central.html#distribución-t-de-student",
    "href": "t_limite_central.html#distribución-t-de-student",
    "title": "4  Teorema del Límite Central",
    "section": "4.3 Distribución t de Student",
    "text": "4.3 Distribución t de Student\n\n\nt de Student\n\nEn probabilidad y estadística, la distribución t (de Student) es una distribución de probabilidad que surge del problema de estimar la media de una población normalmente distribuida cuando el tamaño de la muestra es pequeño y la desviación estándar poblacional es desconocida.\n\n\n\n\n\n\n\n\nNote\n\n\n\ncompletar formulación wiki\n\n\nSi el tamaño muestral (n) es muy largo (e.g., > 30), la distribución de t Student se aproxima a una distribución Normal.\n\npar(mfrow = c(1, 2))\ncurve(dt(x, df = 15), -4, 4, col = 'red', ylab = 'y', lwd = 2, las = 1, main = 'Dist. t Student')\ncurve(pt(x, df = 15), -4, 4, col = 'blue', ylab = 'y', lwd = 2, las = 1, main = 'Probabilidad t Student')\n\n\n\n\nlas distribuciones de probabilidad de la t student se generan a partir de dt y pt\n\n\n\n\nLa distribución Normal necesita de valores de \\mu y \\sigma. Acabamos de demostrar que no es posible estimar σ a partir de S:\n\nX es un estimador sin sesgo de \\mu\nS es un estimador sesgado de \\sigma\n\nt Student es una distribución que se describe con dos parámetros:\n\nX\nDF (deegrees of freedom), o grados de libertad\n\nTiene distinta forma según los grados de libertad (Degrees of freedom [DF])\nDF = ν = n - 1\nVariación de la distribucion de t Student con distintos DF\n\ndegf <- c(1, 3, 8, 30)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\", \"black\")\nlabels <- c(\"df = 1\", \"df = 3\", \"df = 8\", \"df = 30\", \"normal\")\n\n\npar(mfrow = c(1, 1))\ncurve(dnorm(x), -4, 4, lty=2, ylab='y', lwd=2, las=1)\n\n# plot t student's\nfor (i in 1:4){\n  curve(dt(x, degf[i]), lwd=2, col=colors[i], add=TRUE)\n}\n\nlegend(\"topright\", inset = .05, title = \"Distributions\", \n       labels, lwd = 2, lty = c(1, 1, 1, 1, 2), col = colors, bty = \"n\")\n\n\n\n\nLa distribución t se utiliza cuando:\n\nQueremos estimar la media de una población normalmente distribuida a partir de una muestra pequeña.\nTamaño de la muestra es inferior a 30 elementos, es decir, n < 30.\n\nNo se conoce la desviación típica o estándar de una población y tiene que ser estimada a partir de las observaciones de la muestra.\n ± 1 S\n67.3% No igual a Dist. Norm., pero Parecida\n\n4.3.1 Funciones para estimar el error\nEl error estándar: ::: {.cell}\nse <- function(x) { \n  sqrt(var(x)/length(x))\n}\n:::\nRango probable de valores para un Estadígrafo\nIntervalo de confianza = estadígrafo ± margen de error\n\nIntervConf <- function(x, alpha = 0.05) {\n  t.value <- qt((1-alpha), length(x)-1) # qt -> quantile function for t distrituion\n  standard.error <- se(x)\n  ci <- t.value*standard.error\n  cat(paste((1-alpha), \"Confidence Interval = \"), mean(x) - ci, \"to \", mean(x) + ci,\"\\n\") # concatenate and print\n  }\n\nIntervalo de confianza para estimar un parámetro de población, ej. la media:\nX ± t_{n-1} \\frac{S}{\\sqrt{n}}\nAplicación de la prueba\n\n# generamos datos de prueba\nx <- rnorm(150, 25, 3) # Recuerdan el orden de rnorm\nhist(x)\n\n\n\nmean(x)\n\n[1] 25.0514\n\n# intervalo deconfianza al 95%\nIntervConf(x)\n\n0.95 Confidence Interval =  24.63201 to  25.47079 \n\n# intervalo deconfianza al 99%\nIntervConf(x, alpha = 0.01)\n\n0.99 Confidence Interval =  24.45553 to  25.64727 \n\n\nNivel de confianza (alpha): Probabilidad que el intervalo de confianza contenga al parámetro de población\n\nEj., 95% de nivel de confianza\n\\alpha = 0.05; 1/20 veces de estar equivocado (Error tipo I)"
  },
  {
    "objectID": "correlaciones.html",
    "href": "correlaciones.html",
    "title": "5  Correlaciones",
    "section": "",
    "text": "https://es.wikipedia.org/wiki/Coeficiente_de_correlación_de_Pearson↩︎\nhttps://es.wikipedia.org/wiki/Coeficiente_de_correlación_de_Spearman↩︎\nhttps://es.wikipedia.org/wiki/Coeficiente_de_correlación_de_rango_de_Kendall↩︎"
  },
  {
    "objectID": "regresiones.html",
    "href": "regresiones.html",
    "title": "6  Regresiones",
    "section": "",
    "text": "Modelo estadístico que relaciona funcionalmente dos variables de forma lineal (una recta o, en su versión generalizada, un plano o un hiperplano). El caso más simple contiene una variable respuesta (Y; i.e. lo que se quiere explicar o predecir), y una variable explicativa o predictor (X; i.e., variables que se usan para explicar o predecir Y). A veces estas variables también son llamadas dependiente e independiente.\ny=b_0+b_1*x_1\nQue exista una relación funcional significativa entre ambas variables no implica una causalidad, pero la puede sugerir.\n\n\n\nDescripción de conceptos de la formula de regresión lineal\n\n\nCreación de una función predictiva específica para el problema planteado, con los datos usados\n\n\n\nEjemplo de Regresión Lineal Simple estima el Salario respecto a la experiencia\n\n\nModelo estadístico que relaciona funcionalmente dos variables de forma lineal (una recta o, en su versión generalizada, un plano o un hiperplano). El caso más simple contiene una variable respuesta (Y; i.e. lo que se quiere explicar o predecir), y una variable explicativa o predictor (X; i.e., variables que se usan para explicar o predecir Y). A veces estas variables también son llamadas dependiente e independiente.\nQue exista una relación funcional significativa entre ambas variables no implica una causalidad, pero la puede sugerir."
  },
  {
    "objectID": "regresiones.html#regresión-lineal-múltiple",
    "href": "regresiones.html#regresión-lineal-múltiple",
    "title": "6  Regresiones",
    "section": "6.2 Regresión lineal múltiple",
    "text": "6.2 Regresión lineal múltiple\ny = b0 + b1*x1 + b2*x2 + b3*x3 + … + bn*xn\n\nLos coeficientes representan el cambio medio en la variable de respuesta para una unidad de cambio en la variable de predicción, manteniendo constantes los demás predictores del modelo. Ej:\nContaminación aire = 0 + 0.8*#Habitantes + 0.4*#Autos\nEl coeficiente indica que por cada habitante que se agregue al sistema hay un aumento de 0.8 (unidad) de contaminación; si se aumenta un auto hay un aumento de 0.5 (unidad) de contaminación, etc.\nSe puede entender también como la importancia de las variables en el modelo\n  ### Métricas de Ajustes de los modelos\nLas métricas de regresiones buscan ver cuán parecido, cuanto error, o cuanto sesgo tienen los valores observados versus los predichos por el modelo. Las métricas más comunes son:\n\nError cuadrático medio (mean square error; MSE)\nRaíz del error cuadrático medio (root mean square error; RMSE)\nRaíz del error cuadrático medio normalizada (normalized root mean square error; nRMSE)\nCoeficiente de determinación (coefficient of determination; R2)\nSesgo (bias)\n\nError cuadrático medio (MSE): Mide el error o distancia media entre los valores predichos y los observados. O entre los puntos y la recta ajustada del modelo (líneas rojas en el ejemplo de abajo). Valores más bajos son deseables.\n\nMSE <- mean((Obs-Pred)^2)\n\nagregar formulas\nRaíz de MSE (RMSE): Es la raíz cuadrada de MSE. La ventaja de RMSE sobre MSE, es que presenta valores de error en la unidad de medida de la variable observada. Por esta razón es una de las métricas más utilizadas.\n\nRMSE <- sqrt(MSE)\n\nagregar formulas\nRaíz de MSE normalizada (nRMSE): Es el RMSE pero normalizado por las observaciones de la variable respuesta. Esta normalización se puede hacer utilizando la media o el rango de las observaciones. La ventaja es que el error es presentado en porcentaje (0-1 o 0-100), con lo cual es mejor para comparar modelos que utilizan distintas variables o set de datos.\n\nNRMSE <- RMSE/max(Obs)-min(Obs)\n\nagregar formulas\n\n\n\nMétricas del error"
  },
  {
    "objectID": "regresiones.html#coeficiente-de-determinación-r2",
    "href": "regresiones.html#coeficiente-de-determinación-r2",
    "title": "6  Regresiones",
    "section": "6.3 Coeficiente de determinación (R^2)",
    "text": "6.3 Coeficiente de determinación (R^2)\nEl coeficiente de determinación (o el cuadrado de la correlación de Pearson) es una de las métricas más utilizadas. Si bien esta es muy útil, pueden haber ocasiones donde valores altos de R² se obtienen cuando la dispersión o error de las predicciones es alta. Los valores van entre 0 y 1. Es una medida de ajuste relativa (porcentual), por lo que puede ser usada para comparar modelos entre sí.\nAgregar formula\n\nT = número de observaciones,\nYt = variables observadas,\nŶt = variables predichas por el modelo,\nY = es la media de las variables observadas."
  },
  {
    "objectID": "regresiones.html#sesgo",
    "href": "regresiones.html#sesgo",
    "title": "6  Regresiones",
    "section": "6.4 Sesgo",
    "text": "6.4 Sesgo\nEl sesgo indica si hay una distribución sistemática de los errores del modelo. Mientras más cercano a cero, menos sesgo (errores aleatorios), mientras más grande, ya sea positivo o negativo, indica que hay errores no aleatorios.\n\nValores negativos: el modelo tiende a subestimar valores de Y\nValores positivos: el modelo tiende a sobrestimar valores de Y\n\nHay muchas formas de estimar el sesgo, no es una fórmula específica\n\n\n\nAnálisis visual de los Sesgos"
  },
  {
    "objectID": "regresiones.html#residuos",
    "href": "regresiones.html#residuos",
    "title": "6  Regresiones",
    "section": "6.5 Residuos",
    "text": "6.5 Residuos\nLos residuos son la diferencia entre los valores observados y los predichos (obs - pred). Los residuos se utilizan mucho en post-hoc tests (o tests para analizar los resultados de los modelos). Los residuos, por un lado, dan estimaciones de posibles sesgos del modelo.\nEs muy importante que los residuos se distribuyan de manera aleatoria en el modelo.\n\nUn modelo con errores altos (ej., RMSE) y sesgos y residuos bajos puede ser considerado bueno bajo algunas circunstancias, ya que sus errores son independientes, y se distribuyen de forma aleatoria.\nUn modelo con ajuste alto (R2) y error bajo (RMSE) pero con sesgos muy altos debe ser descartado ya que comete errores sistemáticos.\n\n\n\n\nVisualización de los residuos\n\n\n\n\n\nTipos de los residuos\n\n\nOutput Modelo de Regresión\n\n\n\nOutput de modelos de regesión"
  },
  {
    "objectID": "regresiones.html#distribución-f-de-fisher",
    "href": "regresiones.html#distribución-f-de-fisher",
    "title": "6  Regresiones",
    "section": "6.6 Distribución F de Fisher",
    "text": "6.6 Distribución F de Fisher\nComparar si hay diferencias significativas entre dos varianzas. En caso de las regresiones proporciona esencialmente una medida de la cantidad de variación que explica el modelo frente a la cantidad de variación no explicada (por grados de libertad restantes).\n\nH0: El modelo NO explica la varianza de los datos Y\nH1: El modelo SI explica la varianza de los datos Y\n\nValores de F altos significa que su modelo explica mucho más de la variación por parámetro que el error por grado de libertad restante. No es sumamente importante este valor por ahora!\nP-valor: probabilidad de que el la H0 sea verdad. P-valores significativos, ej., bajo alpha = 0.05, lleva a interpretar la probabilidad de que el modelo de regresión no explique una porción significativa de la varianza de Y es baja.\nSe pueden comparar dos modelos lineales para ver cual es mejor utilizando un análisis de varianza (ANOVA) y el criterio Akaike.\nANOVA: Análisis de varianza para ver si hay si hay diferencia entre la varianza explicada de los dos modelos (F de Fisher).\n\n# Ej., \nlm1 <- lm(y~x1)\nlm2 <- lm(y~x1+x2+x3)\nanova(lm1, lm2)\n\nConcepto de Parsimonia implica:\n\nMientras más simple, mejor.\nLinear es mejor que no-lineal\nParamétrico es mejor que no-paramétrico\n\nExisten otras formas de comparar tros modelos lineales"
  },
  {
    "objectID": "regresiones.html#akaikes-information-criteria-aic",
    "href": "regresiones.html#akaikes-information-criteria-aic",
    "title": "6  Regresiones",
    "section": "6.7 Akaike’s information criteria (AIC):",
    "text": "6.7 Akaike’s information criteria (AIC):\nAIC busca un balance entre la capacidad predictiva de un modelo (la varianza explicada) y la cantidad de parámetros que este debe considerar para lograr un mejor ajuste.\nEs decir, premia a los modelos a medida que aumentan la varianza explicada, pero simultáneamente los penaliza a medida que aumentan el número de parámetros.\nEl criterio de Akaike es de parsimonia, el mejor ajuste con el menor número de parámetros posibles.\nLos valores más bajos de AIC son preferibles. El valor en sí mismo no tiene mucha importancia, ya que depende del caso de estudio en particular, los datos particulares, etc.\n\nAIC(lm1, lm2)"
  },
  {
    "objectID": "regresiones.html#casos-aplicado",
    "href": "regresiones.html#casos-aplicado",
    "title": "6  Regresiones",
    "section": "6.8 Casos Aplicado",
    "text": "6.8 Casos Aplicado\n\n6.8.1 Lectura de Datos\n\ndata <- read.table('data/Pantanillos.txt', header = T)\n\n\n\n\n\n \n  \n    XUTM \n    YUTM \n    LAT \n    LONG \n    BIOMAS \n    TM1 \n    TM2 \n    TM3 \n    TM4 \n    TM5 \n    TM7 \n    BRIGHT \n    GREEN \n    MOIST \n    NDVI \n    NDVIC \n    PEND \n    ALT \n    H \n  \n \n\n  \n    744797.3 \n    6071183 \n    -35.473 \n    -72.302 \n    164.649 \n    43 \n    29 \n    23 \n    57 \n    26 \n    15 \n    83.854 \n    -0.004 \n    -4.548 \n    0.425 \n    0.321 \n    6.546 \n    472.423 \n    17.106 \n  \n  \n    745007.3 \n    6071183 \n    -35.473 \n    -72.300 \n    88.663 \n    48 \n    36 \n    37 \n    66 \n    53 \n    32 \n    109.035 \n    -9.390 \n    -29.607 \n    0.282 \n    0.141 \n    17.793 \n    491.138 \n    2.838 \n  \n  \n    744587.3 \n    6071243 \n    -35.472 \n    -72.304 \n    127.707 \n    42 \n    31 \n    22 \n    54 \n    29 \n    17 \n    82.817 \n    -2.611 \n    -8.038 \n    0.421 \n    0.306 \n    10.933 \n    466.259 \n    9.288 \n  \n  \n    744797.3 \n    6071363 \n    -35.471 \n    -72.302 \n    203.209 \n    43 \n    29 \n    23 \n    62 \n    28 \n    15 \n    87.794 \n    3.431 \n    -5.745 \n    0.459 \n    0.338 \n    15.306 \n    497.456 \n    13.273 \n  \n  \n    745007.3 \n    6071363 \n    -35.471 \n    -72.300 \n    101.979 \n    43 \n    33 \n    24 \n    84 \n    40 \n    20 \n    108.640 \n    15.278 \n    -15.202 \n    0.556 \n    0.347 \n    28.135 \n    471.417 \n    12.141 \n  \n  \n    744587.3 \n    6071423 \n    -35.471 \n    -72.304 \n    185.372 \n    44 \n    29 \n    22 \n    53 \n    27 \n    16 \n    81.422 \n    -2.956 \n    -5.942 \n    0.413 \n    0.308 \n    18.362 \n    484.353 \n    9.874 \n  \n\n\n\n\n\n\n6.8.1.1 Revisión espacial de los datos\n\ndata_sf <-  data %>%  sf::st_as_sf(coords = c(\"LONG\", \"LAT\"), crs = 4326)\nmapview::mapview(data_sf, zcol=\"BIOMAS\")\n\n\n\n\n\n\nDefinición de Variables Dependiente e Independiente\n\nX <- data[ ,6:19]\nY <- data$BIOMAS\n\n\n\n\n6.8.2 Correlaciones\nVamos a seleccionar una variable X por mientras para ver una regresion simple podemos usar una simple correlacion para ver que predictor se relaciona mas con la biomasa.\n\ncor(X, Y, method = \"pearson\")\n\n              [,1]\nTM1    -0.31361610\nTM2    -0.36579661\nTM3    -0.27179254\nTM4    -0.46393079\nTM5    -0.35940473\nTM7    -0.29321630\nBRIGHT -0.46834630\nGREEN   0.06247448\nMOIST   0.32239600\nNDVI    0.11752383\nNDVIC   0.27767911\nPEND    0.10787286\nALT     0.06590560\nH       0.60544860\n\n# cor(X)\n\nVisualización de las correlaciones\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\ncorr <- cor(data[,5:19])\ncorrplot(corr, type='upper', method = \"square\")\n\n\n\n\n\n\n\n\n\n6.8.3 Regresión Lineal Simple\nCálculo de la Regresión Lineal\n\nlm1 <- lm(BIOMAS ~ H, data = data)\n# lm1 <- lm(Y ~ X$H)lm1 <- lm(Y ~ X$H)\n\nExplorar los resultados del Modelo\n\nsummary(lm1)\n\n\nCall:\nlm(formula = BIOMAS ~ H, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-171.840  -28.994   -9.999   31.554  202.631 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   29.215      8.057   3.626 0.000479 ***\nH              7.464      1.040   7.177 2.05e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.1 on 89 degrees of freedom\nMultiple R-squared:  0.3666,    Adjusted R-squared:  0.3595 \nF-statistic:  51.5 on 1 and 89 DF,  p-value: 2.05e-10\n\n\nReferecias para explicar los modelos en R: (“Explaining the Lm() Summary in R – Learn by Marketing” n.d.)\n\nplot_summs(lm1)\n\nRegistered S3 methods overwritten by 'broom':\n  method            from  \n  tidy.glht         jtools\n  tidy.summary.glht jtools\n\n\nLoading required namespace: broom.mixed\n\n\n\n\neffect_plot(lm1, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\nAtributos del Modelo\n\nfitted(lm1)resid(lm1)coef(lm1)confint(lm1)vcov(lm1)rstandard(lm1)anova(lm1)\n\n\nValores ajustados, equivale a lm1$fitted.values\n\nfitted(lm1)\n\n        1         2         3         4         5         6         7         8 \n156.88779  50.39718  98.53738 128.27982 119.83103 102.91105  63.93614  60.08493 \n        9        10        11        12        13        14        15        16 \n104.23211  83.30418  80.89344  54.32303  70.15332  37.13436  34.45493  56.01727 \n       17        18        19        20        21        22        23        24 \n 49.04627  72.52675  79.38579  95.52209  63.70477  65.24974  71.24301  61.44330 \n       25        26        27        28        29        30        31        32 \n 30.57386  50.92709  51.64360  54.36035  62.19713  36.11185  34.67884  52.58401 \n       33        34        35        36        37        38        39        40 \n 64.34664  35.39534  34.87289  38.82860  58.77133  39.32120  69.58609  78.97529 \n       41        42        43        44        45        46        47        48 \n 35.09680 122.92842  57.30101 137.13911 150.32729  63.81673 141.55010 168.30710 \n       49        50        51        52        53        54        55        56 \n131.89967 108.71773  63.40623  99.51512 137.28839 125.94372 106.60553  32.98460 \n       57        58        59        60        61        62        63        64 \n 41.46325  96.23860  71.73560  29.21549 138.07953  98.91056 150.52135 114.18109 \n       65        66        67        68        69        70        71        72 \n 31.43964  30.87240  62.61509  30.00663  37.47022  35.17144 212.56624 125.07048 \n       73        74        75        76        77        78        79        80 \n 90.35728  29.36476  51.68092  30.38727  31.89492  34.56689  35.62672  36.07453 \n       81        82        83        84        85        86        87        88 \n 46.14293  68.04112  65.66770  57.03232  48.13571  33.66379  49.76277  36.90299 \n       89        90        91 \n 36.38054  50.88977  53.68116 \n\n\n\n\nresiduos, equivale a lm1$residuals\n\nresid(lm1)      \n\n          1           2           3           4           5           6 \n   7.761206   38.265823   29.169615   74.929177  -17.852030   82.460947 \n          7           8           9          10          11          12 \n  58.796856   33.938073  -38.262110  -20.012181   38.520561    9.144971 \n         13          14          15          16          17          18 \n  11.074679   65.181637  -23.405931  -27.581266  -15.812266   58.633255 \n         19          20          21          22          23          24 \n -39.960792  -31.718091  -55.358772    2.211263  -62.109006  -12.198302 \n         25          26          27          28          29          30 \n -25.504860  -44.329092  -38.534598  -44.839347  -23.402125  -26.973850 \n         31          32          33          34          35          36 \n -28.195839   15.671989   39.747358  -32.397345  -31.874893  -23.883600 \n         37          38          39          40          41          42 \n -50.244334  -32.176197  -39.591088    8.008706  -31.092801   71.049577 \n         43          44          45          46          47          48 \n -27.682005  107.308886   55.306708    2.781274   60.096900  -94.215100 \n         49          50          51          52          53          54 \n   5.693332    4.259268    6.460772  -55.793116  -70.469386  202.631283 \n         55          56          57          58          59          60 \n  53.788466  -28.104602  -30.344250  -18.301596  -20.163604   -7.307485 \n         61          62          63          64          65          66 \n -16.941527  -92.306564   -5.982345   -7.136086  -14.867638   -7.617404 \n         67          68          69          70          71          72 \n  24.145913   37.936373   38.423775   11.302563 -171.840236   66.782524 \n         73          74          75          76          77          78 \n  49.858719   39.476243   -6.461916  -18.468270  -19.300917  152.183115 \n         79          80          81          82          83          84 \n  91.183284   66.780468   -9.998926  -26.560123  -37.237699  -19.908316 \n         85          86          87          88          89          90 \n -35.780707  -23.507790   -8.175771  -29.791991   -7.118540    8.905226 \n         91 \n  -1.176160 \n\n\n\n\ncoeficientes, equivale a lm1$coefficients\n\ncoef(lm1)       \n\n(Intercept)           H \n  29.215485    7.463598 \n\n\n\n\nintervalos de confianza para dichos coeficientes\n\nconfint(lm1)    \n\n                2.5 %    97.5 %\n(Intercept) 13.206435 45.224535\nH            5.397175  9.530021\n\n\n\n\ntabla de varianza-covarianza\n\nvcov(lm1)       \n\n            (Intercept)         H\n(Intercept)   64.914946 -6.160668\nH             -6.160668  1.081563\n\n\n\n\nresiduos estandarizados (dist. z)\n\nrstandard(lm1)  \n\n          1           2           3           4           5           6 \n 0.15389729  0.73982298  0.56449928  1.46330265 -0.34749910  1.59728295 \n          7           8           9          10          11          12 \n 1.13514238  0.65539190 -0.74137098 -0.38646113  0.74374731  0.17670935 \n         13          14          15          16          17          18 \n 0.21376464  1.26361310 -0.45406718 -0.53284772 -0.30577684  1.13173782 \n         19          20          21          22          23          24 \n-0.77148418 -0.61347793 -1.06878028  0.04268813 -1.19882496 -0.23554096 \n         25          26          27          28          29          30 \n-0.49533686 -0.85697946 -0.74487989 -0.86643196 -0.45185478 -0.52305285 \n         31          32          33          34          35          36 \n-0.54695653  0.30290150  0.76735215 -0.62833868 -0.61829219 -0.46281511 \n         37          38          39          40          41          42 \n-0.97040227 -0.62343551 -0.76419725  0.15461288 -0.60308534  1.38458456 \n         43          44          45          46          47          48 \n-0.53471896  2.10408491  1.09220942  0.05369612  1.18099673 -1.88317274 \n         49          50          51          52          53          54 \n 0.11136024  0.08262197  0.12473664 -1.07993497 -1.38184634  3.95342959 \n         55          56          57          58          59          60 \n 1.04281942 -0.54544260 -0.58765284 -0.35402625 -0.38919655 -0.14197977 \n         61          62          63          64          65          66 \n-0.33233882 -1.78647561 -0.11815437 -0.13864696 -0.28867393 -0.14792643 \n         67          68          69          70          71          72 \n 0.46620289  0.73689953  0.74482158  0.21922355 -3.58391038  1.30250579 \n         73          74          75          76          77          78 \n 0.96357987  0.76696255 -0.12490918 -0.35869754 -0.37470162  2.95221126 \n         79          80          81          82          83          84 \n 1.76836956  1.29495988 -0.19345720 -0.51268695 -0.71885512 -0.38456953 \n         85          86          87          88          89          90 \n-0.69203146 -0.45614254 -0.15808431 -0.57758225 -0.13802677  0.17215869 \n         91 \n-0.02272895 \n\n\n\n\nsignificancia de la influencia de las variables\n\nanova(lm1)    \n\nAnalysis of Variance Table\n\nResponse: BIOMAS\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nH          1 139779  139779  51.504 2.05e-10 ***\nResiduals 89 241539    2714                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "regresiones.html#modelo-de-regresion-multiple",
    "href": "regresiones.html#modelo-de-regresion-multiple",
    "title": "6  Regresiones",
    "section": "6.9 Modelo de Regresion Multiple",
    "text": "6.9 Modelo de Regresion Multiple\nCálculo de la Regresión Lineal Multiple\n\nlm2 <- lm(BIOMAS ~ H + TM2 + TM5, data = data)\nsummary(lm2)\n\n\nCall:\nlm(formula = BIOMAS ~ H + TM2 + TM5, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-162.26  -31.35  -11.10   28.64  200.80 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 75.50158   68.04392   1.110    0.270    \nH            6.89284    1.19982   5.745 1.33e-07 ***\nTM2         -1.25048    3.03877  -0.412    0.682    \nTM5          0.01689    1.04880   0.016    0.987    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.39 on 87 degrees of freedom\nMultiple R-squared:  0.3737,    Adjusted R-squared:  0.3521 \nF-statistic:  17.3 on 3 and 87 DF,  p-value: 6.754e-09\n\n\n\nplot_summs(lm2, robust = TRUE, plot.distributions = TRUE, inner_ci_level = .9)\n\n\n\n\nComparación de Modelos con Anova\n\nanova(lm1, lm2)\n\nAnalysis of Variance Table\n\nModel 1: BIOMAS ~ H\nModel 2: BIOMAS ~ H + TM2 + TM5\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     89 241539                           \n2     87 238818  2    2721.2 0.4957 0.6109\n\n\nEl p-value del estadistico F es alto (Pr(>F) = 0.6109; mayor a 0.05), es decir, hay una probabilidad muy baja de que lm2 agregue algo a la varianza explicada, por lo que se podria decir que las variables TM2 y TM5 no agregan mas informacion Por lo tanto, el modelo lm1 seria el mejor en este caso por el principio de la parsimonia si dos modelos son iguales estadisticamente, el mas sensillo es mejor.\nComparación de Modelos con Akaike\nOtro criterio para seleccionar modelo es el AIC o Akaike Information Criterion. El AIC busca un balance entre la capacidad predictiva de un modelo (la varianza explicada) y la cantidad de parametros que este debe considerar para lograr un mejor ajuste. Es decir, premia a los modelos a medida que aumentan la varianza explicada, pero simultaneamente los penaliza a medida que aumentan el numero de parametros. El criterio de Akaike es de parsimonia, el mejor ajuste con el menor numero de parametros posibles. Los valores mas bajos de AIC son preferibles.\n\nAIC(lm1, lm2)\n\n    df      AIC\nlm1  3 981.6841\nlm2  5 984.6531\n\n\nAIC concuerda que lm1 es mejor en este caso\n\n\n\n\n“Explaining the Lm() Summary in R – Learn by Marketing.” n.d. Accessed September 2, 2022. https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/."
  },
  {
    "objectID": "val_models.html",
    "href": "val_models.html",
    "title": "7  Validación de Modelos",
    "section": "",
    "text": "Lectura de Datos\n\ndata <- read.table('data/Pantanillos.txt', header = T, sep = '')\n\n\n\n\n\n \n  \n    XUTM \n    YUTM \n    LAT \n    LONG \n    BIOMAS \n    TM1 \n    TM2 \n    TM3 \n    TM4 \n    TM5 \n    TM7 \n    BRIGHT \n    GREEN \n    MOIST \n    NDVI \n    NDVIC \n    PEND \n    ALT \n    H \n  \n \n\n  \n    744797.3 \n    6071183 \n    -35.473 \n    -72.302 \n    164.649 \n    43 \n    29 \n    23 \n    57 \n    26 \n    15 \n    83.854 \n    -0.004 \n    -4.548 \n    0.425 \n    0.321 \n    6.546 \n    472.423 \n    17.106 \n  \n  \n    745007.3 \n    6071183 \n    -35.473 \n    -72.300 \n    88.663 \n    48 \n    36 \n    37 \n    66 \n    53 \n    32 \n    109.035 \n    -9.390 \n    -29.607 \n    0.282 \n    0.141 \n    17.793 \n    491.138 \n    2.838 \n  \n  \n    744587.3 \n    6071243 \n    -35.472 \n    -72.304 \n    127.707 \n    42 \n    31 \n    22 \n    54 \n    29 \n    17 \n    82.817 \n    -2.611 \n    -8.038 \n    0.421 \n    0.306 \n    10.933 \n    466.259 \n    9.288 \n  \n  \n    744797.3 \n    6071363 \n    -35.471 \n    -72.302 \n    203.209 \n    43 \n    29 \n    23 \n    62 \n    28 \n    15 \n    87.794 \n    3.431 \n    -5.745 \n    0.459 \n    0.338 \n    15.306 \n    497.456 \n    13.273 \n  \n  \n    745007.3 \n    6071363 \n    -35.471 \n    -72.300 \n    101.979 \n    43 \n    33 \n    24 \n    84 \n    40 \n    20 \n    108.640 \n    15.278 \n    -15.202 \n    0.556 \n    0.347 \n    28.135 \n    471.417 \n    12.141 \n  \n  \n    744587.3 \n    6071423 \n    -35.471 \n    -72.304 \n    185.372 \n    44 \n    29 \n    22 \n    53 \n    27 \n    16 \n    81.422 \n    -2.956 \n    -5.942 \n    0.413 \n    0.308 \n    18.362 \n    484.353 \n    9.874 \n  \n\n\n\n\n\nFiltrar los datos\n\ndata2 <- data[,-c(1:4)]\n\n\n\n\n\n \n  \n    BIOMAS \n    TM1 \n    TM2 \n    TM3 \n    TM4 \n    TM5 \n    TM7 \n    BRIGHT \n    GREEN \n    MOIST \n    NDVI \n    NDVIC \n    PEND \n    ALT \n    H \n  \n \n\n  \n    164.649 \n    43 \n    29 \n    23 \n    57 \n    26 \n    15 \n    83.854 \n    -0.004 \n    -4.548 \n    0.425 \n    0.321 \n    6.546 \n    472.423 \n    17.106 \n  \n  \n    88.663 \n    48 \n    36 \n    37 \n    66 \n    53 \n    32 \n    109.035 \n    -9.390 \n    -29.607 \n    0.282 \n    0.141 \n    17.793 \n    491.138 \n    2.838 \n  \n  \n    127.707 \n    42 \n    31 \n    22 \n    54 \n    29 \n    17 \n    82.817 \n    -2.611 \n    -8.038 \n    0.421 \n    0.306 \n    10.933 \n    466.259 \n    9.288 \n  \n  \n    203.209 \n    43 \n    29 \n    23 \n    62 \n    28 \n    15 \n    87.794 \n    3.431 \n    -5.745 \n    0.459 \n    0.338 \n    15.306 \n    497.456 \n    13.273 \n  \n  \n    101.979 \n    43 \n    33 \n    24 \n    84 \n    40 \n    20 \n    108.640 \n    15.278 \n    -15.202 \n    0.556 \n    0.347 \n    28.135 \n    471.417 \n    12.141 \n  \n  \n    185.372 \n    44 \n    29 \n    22 \n    53 \n    27 \n    16 \n    81.422 \n    -2.956 \n    -5.942 \n    0.413 \n    0.308 \n    18.362 \n    484.353 \n    9.874 \n  \n\n\n\n\n\nHistograma de variable respuesta\n\n# histograma de variable respuesta\nhist(data$BIOMAS)"
  },
  {
    "objectID": "val_models.html#definición-de-funciones",
    "href": "val_models.html#definición-de-funciones",
    "title": "7  Validación de Modelos",
    "section": "7.2 Definición de Funciones",
    "text": "7.2 Definición de Funciones\nFunción para scatterplot\n\n# funcion para scatterplot\nplot_prediction <- function(obs, pred, main=''){\n  x <- cbind(obs, pred)\n  plot(x, xlab = 'Biomasa observada [kg m-2]', ylab = 'Biomasa predicha [kg m-2]', pch=16, las=1,\n       xlim = c(min(x), max(x)), ylim = c(min(x), max(x)), main=main, col=rgb(0,0,0,0.2), cex=1.5)\n  abline(0,1, lty=2)\n  lm <- lm(pred ~ obs-1)\n  abline(lm)\n  legend('topleft', legend=c('Linea 1:1', 'Linea ajustada'), lty=c(1,2), bty = 'n')\n  # agregar metricas de ajuste de modelo\n  r2 <- round( (cor(pred, obs)^2), 2) # solo dos decimales con funcion round\n  NRMSE <- round((sqrt(mean((obs - pred)^2))/(max(obs) - min(obs))) * 100, 2) # RMSE normalizado\n  bias = round( (1-coef(lm))*-1, 2)\n  mtext(bquote(paste(r^2 == .(r2), \",\", \" %RMSE\" == .(NRMSE), \"%\", \",\", \" bias\" ==\n                       .(bias))), side = 3, line = 0.5, adj = 0, font = 2)\n  \n}\n\nVisualización de Residuos\n\nplot_residuos <- function(res, pred, main='Modelo'){\n  par(mfrow=c(1,2))\n  plot(pred, res, xlab = 'Biomasa predicha [kg m-2]', ylab = 'Residuos [kg m-2]', pch=16, las=1,\n       main=main, col=rgb(0,0,0,0.2), cex=1.5)\n  abline(h=0, lty=2)\n  qqnorm(res)\n  qqline(res, lty=2)\n}"
  },
  {
    "objectID": "val_models.html#analisis",
    "href": "val_models.html#analisis",
    "title": "7  Validación de Modelos",
    "section": "7.3 Analisis",
    "text": "7.3 Analisis\n\n7.3.1 Análisis de Significancia de Corrección\n\ncorr <- cor(data2)\ntestRes = cor.mtest(data2, conf.level = 0.95) # matriz con valores de p\npar(mfrow=c(1,1))\ncorrplot(corr, p.mat = testRes$p, type = 'lower', diag = FALSE) # X a las no sign. con p > 0.05\n\n\n\ncor(data2) # mejor variable segun cor es one_mean\n\n            BIOMAS         TM1        TM2         TM3         TM4        TM5\nBIOMAS  1.00000000 -0.31361610 -0.3657966 -0.27179254 -0.46393079 -0.3594047\nTM1    -0.31361610  1.00000000  0.9620088  0.95921101  0.09765849  0.9063002\nTM2    -0.36579661  0.96200881  1.0000000  0.96123400  0.22164639  0.9364134\nTM3    -0.27179254  0.95921101  0.9612340  1.00000000  0.04443123  0.9426152\nTM4    -0.46393079  0.09765849  0.2216464  0.04443123  1.00000000  0.1900475\nTM5    -0.35940473  0.90630018  0.9364134  0.94261521  0.19004752  1.0000000\nTM7    -0.29321630  0.92326124  0.9328171  0.96913153  0.04712320  0.9762178\nBRIGHT -0.46834630  0.87680231  0.9366557  0.87721991  0.50462364  0.9265610\nGREEN   0.06247448 -0.84581862 -0.7924929 -0.89542924  0.39613113 -0.7977948\nMOIST   0.32239600 -0.89367594 -0.9159402 -0.94344351 -0.10547874 -0.9939164\nNDVI    0.11752383 -0.87593057 -0.8298394 -0.93068575  0.31098157 -0.8262571\nNDVIC   0.27767911 -0.91453558 -0.8983385 -0.95949090  0.08793446 -0.9193543\nPEND    0.10787286 -0.29088550 -0.2667467 -0.30306962  0.05054119 -0.1913806\nALT     0.06590560 -0.34638456 -0.2674291 -0.30541545  0.01988928 -0.2707978\nH       0.60544860 -0.47942172 -0.4819355 -0.43697984 -0.31427651 -0.4823196\n              TM7     BRIGHT       GREEN      MOIST       NDVI       NDVIC\nBIOMAS -0.2932163 -0.4683463  0.06247448  0.3223960  0.1175238  0.27767911\nTM1     0.9232612  0.8768023 -0.84581862 -0.8936759 -0.8759306 -0.91453558\nTM2     0.9328171  0.9366557 -0.79249292 -0.9159402 -0.8298394 -0.89833845\nTM3     0.9691315  0.8772199 -0.89542924 -0.9434435 -0.9306857 -0.95949090\nTM4     0.0471232  0.5046236  0.39613113 -0.1054787  0.3109816  0.08793446\nTM5     0.9762178  0.9265610 -0.79779485 -0.9939164 -0.8262571 -0.91935429\nTM7     1.0000000  0.8752779 -0.88290983 -0.9885743 -0.8979835 -0.94375520\nBRIGHT  0.8752779  1.0000000 -0.59146405 -0.8891844 -0.6518289 -0.79086476\nGREEN  -0.8829098 -0.5914641  1.00000000  0.8369327  0.9869514  0.92129745\nMOIST  -0.9885743 -0.8891844  0.83693272  1.0000000  0.8556265  0.92978569\nNDVI   -0.8979835 -0.6518289  0.98695136  0.8556265  1.0000000  0.95917534\nNDVIC  -0.9437552 -0.7908648  0.92129745  0.9297857  0.9591753  1.00000000\nPEND   -0.2282007 -0.2052176  0.27841863  0.1905210  0.3166394  0.28910470\nALT    -0.2832766 -0.2524166  0.28856127  0.2690036  0.3035372  0.30633676\nH      -0.4304685 -0.5347813  0.27232831  0.4517838  0.3362205  0.46368280\n              PEND         ALT           H\nBIOMAS  0.10787286  0.06590560  0.60544860\nTM1    -0.29088550 -0.34638456 -0.47942172\nTM2    -0.26674670 -0.26742907 -0.48193548\nTM3    -0.30306962 -0.30541545 -0.43697984\nTM4     0.05054119  0.01988928 -0.31427651\nTM5    -0.19138064 -0.27079776 -0.48231958\nTM7    -0.22820067 -0.28327655 -0.43046847\nBRIGHT -0.20521762 -0.25241661 -0.53478130\nGREEN   0.27841863  0.28856127  0.27232831\nMOIST   0.19052104  0.26900363  0.45178385\nNDVI    0.31663942  0.30353719  0.33622053\nNDVIC   0.28910470  0.30633676  0.46368280\nPEND    1.00000000  0.19853031  0.38709465\nALT     0.19853031  1.00000000  0.07529796\nH       0.38709465  0.07529796  1.00000000\n\n#corr\n\n\n\n7.3.2 Validación Cruzada\n\n# separar en set de validacion y entrenamiento: Validacion cruzada simple!\nset.seed(1234)\nidx <- createDataPartition(data2$BIOMAS, p = 0.6, list = F)\nlength(idx)\n\n[1] 56\n\nidx %>% head()\n\n     Resample1\n[1,]         1\n[2,]         5\n[3,]         8\n[4,]         9\n[5,]        11\n[6,]        12\n\n# 91*0.6 --> 54.6\n\n# particionar los datos usando los datos generados\nentrenar <- data2[idx,  ] # 60% de los datos \nvalidar  <- data2[-idx, ] # 40% de los datos"
  },
  {
    "objectID": "val_models.html#regresiones",
    "href": "val_models.html#regresiones",
    "title": "7  Validación de Modelos",
    "section": "7.4 Regresiones",
    "text": "7.4 Regresiones\n\n7.4.1 Regresiones Simples\n\nlm1 <- lm(BIOMAS ~ H, data = entrenar)\nsummary(lm1)\n\n\nCall:\nlm(formula = BIOMAS ~ H, data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-161.91  -31.59  -12.85   18.43  206.26 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   32.623     11.265   2.896  0.00545 ** \nH              6.921      1.430   4.840 1.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.64 on 54 degrees of freedom\nMultiple R-squared:  0.3026,    Adjusted R-squared:  0.2897 \nF-statistic: 23.43 on 1 and 54 DF,  p-value: 1.125e-05\n\n\nReferecias para explicar los modelos en R: (“Explaining the Lm() Summary in R – Learn by Marketing” n.d.)\n\neffect_plot(lm1, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\nlm2 <- glm(BIOMAS ~ H, data = entrenar, family = Gamma(link = \"log\"))\nsummary(lm2)\n\n\nCall:\nglm(formula = BIOMAS ~ H, family = Gamma(link = \"log\"), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.8159  -0.8806  -0.1909   0.3185   2.1156  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.58884    0.17418  20.605  < 2e-16 ***\nH            0.09849    0.02211   4.456 4.25e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.7669877)\n\n    Null deviance: 58.130  on 55  degrees of freedom\nResidual deviance: 43.909  on 54  degrees of freedom\nAIC: 580.9\n\nNumber of Fisher Scoring iterations: 7\n\neffect_plot(lm2, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\n\n7.4.2 Regresión Multiple\n\n## Regression multiple con todas las variables -----------------------------\nlm3 <- lm(BIOMAS ~., data = entrenar)\nsummary(lm3)\n\n\nCall:\nlm(formula = BIOMAS ~ ., data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-100.67  -31.30   -8.14   21.58  182.80 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)\n(Intercept)  4.993e+02  5.815e+02   0.859    0.395\nTM1          9.320e+00  2.906e+01   0.321    0.750\nTM2          1.533e+01  2.822e+01   0.543    0.590\nTM3          1.866e+01  3.699e+01   0.504    0.617\nTM4         -4.582e+00  3.919e+01  -0.117    0.908\nTM5         -1.410e+00  3.274e+01  -0.043    0.966\nTM7         -3.049e+00  2.650e+01  -0.115    0.909\nBRIGHT      -1.498e+01  5.023e+01  -0.298    0.767\nGREEN        2.388e+01  4.312e+01   0.554    0.583\nMOIST       -1.232e+01  4.067e+01  -0.303    0.764\nNDVI        -1.204e+03  1.728e+03  -0.697    0.490\nNDVIC        1.213e+03  8.425e+02   1.440    0.157\nPEND        -2.048e-01  1.008e+00  -0.203    0.840\nALT          1.759e-02  1.066e-01   0.165    0.870\nH            3.802e+00  2.285e+00   1.664    0.104\n\nResidual standard error: 57.21 on 41 degrees of freedom\nMultiple R-squared:  0.4599,    Adjusted R-squared:  0.2755 \nF-statistic: 2.494 on 14 and 41 DF,  p-value: 0.01162\n\neffect_plot(lm3, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\nlm4 <- glm(BIOMAS ~., data = entrenar, family = Gamma(link = log))\nsummary(lm4)\n\n\nCall:\nglm(formula = BIOMAS ~ ., family = Gamma(link = log), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4922  -0.7954  -0.1666   0.4182   1.5964  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  11.099546   9.159715   1.212   0.2325  \nTM1           0.437576   0.457743   0.956   0.3447  \nTM2           0.384137   0.444555   0.864   0.3926  \nTM3           0.448039   0.582720   0.769   0.4464  \nTM4          -0.035895   0.617363  -0.058   0.9539  \nTM5           0.027237   0.515759   0.053   0.9581  \nTM7          -0.018001   0.417409  -0.043   0.9658  \nBRIGHT       -0.503779   0.791271  -0.637   0.5279  \nGREEN         0.627758   0.679168   0.924   0.3607  \nMOIST        -0.271592   0.640674  -0.424   0.6738  \nNDVI        -20.985287  27.223143  -0.771   0.4452  \nNDVIC        15.108460  13.270804   1.138   0.2615  \nPEND          0.001204   0.015875   0.076   0.9399  \nALT          -0.001040   0.001679  -0.619   0.5391  \nH             0.080295   0.035993   2.231   0.0312 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.8120839)\n\n    Null deviance: 58.13  on 55  degrees of freedom\nResidual deviance: 36.52  on 41  degrees of freedom\nAIC: 595.41\n\nNumber of Fisher Scoring iterations: 14\n\neffect_plot(lm4, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\n\n\n7.4.3 Regresión multiple con seleccion de variables stepwise\nUtilizando train() utilizanndo el método “lmStepAIC”, que va a buscar las conbinaciones de modelos lineales, simples, luego con dos, tres, etc., bajo el criterio AIC . (Kuhn n.d.)\n\nlm5 <- train(BIOMAS ~., data = entrenar, method = \"lmStepAIC\")\nlm5$finalModel\n\nEl objeto caret lm5 guarda perfectamente cual es el mejor modelo, y se puede usar directamente para predecir, etc. Pero no se lleva bein caret con las funciones anova, AIC, así que vamos a usar las mejores variables y a hacer otro modelo\n\nlm5 <- lm(BIOMAS ~ TM3 + BRIGHT + NDVIC + H, data = entrenar)\nsummary(lm5)\n\n\nCall:\nlm(formula = BIOMAS ~ TM3 + BRIGHT + NDVIC + H, data = entrenar)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-99.37 -30.51 -13.02  21.00 181.98 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  105.909    147.888   0.716  0.47717   \nTM3           10.183      4.256   2.393  0.02045 * \nBRIGHT        -4.611      1.340  -3.441  0.00116 **\nNDVIC        487.008    305.084   1.596  0.11660   \nH              3.954      1.717   2.303  0.02538 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.46 on 51 degrees of freedom\nMultiple R-squared:  0.435, Adjusted R-squared:  0.3907 \nF-statistic: 9.818 on 4 and 51 DF,  p-value: 5.74e-06\n\neffect_plot(lm5, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)\n\n\n\n\nFamily: Gamma(link = log)\n\nlm6 <- train(BIOMAS ~., data = entrenar, method = \"glmStepAIC\", family = Gamma(link = log))\nlm6$finalModel\n\n\nlm6 <- glm(BIOMAS ~ TM3 + BRIGHT + H, data = entrenar, family = Gamma(link = \"log\"))\n\neffect_plot(lm6, pred = H, interval = TRUE, plot.points = TRUE, \n            jitter = 0.05)"
  },
  {
    "objectID": "val_models.html#información-de-modelos",
    "href": "val_models.html#información-de-modelos",
    "title": "7  Validación de Modelos",
    "section": "7.5 Información de modelos",
    "text": "7.5 Información de modelos\n\nsummary(lm1)\n\n\nCall:\nlm(formula = BIOMAS ~ H, data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-161.91  -31.59  -12.85   18.43  206.26 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   32.623     11.265   2.896  0.00545 ** \nH              6.921      1.430   4.840 1.12e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.64 on 54 degrees of freedom\nMultiple R-squared:  0.3026,    Adjusted R-squared:  0.2897 \nF-statistic: 23.43 on 1 and 54 DF,  p-value: 1.125e-05\n\nsummary(lm2)\n\n\nCall:\nglm(formula = BIOMAS ~ H, family = Gamma(link = \"log\"), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.8159  -0.8806  -0.1909   0.3185   2.1156  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.58884    0.17418  20.605  < 2e-16 ***\nH            0.09849    0.02211   4.456 4.25e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.7669877)\n\n    Null deviance: 58.130  on 55  degrees of freedom\nResidual deviance: 43.909  on 54  degrees of freedom\nAIC: 580.9\n\nNumber of Fisher Scoring iterations: 7\n\nsummary(lm3)\n\n\nCall:\nlm(formula = BIOMAS ~ ., data = entrenar)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-100.67  -31.30   -8.14   21.58  182.80 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)\n(Intercept)  4.993e+02  5.815e+02   0.859    0.395\nTM1          9.320e+00  2.906e+01   0.321    0.750\nTM2          1.533e+01  2.822e+01   0.543    0.590\nTM3          1.866e+01  3.699e+01   0.504    0.617\nTM4         -4.582e+00  3.919e+01  -0.117    0.908\nTM5         -1.410e+00  3.274e+01  -0.043    0.966\nTM7         -3.049e+00  2.650e+01  -0.115    0.909\nBRIGHT      -1.498e+01  5.023e+01  -0.298    0.767\nGREEN        2.388e+01  4.312e+01   0.554    0.583\nMOIST       -1.232e+01  4.067e+01  -0.303    0.764\nNDVI        -1.204e+03  1.728e+03  -0.697    0.490\nNDVIC        1.213e+03  8.425e+02   1.440    0.157\nPEND        -2.048e-01  1.008e+00  -0.203    0.840\nALT          1.759e-02  1.066e-01   0.165    0.870\nH            3.802e+00  2.285e+00   1.664    0.104\n\nResidual standard error: 57.21 on 41 degrees of freedom\nMultiple R-squared:  0.4599,    Adjusted R-squared:  0.2755 \nF-statistic: 2.494 on 14 and 41 DF,  p-value: 0.01162\n\nsummary(lm4)\n\n\nCall:\nglm(formula = BIOMAS ~ ., family = Gamma(link = log), data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4922  -0.7954  -0.1666   0.4182   1.5964  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  11.099546   9.159715   1.212   0.2325  \nTM1           0.437576   0.457743   0.956   0.3447  \nTM2           0.384137   0.444555   0.864   0.3926  \nTM3           0.448039   0.582720   0.769   0.4464  \nTM4          -0.035895   0.617363  -0.058   0.9539  \nTM5           0.027237   0.515759   0.053   0.9581  \nTM7          -0.018001   0.417409  -0.043   0.9658  \nBRIGHT       -0.503779   0.791271  -0.637   0.5279  \nGREEN         0.627758   0.679168   0.924   0.3607  \nMOIST        -0.271592   0.640674  -0.424   0.6738  \nNDVI        -20.985287  27.223143  -0.771   0.4452  \nNDVIC        15.108460  13.270804   1.138   0.2615  \nPEND          0.001204   0.015875   0.076   0.9399  \nALT          -0.001040   0.001679  -0.619   0.5391  \nH             0.080295   0.035993   2.231   0.0312 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.8120839)\n\n    Null deviance: 58.13  on 55  degrees of freedom\nResidual deviance: 36.52  on 41  degrees of freedom\nAIC: 595.41\n\nNumber of Fisher Scoring iterations: 14\n\nsummary(lm5)\n\n\nCall:\nlm(formula = BIOMAS ~ TM3 + BRIGHT + NDVIC + H, data = entrenar)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-99.37 -30.51 -13.02  21.00 181.98 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  105.909    147.888   0.716  0.47717   \nTM3           10.183      4.256   2.393  0.02045 * \nBRIGHT        -4.611      1.340  -3.441  0.00116 **\nNDVIC        487.008    305.084   1.596  0.11660   \nH              3.954      1.717   2.303  0.02538 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.46 on 51 degrees of freedom\nMultiple R-squared:  0.435, Adjusted R-squared:  0.3907 \nF-statistic: 9.818 on 4 and 51 DF,  p-value: 5.74e-06\n\nsummary(lm6)\n\n\nCall:\nglm(formula = BIOMAS ~ TM3 + BRIGHT + H, family = Gamma(link = \"log\"), \n    data = entrenar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7612  -0.7162  -0.1862   0.3547   1.6836  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.79928    1.37938   4.929 8.82e-06 ***\nTM3          0.05952    0.02484   2.396  0.02021 *  \nBRIGHT      -0.04705    0.01781  -2.641  0.01088 *  \nH            0.07821    0.02458   3.182  0.00247 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.6614027)\n\n    Null deviance: 58.130  on 55  degrees of freedom\nResidual deviance: 39.293  on 52  degrees of freedom\nAIC: 577.95\n\nNumber of Fisher Scoring iterations: 6\n\n\nPlot de diagnostico\n\npar(mfrow=c(2,2))\nplot(lm1)\n\n\n\nplot(lm2)\n\n\n\nplot(lm3)\n\n\n\nplot(lm4)\n\n\n\nplot(lm5)\n\n\n\nplot(lm6)"
  },
  {
    "objectID": "val_models.html#validación-independientes",
    "href": "val_models.html#validación-independientes",
    "title": "7  Validación de Modelos",
    "section": "7.6 Validación Independientes",
    "text": "7.6 Validación Independientes\n\n7.6.1 Predicción\n\npred1 <- predict(lm1, validar, type = 'response')\npred2 <- predict(lm2, validar, type = 'response')\npred3 <- predict(lm3, validar, type = 'response')\npred4 <- predict(lm4, validar, type = 'response')\npred5 <- predict(lm5, validar, type = 'response')\npred6 <- predict(lm6, validar, type = 'response')\n\n\n\n7.6.2 R^2\n\npostResample(validar$BIOMAS, pred1)\n\n      RMSE   Rsquared        MAE \n44.4093971  0.4945806 36.5128797 \n\npostResample(validar$BIOMAS, pred2)\n\n      RMSE   Rsquared        MAE \n47.5393225  0.4190765 37.4912978 \n\npostResample(validar$BIOMAS, pred3)\n\n      RMSE   Rsquared        MAE \n41.9033685  0.5493197 33.2810130 \n\npostResample(validar$BIOMAS, pred4)\n\n     RMSE  Rsquared       MAE \n51.073834  0.503803 36.899949 \n\npostResample(validar$BIOMAS, pred5)\n\n      RMSE   Rsquared        MAE \n42.2525620  0.5466302 35.0206725 \n\npostResample(validar$BIOMAS, pred6)\n\n      RMSE   Rsquared        MAE \n44.5042861  0.5289186 32.5334253 \n\n\n\n\n7.6.3 Plot de valores predichos vs observados\n\npar(mfrow=c(1,2))\nplot_prediction(validar$BIOMAS, pred1, main='lm simple') # nuestra funcion\nplot_prediction(validar$BIOMAS, pred2, main='GLM simple')\n\n\n\nplot_prediction(validar$BIOMAS, pred3, main='lm todo')\nplot_prediction(validar$BIOMAS, pred4, main='GLM todo')\n\n\n\nplot_prediction(validar$BIOMAS, pred5, main='lm seleccion')\nplot_prediction(validar$BIOMAS, pred6, main='GLM deleccion')\n\n\n\n\n\n\n7.6.4 Residuos\n\nres1 <- validar$BIOMAS - pred1\nres2 <- validar$BIOMAS - pred2\nres3 <- validar$BIOMAS - pred3\nres4 <- validar$BIOMAS - pred4\nres5 <- validar$BIOMAS - pred5\nres6 <- validar$BIOMAS - pred6\n\n\n\n7.6.5 Plot de residuos\nLos observados vs los predichos\n\nplot_residuos(res1, pred1) # nuestra funcion\n\n\n\nplot_residuos(res2, pred2)\n\n\n\nplot_residuos(res3, pred3)\n\n\n\nplot_residuos(res4, pred4)\n\n\n\nplot_residuos(res5, pred5)\n\n\n\nplot_residuos(res6, pred6)\n\n\n\n\n\n\n7.6.6 Histrogramas\n\npar(mfrow=c(1,2))\nhist(res1, main = 'lm simple')\nhist(res2, main = 'GLM simple')\n\n\n\nhist(res3, main = 'lm todo')\nhist(res4, main = 'GLM todo')\n\n\n\nhist(res5, main = 'lm seleccion')\nhist(res6, main = 'GLM seleccion')\n\n\n\n\n\n\n7.6.7 Shapiro Test\n\nH0 -> dist. normal H1 -> dist. no normal\n\n\nshapiro.test(res1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res1\nW = 0.96422, p-value = 0.3049\n\nshapiro.test(res2) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res2\nW = 0.94851, p-value = 0.102\n\nshapiro.test(res3) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res3\nW = 0.97745, p-value = 0.6747\n\nshapiro.test(res4) # no normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  res4\nW = 0.90988, p-value = 0.007368\n\nshapiro.test(res5) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res5\nW = 0.97574, p-value = 0.6182\n\nshapiro.test(res6) # no normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  res6\nW = 0.92007, p-value = 0.01432\n\n\n\n\n7.6.8 Significancia de las diferencias\n\nanova(lm1,lm2,lm3,lm4,lm5, lm6) # diferencias entre gaussianos\n\nAnalysis of Variance Table\n\nModel 1: BIOMAS ~ H\nModel 2: BIOMAS ~ H\nModel 3: BIOMAS ~ TM1 + TM2 + TM3 + TM4 + TM5 + TM7 + BRIGHT + GREEN + \n    MOIST + NDVI + NDVIC + PEND + ALT + H\nModel 4: BIOMAS ~ TM1 + TM2 + TM3 + TM4 + TM5 + TM7 + BRIGHT + GREEN + \n    MOIST + NDVI + NDVIC + PEND + ALT + H\nModel 5: BIOMAS ~ TM3 + BRIGHT + NDVIC + H\nModel 6: BIOMAS ~ TM3 + BRIGHT + H\n  Res.Df    RSS  Df Sum of Sq      F    Pr(>F)    \n1     54 173261                                   \n2     54     44   0    173217                     \n3     41 134181  13   -134137                     \n4     41     37   0    134144                     \n5     51 140355 -10   -140319 4.2876 0.0004042 ***\n6     52     39  -1    140316                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSería al menos 1 es diferentes o significato, no necesariamente es el 5\n\nAIC(lm1, lm2, lm3, lm4, lm5, lm6)\n\n    df      AIC\nlm1  3 615.0045\nlm2  3 580.9045\nlm3 16 626.6902\nlm4 16 595.4066\nlm5  6 609.2097\nlm6  5 577.9501\n\n\nSe puede estar en desacuerdo con esto, todo depende de su objetivo, el modelo 6 (lm6) es parsimonioso, pero no el que da mejores resultados.\nRSS: Df:"
  },
  {
    "objectID": "val_models.html#mejor-modelo-con-re-muestreo",
    "href": "val_models.html#mejor-modelo-con-re-muestreo",
    "title": "7  Validación de Modelos",
    "section": "7.7 Mejor modelo con re-muestreo",
    "text": "7.7 Mejor modelo con re-muestreo\nusamos caret para definir un tipo de metodo de re-muestreo para entrenar modelos mas robustos.\nsavePredictions = TRUE = nos va a guardar los daos internamente en el modelo validacion K-fold, con K=5, y 5 repeticiones aleatoreas\n\ncontrol <- trainControl(method = \"repeatedcv\", \n                        number = 5, # K\n                        repeats = 5, \n                        savePredictions = TRUE)\n\nUsar mejor modelos agregamos el parametro trControl que nos permite pasar la informacion del tipo de vadilacion cruzada a usar todos los datos, no solo los de entrenar, ya que las particiones se hacen internamente.\n\n7.7.1 Entrenar Modelos con cv\nModelos 7\n\n## efecto cantidad de variables en validaciones mas robustas! \nlm7 <- train(BIOMAS ~., \n             method = \"glm\", \n             data = data2, \n             family = Gamma(link = log),\n             trControl = control)\nsummary(lm7)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5663  -0.8534  -0.1446   0.3204   1.6855  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  7.765e+00  5.666e+00   1.370 0.174567    \nTM1          4.150e-01  3.397e-01   1.222 0.225644    \nTM2          2.603e-01  3.413e-01   0.763 0.448091    \nTM3          4.301e-01  4.224e-01   1.018 0.311786    \nTM4         -3.962e-01  4.897e-01  -0.809 0.420965    \nTM5          1.045e-01  3.933e-01   0.266 0.791257    \nTM7          9.071e-02  3.147e-01   0.288 0.773926    \nBRIGHT      -2.014e-01  6.218e-01  -0.324 0.746916    \nGREEN        8.252e-01  5.001e-01   1.650 0.103039    \nMOIST       -7.137e-02  4.807e-01  -0.148 0.882373    \nNDVI        -1.987e+01  1.913e+01  -1.039 0.302292    \nNDVIC        1.530e+01  1.014e+01   1.508 0.135579    \nPEND        -7.538e-03  1.199e-02  -0.629 0.531550    \nALT         -2.434e-04  1.169e-03  -0.208 0.835610    \nH            8.856e-02  2.510e-02   3.528 0.000714 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.7076406)\n\n    Null deviance: 95.048  on 90  degrees of freedom\nResidual deviance: 55.750  on 76  degrees of freedom\nAIC: 937.46\n\nNumber of Fisher Scoring iterations: 11\n\n\nModelo 6\n\nlm8 <- train(BIOMAS ~ TM3 + BRIGHT + H, # los determinados por el train de lm6\n             method = \"glm\", \n             data = data2, \n             family = Gamma(link = log),\n             trControl = control)\nsummary(lm8)\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7172  -0.8079  -0.1219   0.3163   1.8271  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.56495    1.02006   6.436 6.46e-09 ***\nTM3          0.05896    0.01869   3.154 0.002210 ** \nBRIGHT      -0.04554    0.01333  -3.417 0.000965 ***\nH            0.08557    0.01904   4.495 2.14e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.6453826)\n\n    Null deviance: 95.048  on 90  degrees of freedom\nResidual deviance: 61.377  on 87  degrees of freedom\nAIC: 925.12\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n7.7.2 Datos de ajuste internos de cada iteración\n\nlm7$resample\n\n        RMSE   Rsquared      MAE   Resample\n1   42.08596 0.55062712 34.34071 Fold1.Rep1\n2  164.24473 0.11760861 93.04358 Fold2.Rep1\n3   62.70291 0.36601711 44.95314 Fold3.Rep1\n4   53.79932 0.25253642 39.66982 Fold4.Rep1\n5   82.24359 0.20767591 60.84382 Fold5.Rep1\n6   64.45791 0.22995763 39.02619 Fold1.Rep2\n7  170.00849 0.07854019 82.37425 Fold2.Rep2\n8   43.10085 0.42965684 35.63650 Fold3.Rep2\n9   39.07610 0.57550108 33.40203 Fold4.Rep2\n10  89.18437 0.13761200 72.19029 Fold5.Rep2\n11  64.32318 0.54899375 42.86009 Fold1.Rep3\n12  73.58456 0.40000220 54.21211 Fold2.Rep3\n13  46.76064 0.54345393 38.59701 Fold3.Rep3\n14  31.23562 0.64675677 26.76364 Fold4.Rep3\n15 158.51760 0.17864936 89.69632 Fold5.Rep3\n16 152.52734 0.15959130 77.79163 Fold1.Rep4\n17  41.18393 0.48586434 29.45265 Fold2.Rep4\n18  61.27450 0.45782888 38.05745 Fold3.Rep4\n19  66.67338 0.31925216 49.10811 Fold4.Rep4\n20  52.02723 0.48809468 40.18278 Fold5.Rep4\n21  48.76703 0.52934030 37.69387 Fold1.Rep5\n22  64.96093 0.26812830 45.72222 Fold2.Rep5\n23  61.23993 0.39640010 42.70253 Fold3.Rep5\n24 110.39498 0.07262132 63.72854 Fold4.Rep5\n25  55.79810 0.49990714 41.85867 Fold5.Rep5\n\n\n\n\n7.7.3 Visualización\nVisualización de R^2\n\npar(mfrow=c(1,2))\nboxplot(lm7$resample[,2], main ='R2 todo', ylim = c(0,1))\nabline(h = median(lm7$resample[,2]), lty = 2, col = \"red\")\nboxplot(lm8$resample[,2], main ='R2 (TM3 + BRIGHT + H)', ylim = c(0,1))\nabline(h = median(lm8$resample[,2]), lty = 2, col = \"red\")\n\n\n\n\nVisualización de RMSE\n\npar(mfrow=c(1,2))\nboxplot(lm7$resample[,1], main ='RMSE todo',  ylim = c(20,120))\nabline(h = median(lm7$resample[,1]), lty = 2, col = \"red\")\nboxplot(lm8$resample[,1], main ='RMSE (TM3 + BRIGHT + H)', ylim = c(20,120))\nabline(h = median(lm8$resample[,1]), lty = 2, col = \"red\")\n\n\n\n\nEn este caso tenemos una sitribución de datos\n\n\n7.7.4 Observados vs predichos\n\n# lm7$pred\n\npar(mfrow=c(1,2))\n\nobs7 <- lm7$pred[,2]\npred7 <- lm7$pred[,1]\n\nplot(obs7, pred7, pch = 16, col = rgb(0,0.5,0,0.3)) # red, green, blue, alpha\nabline(0, 1, lty = 2, col = \"red\") # intercepto, pendiente\n\nlm <- lm(pred7 ~ obs7 - 1)\nabline(lm)\nlegend('topleft', legend=c('Linea 1:1', 'Linea ajustada'), lty = c(2,1), \n       col = c(\"red\", \"black\"), bty = 'n')\n\nobs8 <- lm8$pred[,2]\npred8 <- lm8$pred[,1]\n\nplot(obs8, pred8, pch = 17, col = rgb(0,0,0.5,0.3))\nabline(0, 1, lty = 2, col = \"red\")\n\nlm <- lm(pred8 ~ obs8 - 1)\nabline(lm)\nlegend('topleft', legend=c('Linea 1:1', 'Linea ajustada'), lty = c(2,1), \n       col = c(\"red\", \"black\"), bty = 'n')\n\n\n\n\nEN el Eje x son fijas las predicciones, mientras que en las prediccionesn pueden variar.\n\n\n\n\n“Explaining the Lm() Summary in R – Learn by Marketing.” n.d. Accessed September 2, 2022. https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/.\n\n\nKuhn, Max. n.d. 7 Train Models By Tag | The Caret Package. Accessed September 9, 2022. https://topepo.github.io/caret/train-models-by-tag.html."
  },
  {
    "objectID": "diseno_exp.html",
    "href": "diseno_exp.html",
    "title": "9  Diseño de Experimentos",
    "section": "",
    "text": "El objetivo principal de la estadística es hacer inferencias sobre poblaciones a partir de muestras.\n\n\n\nDescripción de Test de Hipótesis\n\n\nEl objetivo es decidir, basado en una muestra de la población, si existe evidencia suficiente para rechazar la hipótesis nula.\n\n\nNormalmente, un test de hipótesis se especifica en base a un estadístico (ej., Z, t, F). Es decir, una función que determina un valor dada la muestra de datos sobre la H_0. Todo test se hace en base a H_0.\nEl procedimiento de un test de hipótesis debe especificar:\n\nPara que valores la hipótesis H_0 se considera “verdadera”; realmente no existe evidencia suficiente para rechazar H_0.\nPara que valores la hipótesis H_0 se rechaza y H_1 es “aceptada” como verdad; realmente no hay suficiente información para aceptar H_0.\n\nLos valores para los cuales el test de hipótesis se rechaza se denomina región de rechazo o región crítica. El complemento de esta región se denomina región de aceptación.\nColas\nNormalmente existen dos tipos de test de hipótesis, de una cola y de dos colas.\n\n\n\nColas en Test de Hipótesis\n\n\nLa probabilidad de rechazar H_0 se conoce como nivel de significancia (significance level), y se denota con la letra griega alfa. Ej., \\alpha = 0.05 (5%)\nEl valor del estadígrafo utilizado en el test (ej., Z, t, F) correspondiente a α se conoce como valor crítico (critical value)\n\n\n\nEg. Test dos colas\n\n\n\n\n\n\n\n\nEg. Valor Crítico\n\n\n\n\n\nError Tipo 1\nEs muy importante darse cuenta de que una hipótesis nula verdadera en ocasiones será rechazada. Además, este error se cometerá con una frecuencia de \\alpha (e.g. \\alpha = 0.05)\nEl rechazo de una hipótesis nula cuando en realidad es verdadera es lo que se conoce como Error Tipo 1\nError Tipo 2\nThe probability of not rejecting th null hypothesis when it in fact false is represented by \\beta Error Tipo 2\nLa potencia de una prueba estadística se define como 1-\\beta\nConculsión de los Errores\n\n\n\nConculsión de los errores\n\n\n\n\n\nGráfico de errores"
  },
  {
    "objectID": "diseno_exp.html#p-valor",
    "href": "diseno_exp.html#p-valor",
    "title": "9  Diseño de Experimentos",
    "section": "9.2 P-Valor",
    "text": "9.2 P-Valor\nDeterminar la región crítica basado en un valor \\alpha solo podemos tomar una decisión binaria sobre la hipótesis, sin info. suficiente para “rechazar” o “aceptar” H_0.\nDado un estadístico W_{(X)}, el p-valor de un test de hipótesis es la probabilidad de obtener un resultado igual o más extremo que el estadístico observado W(x)=w, asumiendo H_0 como verdad.\n\n\n\nConceptualización Probalística del p-value\n\n\n\nUn p-valor bajo => que es muy poco probable haber obtenido W_{(x)} (ej., p < 0.05 … no hay evidencia suficiente para aceptar …(se rechaza)… H_0).\nUn p-valor alto => que es muy probable haber obtenido W_{(x)} (ej., p > 0.05 … se acepta H_0)"
  },
  {
    "objectID": "diseno_exp.html#aplicabilidad-qué-test-debo-usar",
    "href": "diseno_exp.html#aplicabilidad-qué-test-debo-usar",
    "title": "9  Diseño de Experimentos",
    "section": "9.3 Aplicabilidad: ¿Qué test debo usar?",
    "text": "9.3 Aplicabilidad: ¿Qué test debo usar?\n\n\n\nÁrbol de decisión para seleccionar test\n\n\n\n9.3.1 Comparar dos muestras\n\n\n\nComparar dos muestras\n\n\nComparar dos medias\n¿Qué probabilidad hay de que nuestras dos medias muestrales procedan de dos poblaciones con la misma media?\n\nEs muy probable → Las dos medias muestrales no son signiﬁcativamente diferentes.\nEs bastante improbable → Las medias muestrales son signiﬁcativamente diferentes.\n\nSi esta probabilidad es muy baja (digamos, menos del 5% o menos del 1%), entonces podemos estar razonablemente seguros (95% o 99% en estos dos ejemplos) de que las medias son realmente diferentes entre sí.\nOJO!: hay que tener en cuenta que nunca podemos estar seguros al 100%; la diferencia aparente podría deberse simplemente a un muestreo aleatorio, es decir, que hemos obtenido muchos valores bajos en una muestra y muchos valores altos en la otra (error de diseño muestral)\nt Student:\n\n\n\nt Student\n\n\n\n\n\nError Estandas de las Diferencias\n\n\nEjemplo: Ver si las medias de dos muestras de datos de n=20 difieren:\n\nDF = 20 – 2 = 18 (- 2 por que en este caso son dos poblaciones, no una)\nNivel de significancia: Normalmente utilizamos el 5% como probabilidad de rechazar la hipótesis nula cuando es verdadera (es la tasa de error de tipo I). Puede cambiar dependiendo de la aplicación o el campo de estudio (e.g., 10% o 1%).\nValor crítico: Este test es típicamente de dos colas, y el valor crítico que se usa para ver si se acepta o rechaza H_0 sería:\n\n\n# porqué 0.975 envés de 0.95? por qué el test es de dos colas, \n# y el nivel de significancia se divide en dos \n\nqt(0.975, 18)  \n\n[1] 2.100922\n\n# valor crítico!\n\nEsto significa que nuestro estadístico t de prueba tiene que ser mayor que 2,1 (valor crítico) para rechazar la hipótesis nula y, por tanto concluir que las dos medias son signiﬁcativamente diferentes a α = 0,05.\n\nt.test(gardenA, gardenB)\n\n\n\n\nPrueba visual: Usar boxplot con muescas (notchs)\n\n\nEn R:\n\nboxplot(A, B, notch=TRUE, xlab=\"Garden\", ylab=\"Ozone\")\n\n\n\n\nPrueba visual en R\n\n\nVisualmente las muescas no se sobrelapan, se podría concluir que las medias de las dos distribuciones son significativamente diferentes al nivel de 5%"
  },
  {
    "objectID": "anova.html",
    "href": "anova.html",
    "title": "10  Anova",
    "section": "",
    "text": "Si queremos predecir una variable Y de tipo continua, podemos dividir a grandes rasgos los tipos de modelos predictivos en tres grandes tipo en base a la naturaleza de los predictores o variables (X):"
  },
  {
    "objectID": "anova.html#anova-análisis-de-varianza",
    "href": "anova.html#anova-análisis-de-varianza",
    "title": "10  Anova",
    "section": "10.1 ANOVA: Análisis de Varianza",
    "text": "10.1 ANOVA: Análisis de Varianza\nPredecir Y usando una o más variables factoriales\nY ~ A; Y ~ A+B; Y ~ A+B+C\nH0: μ1 = μ2 = μ3….(todas las medias poblacionales de Y son iguales, o no significativamente distintas)\nH1: Al menos una media poblacional es distinta del resto\n\nNo dice cual es la distinta!\n\nAsume que:\n\nLa selección de valores en los subgrupos es aleatoria e independiente\nTodas los subgrupos tienen una distribución de errores normal (residuos)\nTodas las poblaciones de los subgrupos de Y tienen la misma varianza\n\nEn caso que alguno de estos supuestos no se cumplan: Impactarán directamente sobre los valores p-valor reportados, y por lo tanto sobre la calidad de las conclusiones que finalmente buscamos obtener.\nLa verificación de los supuestos se realiza en la práctica a través de los predictores de los términos de error aleatorio que son los residuos aleatorios asociados a cada observación Por lo tanto los supuestos pueden verificarse mediante el análisis de los RESIDUOS.\n\n\n\nFigure 10.3: Comparación de Análisis de Anova Unidireccional y Multidimensional. La única diferencia entre ANOVA unidireccional y bidireccional es el número de variables independientes. Un ANOVA unidireccional tiene una variable independiente, mientras que un ANOVA bidireccional tiene dos."
  },
  {
    "objectID": "anova.html#on-way-anova",
    "href": "anova.html#on-way-anova",
    "title": "10  Anova",
    "section": "10.2 On-Way ANOVA",
    "text": "10.2 On-Way ANOVA\nANOVA de unas sola cola, o comparación de una variable Y en un variable X de tipo factorial\nOutput del modelo simpre es:\n\n\n\nFigure 10.4: Summary del Modelo de Anova\n\n\n\nFigure 10.5: Definición de Siglas"
  },
  {
    "objectID": "anova.html#experimento-factorial-two-way-anova",
    "href": "anova.html#experimento-factorial-two-way-anova",
    "title": "10  Anova",
    "section": "10.3 Experimento factorial (Two-Way ANOVA)",
    "text": "10.3 Experimento factorial (Two-Way ANOVA)\nEn estas situaciones estimamos los parámetros para los efectos principales de cada nivel de dieta y cada nivel de suplemento, además de los términos para la interacción entre la dieta y el suplemento. Los grados de libertad de la interacción son el producto de los grados de libertad de los términos componentes (es decir, (3 - 1) × (4 - 1) = 6).\nEl modelo es gain~diet+supplement+diet:supplement, pero puede simplificarse utilizando la notación del asterisco así:\nmodel <- aov(gain~diet*supplement)\nsummary(model)\n\nOutput del modelo Two-Way ANOVA :::\nNo hay evidencia de que las diferencias que dieta causa sobre Y (gain) varían en función de los suplementos, y viceversa. En este caso se puede decir entonces que los efectos de dieta y suplementos son Aditivos!"
  },
  {
    "objectID": "anova.html#pseudoreplicación-diseños-anidados-y-parcelas-divididas",
    "href": "anova.html#pseudoreplicación-diseños-anidados-y-parcelas-divididas",
    "title": "10  Anova",
    "section": "10.4 Pseudoreplicación: Diseños anidados y parcelas divididas",
    "text": "10.4 Pseudoreplicación: Diseños anidados y parcelas divididas\nLos modelos ANOVA tienen la facilidad de tratar con estructuras de error complicadas, y es importante que puedan reconocer tales estructuras de error, y por lo tanto evitar posibles trampas de la pseudoreplicación.\nHay dos casos generales:\n\nMuestreo anidado, como cuando se toman medidas repetidas del mismo individuo, o se realizan estudios observacionales donde datos se llevan a cabo en varias escalas espaciales diferentes (principalmente efectos aleatorios);\nAnálisis de parcelas divididas, como cuando los experimentos diseñados tienen diferentes tratamientos aplicados a parcelas de diferentes tamaños (en su mayoría, efectos fijos).\n\n\n10.4.1 Parcelas divididas\nSe aplican diferentes tratamientos a parcelas de diferentes tamaños. Cada tamaño de parcela tiene su propia varianza de error asociada, por lo que en lugar de tener una varianza de error (como en todas las tablas de ANOVA hasta este punto), tenemos tantos términos de error como tamaños de parcela diferentes. El análisis se presenta como una serie de tablas de ANOVA de componentes, una para cada tamaño de parcela, en una jerarquía que va desde el tamaño de parcela más grande con la menor replicación en la parte superior, hasta el tamaño de parcela más pequeño con la mayor replicación en la parte inferior.\nEjemplo: un experimento de campo diseñado sobre el rendimiento de los cultivos con tres tratamientos: riego (con dos niveles, regado o no), densidad de siembra (con tres niveles, bajo, medio y alto), y aplicación de fertilizantes (con tres niveles, bajo, medio y alto).\nLas parcelas más grandes fueron los cuatro campos completos (bloque), cada uno de los cuales se dividió por la mitad, y el riego se asignó al azar a una mitad del campo. Cada parcela de riego se dividió en tres, y se asignó al azar una de las tres densidades de siembra diferentes (baja, media o alta) (independientemente para cada nivel de riego y cada bloque). Por último, cada parcela de densidad se dividió en tres, y se asignó al azar uno de los tres tratamientos de nutrientes fertilizantes (N, P, o N y P juntos).\n\n\n\nFigure 10.6: Parcelas Divididas\n\n\nEl problema de los experimentos con parcelas divididas es la pseudoreplicación.\nEn el ejemplo, hay cuatro bloques, cada uno dividido por la mitad, con una mitad regada y la otra como control. En caso específico del factor riego, el experimento debería contener sólo 8 filas (no 72 filas como en el presente caso). Debería tener d.f. = 7: tres para los bloques, uno para el riego y sólo 7 - 3 - 1 = 3 d.f. para el error.\n\n\n\nFigure 10.7: Estructura de Datos Parcelas Divididas\n\n\nSi no se ha detectado esto, el modelo podría ejecutarse con 51 f.d. que representan una pseudoreplicación masiva (el valor de p-valor correcto para el tratamiento de riego es 0,0247, pero en una ANOVA normal el error pseudoreplicado da p-valor = 2.81 × 10^{-10}).\nEj.,modelo factorial, usando todas las combinaciones entre factores (asteriscos en formula; *)\n\n\n\nFigure 10.8: Summary del Modelo ANOVA factorial Parcelas Divididas\n\n\nPara corregir esto, la estructura del error se deﬁne en el término Error, con los tamaños de parcela enumerados de izquierda a derecha, de mayor a menor, con cada variable separada por el operador de barra diagonal /. Tenga en cuenta que el tamaño de parcela más pequeño, el fertilizante, no necesita aparecer en el término Error:\n\n\n\nFigure 10.9: Efectos entre factores: Densidad al parecer no es sig. por si solo (efecto aditivo), pero sí tiene relevancia en sus efectos sinérgicos con irrigación.\n\n\nNótese que el efecto principal no signiﬁcativo de la densidad (p = 0,053) no significa que la densidad no sea importante, porque la densidad aparece en una interacción signiﬁcativa con el riego (los términos de densidad se anulan, cuando se promedian en los dos tratamientos de riego; véase más adelante). La mejor manera de entender los dos términos de interacción signiﬁcativos es trazarlos utilizando interaction.plot de la siguiente manera:\nirrigation:fertilizer relationship\n\n\n\nFigure 10.10: En las parcelas con riego, el rendimiento con baja densidad, pero en las parcelas de control el rendimiento es menor que en las parcelas de alta densidad.\n\n\n\n\n10.4.2 Muestreo Anidado\nEn este caso, hay un posible gradiente que se quiere ELIMINAR del análisis, para centrarse bien en el gradiente o efecto que SI es interesante. Ejemplo:\nSe tiene una plantación de paltos en una ladera de cerro, y se quiere ver el efecto de fertilizantes y densidad de cultivo. Cómo la ladera de cerro puede tener mucho efecto en los resultados, debido a efectos de pendiente, características del suelo, etc., lo más importante acá es eliminar el efecto ladera-suelo del análisis.\nDiseño de muestreo estratificado por ladera: clasificar 3 tipos de ladera (baja, media y alta) y hacer las MISMAS mediciones de fertilizante y densidad en las 3 clases de ladera. Finalmente, se agrega la info del bloque como factor para ser si efecto independiente.\naov(yield ~ fertilizer + density + block, data = block)\n\n\n\nFigure 10.11: Anova para el caso de muestreo anidado que denota que no hay efecto bloque"
  },
  {
    "objectID": "anova.html#sección-práctica-anova",
    "href": "anova.html#sección-práctica-anova",
    "title": "10  Anova",
    "section": "10.5 Sección Práctica Anova",
    "text": "10.5 Sección Práctica Anova\n\n10.5.1 Tratamiento a los Datos\n\nlibrary(DescTools)\n\ndata <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/yields.txt',\n                    header=T, stringsAsFactors = TRUE)\n\n\n# estructura de los datos\nstr(data)\n\n'data.frame':   10 obs. of  3 variables:\n $ sand: int  6 10 8 6 14 17 9 11 7 11\n $ clay: int  17 15 3 11 14 12 12 8 10 13\n $ loam: int  13 16 9 12 15 16 17 13 18 14\n\nsummary(data)\n\n      sand            clay            loam     \n Min.   : 6.00   Min.   : 3.00   Min.   : 9.0  \n 1st Qu.: 7.25   1st Qu.:10.25   1st Qu.:13.0  \n Median : 9.50   Median :12.00   Median :14.5  \n Mean   : 9.90   Mean   :11.50   Mean   :14.3  \n 3rd Qu.:11.00   3rd Qu.:13.75   3rd Qu.:16.0  \n Max.   :17.00   Max.   :17.00   Max.   :18.0  \n\n\n\n# se pueden juntar las 3 clases en una sola columna y agregar las clases en otra con la\n# funcion stack\n\ndata2 <- stack(data)\ncolnames(data2) <- c(\"yield\",\"soil\") # cambiamos el nombre de las columnas\nstr(data2)\n\n'data.frame':   30 obs. of  2 variables:\n $ yield: int  6 10 8 6 14 17 9 11 7 11 ...\n $ soil : Factor w/ 3 levels \"sand\",\"clay\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\nLa clase soil es de tipo factorial esto es fundamental\n\n\n\n10.5.2 Test de Bartlett\nAnalizar si las varianza por subgrupo es homogeneas con test de Bartlett, este test no necesita hacerse sobre los residuos\n\nH0 = son homogeneas\nH1 = no son homogeneas\n\n\n### Test de Bartlett \n\nbartlett.test(yield ~ soil, data = data2)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  yield by soil\nBartlett's K-squared = 1.2764, df = 2, p-value = 0.5283\n\n\n\n\n10.5.3 one-way ANOVA\nRealizar test anova usando la funcion aov. Esta es la funcion estandar para este tipo de analisis\n\nanov1 <- aov(yield ~ soil, data = data2)\nsummary(anov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nsoil         2   99.2   49.60   4.245  0.025 *\nResiduals   27  315.5   11.69                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(anov1)\n\n\nCall:\naov(formula = yield ~ soil, data = data2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -8.5   -1.8    0.3    1.7    7.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.900      1.081   9.158 9.04e-10 ***\nsoilclay       1.600      1.529   1.047  0.30456    \nsoilloam       4.400      1.529   2.878  0.00773 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.418 on 27 degrees of freedom\nMultiple R-squared:  0.2392,    Adjusted R-squared:  0.1829 \nF-statistic: 4.245 on 2 and 27 DF,  p-value: 0.02495\n\n\n\n\n10.5.4 Normalidad de los Residuos\n\npar(mfrow = c(2, 2))\nplot(anov1)\n\n\n\n\n\n\nnull device \n          1 \n\n\n\nHO = es normal\nH1 = no es normal\n\n\nshapiro.test(anov1$residuals) # si!\n\n\n    Shapiro-Wilk normality test\n\ndata:  anov1$residuals\nW = 0.99131, p-value = 0.9961\n\n\n\n\n10.5.5 Post-Hoc\nNecesitamos saber donde estan las diferencias entre clases\n\ntuk <- TukeyHSD(anov1, conf.level = 0.95)\ntuk\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = yield ~ soil, data = data2)\n\n$soil\n          diff        lwr      upr     p adj\nclay-sand  1.6 -2.1903777 5.390378 0.5546301\nloam-sand  4.4  0.6096223 8.190378 0.0204414\nloam-clay  2.8 -0.9903777 6.590378 0.1785489\n\nplot(tuk, col = \"red\", las = 1, cex.axis = 0.5, \n     cex.lab = 0.5, cex = 0.5)\n\n\n\n\nLa diferencia entre loam y sand (limo y arena) es la unica significativa\n\n\n10.5.6 Visualización\nBoxplot*\n\nboxplot(yield ~ soil, data = data2, col = 'lightblue', notch = T)\n\nWarning in (function (z, notch = FALSE, width = NULL, varwidth = FALSE, : some\nnotches went outside hinges ('box'): maybe set notch=FALSE\n\n\n\n\n\nBarplot con barras de error\nRevisar cuantas observaciones hay por clase. Ya sabemos que son 10, pero se puede revisar con table\n\ntable(data2$soil)\n\n\nsand clay loam \n  10   10   10 \n\n\nError estandar de una media = \\sqrt(\\frac{S2}{N}\n\nsummary(anov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nsoil         2   99.2   49.60   4.245  0.025 *\nResiduals   27  315.5   11.69                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# repetimos este valor por el numero de subclases\nse <- rep( sqrt(11.69/10),3)\n\n# Estimar las medias de los tres subgrupos\n\n# La funcion tapply va a sacar la mean de yield usando como factor soil\nybar <- tapply(data2$yield, data2$soil, mean)\n\n# Nombres de los subgrupos\nlabels <- levels(data2$soil)\n\nNo hay una funcion para crear barras de error en R basico. Hay por su puesto en varios paquetes avanzados de plots, pero en este caso usamos esta funcion casera\n\nerror.bars <- function(yv,z,nn)\n{xv <- barplot(yv,ylim=c(0,(max(yv)+max(z))),\n               col=\"gray\",names=nn,ylab=deparse(substitute(yv)))\nfor (i in 1:length(xv)) {\n  arrows(xv[i],yv[i]+z[i],xv[i],yv[i]-z[i],angle=90,code=3,length=0.15)\n}}\n\n\nerror.bars(ybar, se, labels)"
  },
  {
    "objectID": "anova.html#ejemplo-2",
    "href": "anova.html#ejemplo-2",
    "title": "10  Anova",
    "section": "10.6 Ejemplo 2",
    "text": "10.6 Ejemplo 2\none-way anova con tratamiento con control y post-hoc test de Dun\nEjemplo, examinar si dos nuevas tecnicas de ensenanza tienen potencialmente un beneficio en la nota final de un examen. Se dividen los estudiantes en 30 individuos en los siguientes grupos:\nControl Group: 10 students New Study technique 1: 10 students New Study Technique 2: 10 students\n\ndata <- data.frame(technique = rep(c(\"control\", \"new1\", \"new2\"), each = 10),\n                   score = c(76, 77, 77, 81, 82, 82, 83, 84, 85, 89,\n                             81, 82, 83, 83, 83, 84, 87, 90, 92, 93,\n                             77, 78, 79, 88, 89, 90, 91, 95, 95, 98))\n\n\nhead(data)\n\n  technique score\n1   control    76\n2   control    77\n3   control    77\n4   control    81\n5   control    82\n6   control    82\n\nstr(data)\n\n'data.frame':   30 obs. of  2 variables:\n $ technique: chr  \"control\" \"control\" \"control\" \"control\" ...\n $ score    : num  76 77 77 81 82 82 83 84 85 89 ...\n\n\nAsegurarse que de las clases o tratamientos esten en formato factorial!\n\ndata$technique <- as.factor(data$technique)\nstr(data)\n\n'data.frame':   30 obs. of  2 variables:\n $ technique: Factor w/ 3 levels \"control\",\"new1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ score    : num  76 77 77 81 82 82 83 84 85 89 ...\n\n\n\nboxplot(score ~ technique,\n        data = data,\n        main = \"Exam Scores by Studying Technique\",\n        xlab = \"Studying Technique\",\n        ylab = \"Exam Scores\",\n        col = \"steelblue\",\n        border = \"black\")\n\n\n\n\n\n10.6.1 one-way ANOVA\n\nmodel <- aov(score ~ technique, data = data)\nsummary(model)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ntechnique    2  211.5  105.73   3.415 0.0476 *\nResiduals   27  836.0   30.96                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n10.6.2 Revision de residuos\n\npar(mfrow = c(2, 2))\nplot(model)\n\n\n\nshapiro.test(model$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  model$residuals\nW = 0.97617, p-value = 0.7172\n\n\n\n\nnull device \n          1 \n\n\n\n\n10.6.3 Test de Dunnett\ncompara solo las clases contra el tratamiento control\n\nplot(DunnettTest(x = data$score, g = data$technique))\n\n\n\n\nASEGURARSE siempre que el control tenga el nombre ‘control’ exactamente en la tabla\n\n\n10.6.4 PostHocs\nla libreria DescTools tiene muchos test Post-hoc para hacer\n\n10.6.4.1 Test de Tukey\nDos formas de visualizar el test de tukey\n\n# Usando DescTools\nPostHocTest(model, method = \"hsd\")\n\n\n  Posthoc multiple comparisons of means : Tukey HSD \n    95% family-wise confidence level\n\n$technique\n             diff     lwr.ci    upr.ci   pval    \nnew1-control  4.2 -1.9700112 10.370011 0.2281    \nnew2-control  6.4  0.2299888 12.570011 0.0409 *  \nnew2-new1     2.2 -3.9700112  8.370011 0.6548    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# usando R\nTukeyHSD(model)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = score ~ technique, data = data)\n\n$technique\n             diff        lwr       upr     p adj\nnew1-control  4.2 -1.9700112 10.370011 0.2281369\nnew2-control  6.4  0.2299888 12.570011 0.0409017\nnew2-new1     2.2 -3.9700112  8.370011 0.6547756\n\n\n\nplot(PostHocTest(model, method = \"hsd\"))\n\n\n\nplot(TukeyHSD(model))"
  },
  {
    "objectID": "anova.html#experimento-factorial-two-way-anova-1",
    "href": "anova.html#experimento-factorial-two-way-anova-1",
    "title": "10  Anova",
    "section": "10.7 Experimento Factorial (two-way Anova)",
    "text": "10.7 Experimento Factorial (two-way Anova)\n\n10.7.1 Lectura Data\n\nweights <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/growth.txt',\n                      header=T, stringsAsFactors = TRUE)\n\nstr(weights)\n\n'data.frame':   48 obs. of  3 variables:\n $ supplement: Factor w/ 4 levels \"agrimore\",\"control\",..: 3 3 3 3 2 2 2 2 4 4 ...\n $ diet      : Factor w/ 3 levels \"barley\",\"oats\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ gain      : num  17.4 16.8 18.1 15.8 17.7 ...\n\n\n\n\n10.7.2 Barplot\ninspeccion de datos con barplot. Primero, crear una tabla con promedios por clase usando tapply esta vez en tapply usamos una lista con los dos factores para que los tome a los dos en cuenta\n\nymean <- tapply(weights$gain, list(weights$diet, weights$supplement), mean)\n\nEl parametro beside=TRUE indica que las subcalses (dieta) van como subgrupo del suplemento\n\nbarplot(ymean, beside = TRUE, ylim = c(0, 30), col = c(\"orange\", \"yellow\", \"cornsilk\"))\nlabs <- c(\"Barley\", \"Oats\", \"Wheat\")\nlegend('top', labs, fill= c(\"orange\", \"yellow\", \"cornsilk\"))\n\n\n\n\n\n\n10.7.3 ANOVA\n\nmodel <- aov(gain ~ diet*supplement, data = weights)\nsummary(model)\n\n                Df Sum Sq Mean Sq F value   Pr(>F)    \ndiet             2 287.17  143.59   83.52 3.00e-14 ***\nsupplement       3  91.88   30.63   17.82 2.95e-07 ***\ndiet:supplement  6   3.41    0.57    0.33    0.917    \nResiduals       36  61.89    1.72                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVer interacciones completas\n\nsummary.lm(model)\n\n\nCall:\naov(formula = gain ~ diet * supplement, data = weights)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.48756 -1.00368 -0.07452  1.03496  2.68069 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                    26.3485     0.6556  40.191  < 2e-16 ***\ndietoats                       -3.0501     0.9271  -3.290 0.002248 ** \ndietwheat                      -6.7094     0.9271  -7.237 1.61e-08 ***\nsupplementcontrol              -3.0518     0.9271  -3.292 0.002237 ** \nsupplementsupergain            -3.8824     0.9271  -4.187 0.000174 ***\nsupplementsupersupp            -0.7732     0.9271  -0.834 0.409816    \ndietoats:supplementcontrol      0.2471     1.3112   0.188 0.851571    \ndietwheat:supplementcontrol     0.8183     1.3112   0.624 0.536512    \ndietoats:supplementsupergain    0.2470     1.3112   0.188 0.851652    \ndietwheat:supplementsupergain   1.2557     1.3112   0.958 0.344601    \ndietoats:supplementsupersupp   -0.6650     1.3112  -0.507 0.615135    \ndietwheat:supplementsupersupp   0.8024     1.3112   0.612 0.544381    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.311 on 36 degrees of freedom\nMultiple R-squared:  0.8607,    Adjusted R-squared:  0.8182 \nF-statistic: 20.22 on 11 and 36 DF,  p-value: 3.295e-12\n\n\nModelo muy complejo, por lo que podemos dejar solo los componentes e interacciones significativas e interesantes.\n\n\n10.7.4 Test de varianzas homogeneas\n\nbartlett.test(gain ~ diet, data = weights)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  gain by diet\nBartlett's K-squared = 2.2513, df = 2, p-value = 0.3244\n\nbartlett.test(gain ~ supplement, data = weights)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  gain by supplement\nBartlett's K-squared = 0.57513, df = 3, p-value = 0.9021\n\n\n\nmodel2 <- aov(gain ~ diet + supplement, data = weights)\nsummary(model2) # ya no hay interacciones!\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ndiet         2 287.17  143.59   92.36 4.20e-16 ***\nsupplement   3  91.88   30.63   19.70 3.98e-08 ***\nResiduals   42  65.30    1.55                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(model2)\n\n\nCall:\naov(formula = gain ~ diet + supplement, data = weights)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.30792 -0.85929 -0.07713  0.92052  2.90615 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          26.1230     0.4408  59.258  < 2e-16 ***\ndietoats             -3.0928     0.4408  -7.016 1.38e-08 ***\ndietwheat            -5.9903     0.4408 -13.589  < 2e-16 ***\nsupplementcontrol    -2.6967     0.5090  -5.298 4.03e-06 ***\nsupplementsupergain  -3.3815     0.5090  -6.643 4.72e-08 ***\nsupplementsupersupp  -0.7274     0.5090  -1.429     0.16    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.247 on 42 degrees of freedom\nMultiple R-squared:  0.8531,    Adjusted R-squared:  0.8356 \nF-statistic: 48.76 on 5 and 42 DF,  p-value: < 2.2e-16\n\n\n\n\n10.7.5 Comparación de modelos\n\nmodel: Factorial\nmodel2: Aditivo\n\n\n# diferencias significativas entre los dos modelos?\nanova(model, model2) # No\n\nAnalysis of Variance Table\n\nModel 1: gain ~ diet * supplement\nModel 2: gain ~ diet + supplement\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     36 61.890                           \n2     42 65.296 -6   -3.4058 0.3302 0.9166\n\n\n\nAIC(model, model2)\n\n       df      AIC\nmodel  13 174.4179\nmodel2  7 164.9892\n\n\n\n# plot(PostHocTest(model, method = \"hsd\"))\nTukeyHSD(model)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = gain ~ diet * supplement, data = weights)\n\n$diet\n                  diff       lwr       upr p adj\noats-barley  -3.092817 -4.225918 -1.959715 3e-07\nwheat-barley -5.990298 -7.123399 -4.857196 0e+00\nwheat-oats   -2.897481 -4.030582 -1.764379 1e-06\n\n$supplement\n                          diff       lwr        upr     p adj\ncontrol-agrimore    -2.6967005 -4.138342 -1.2550592 0.0000764\nsupergain-agrimore  -3.3814586 -4.823100 -1.9398173 0.0000015\nsupersupp-agrimore  -0.7273521 -2.168993  0.7142892 0.5326710\nsupergain-control   -0.6847581 -2.126399  0.7568832 0.5817637\nsupersupp-control    1.9693484  0.527707  3.4109897 0.0040534\nsupersupp-supergain  2.6541065  1.212465  4.0957478 0.0000972\n\n$`diet:supplement`\n                                          diff         lwr        upr     p adj\noats:agrimore-barley:agrimore     -3.050093860  -6.2861072  0.1859194 0.0800774\nwheat:agrimore-barley:agrimore    -6.709404652  -9.9454179 -3.4733914 0.0000010\nbarley:control-barley:agrimore    -3.051827710  -6.2878410  0.1841856 0.0797364\noats:control-barley:agrimore      -5.854812782  -9.0908261 -2.6187995 0.0000156\nwheat:control-barley:agrimore     -8.942959440 -12.1789727 -5.7069461 0.0000000\nbarley:supergain-barley:agrimore  -3.882353990  -7.1183673 -0.6463407 0.0081992\noats:supergain-barley:agrimore    -6.685474160  -9.9214875 -3.4494609 0.0000011\nwheat:supergain-barley:agrimore   -9.336046198 -12.5720595 -6.1000329 0.0000000\nbarley:supersupp-barley:agrimore  -0.773175055  -4.0091883  2.4628382 0.9993538\noats:supersupp-barley:agrimore    -4.488243097  -7.7242564 -1.2522298 0.0012832\nwheat:supersupp-barley:agrimore   -6.680136725  -9.9161500 -3.4441234 0.0000011\nwheat:agrimore-oats:agrimore      -3.659310793  -6.8953241 -0.4232975 0.0156910\nbarley:control-oats:agrimore      -0.001733850  -3.2377471  3.2342794 1.0000000\noats:control-oats:agrimore        -2.804718923  -6.0407322  0.4312944 0.1426161\nwheat:control-oats:agrimore       -5.892865580  -9.1288789 -2.6568523 0.0000138\nbarley:supergain-oats:agrimore    -0.832260130  -4.0682734  2.4037532 0.9987355\noats:supergain-oats:agrimore      -3.635380300  -6.8713936 -0.3993670 0.0167992\nwheat:supergain-oats:agrimore     -6.285952338  -9.5219656 -3.0499390 0.0000038\nbarley:supersupp-oats:agrimore     2.276918805  -0.9590945  5.5129321 0.3975577\noats:supersupp-oats:agrimore      -1.438149237  -4.6741625  1.7978641 0.9151137\nwheat:supersupp-oats:agrimore     -3.630042865  -6.8660562 -0.3940296 0.0170562\nbarley:control-wheat:agrimore      3.657576943   0.4215636  6.8935902 0.0157690\noats:control-wheat:agrimore        0.854591870  -2.3814214  4.0906052 0.9983978\nwheat:control-wheat:agrimore      -2.233554788  -5.4695681  1.0024585 0.4258079\nbarley:supergain-wheat:agrimore    2.827050663  -0.4089626  6.0630640 0.1356315\noats:supergain-wheat:agrimore      0.023930493  -3.2120828  3.2599438 1.0000000\nwheat:supergain-wheat:agrimore    -2.626641545  -5.8626548  0.6093717 0.2089804\nbarley:supersupp-wheat:agrimore    5.936229597   2.7002163  9.1722429 0.0000120\noats:supersupp-wheat:agrimore      2.221161555  -1.0148517  5.4571748 0.4340350\nwheat:supersupp-wheat:agrimore     0.029267927  -3.2067454  3.2652812 1.0000000\noats:control-barley:control       -2.802985073  -6.0389984  0.4330282 0.1431702\nwheat:control-barley:control      -5.891131730  -9.1271450 -2.6551184 0.0000139\nbarley:supergain-barley:control   -0.830526280  -4.0665396  2.4054870 0.9987590\noats:supergain-barley:control     -3.633646450  -6.8696597 -0.3976332 0.0168823\nwheat:supergain-barley:control    -6.284218488  -9.5202318 -3.0482052 0.0000039\nbarley:supersupp-barley:control    2.278652655  -0.9573606  5.5146659 0.3964466\noats:supersupp-barley:control     -1.436415387  -4.6724287  1.7995979 0.9157324\nwheat:supersupp-barley:control    -3.628309015  -6.8643223 -0.3922957 0.0171405\nwheat:control-oats:control        -3.088146658  -6.3241600  0.1478666 0.0728783\nbarley:supergain-oats:control      1.972458793  -1.2635545  5.2084721 0.6078579\noats:supergain-oats:control       -0.830661377  -4.0666747  2.4053519 0.9987572\nwheat:supergain-oats:control      -3.481233415  -6.7172467 -0.2452201 0.0258844\nbarley:supersupp-oats:control      5.081637727   1.8456244  8.3176510 0.0001928\noats:supersupp-oats:control        1.366569685  -1.8694436  4.6025830 0.9382729\nwheat:supersupp-oats:control      -0.825323943  -4.0613372  2.4106894 0.9988273\nbarley:supergain-wheat:control     5.060605450   1.8245922  8.2966187 0.0002063\noats:supergain-wheat:control       2.257485280  -0.9785280  5.4934986 0.4101108\nwheat:supergain-wheat:control     -0.393086758  -3.6291001  2.8429265 0.9999993\nbarley:supersupp-wheat:control     8.169784385   4.9337711 11.4057977 0.0000000\noats:supersupp-wheat:control       4.454716343   1.2187030  7.6907296 0.0014257\nwheat:supersupp-wheat:control      2.262822715  -0.9731906  5.4988360 0.4066453\noats:supergain-barley:supergain   -2.803120170  -6.0391335  0.4328931 0.1431270\nwheat:supergain-barley:supergain  -5.453692208  -8.6897055 -2.2176789 0.0000577\nbarley:supersupp-barley:supergain  3.109178935  -0.1268344  6.3451922 0.0691463\noats:supersupp-barley:supergain   -0.605889108  -3.8419024  2.6301242 0.9999375\nwheat:supersupp-barley:supergain  -2.797782735  -6.0337960  0.4382306 0.1448433\nwheat:supergain-oats:supergain    -2.650572038  -5.8865853  0.5854413 0.1989133\nbarley:supersupp-oats:supergain    5.912299105   2.6762858  9.1483124 0.0000130\noats:supersupp-oats:supergain      2.197231062  -1.0387822  5.4332444 0.4500973\nwheat:supersupp-oats:supergain     0.005337435  -3.2306759  3.2413507 1.0000000\nbarley:supersupp-wheat:supergain   8.562871143   5.3268578 11.7988844 0.0000000\noats:supersupp-wheat:supergain     4.847803100   1.6117898  8.0838164 0.0004093\nwheat:supersupp-wheat:supergain    2.655909473  -0.5801038  5.8919228 0.1967179\noats:supersupp-barley:supersupp   -3.715068042  -6.9510813 -0.4790547 0.0133696\nwheat:supersupp-barley:supersupp  -5.906961670  -9.1429750 -2.6709484 0.0000132\nwheat:supersupp-oats:supersupp    -2.191893628  -5.4279069  1.0441197 0.4537097\n\n# plot(TukeyHSD(model))"
  },
  {
    "objectID": "ancova.html",
    "href": "ancova.html",
    "title": "11  Ancova",
    "section": "",
    "text": "Regresión + ANOVA.\nLa idea acá es combinar variables continuas con factores para analizar. Se puede pensar como un ANOVA donde hay una co-variable continua que es interesante para el estudio. O como una regresión con una co-variable factorial…\n\n\n\nFigure 11.1: Datos para análisis One Way Ancova\n\n\nEjemplo:\nExperimento sobre el impacto del pastoreo en la producción de semillas de una planta. 40 plantas fueron asignadas a dos tratamientos, pastoreadas y no pastoreadas. Las plantas pastoreadas fueron expuestas a los conejos durante las dos primeras semanas de elongación del tallo. A continuación, se protegieron del pastoreo posterior mediante la instalación de una valla y se les permitió volver a crecer. Dado que el tamaño inicial de la planta se pensó que podía influir en la producción de fruta, se midió el diámetro de la parte superior del portainjerto (sobre la raíz) antes de plantar en maceta. Al final de la temporada de cultivo, se registró la producción de fruta (peso seco en miligramos) en cada una de las 40 plantas, y esto constituye la variable de respuesta en el siguiente análisis.\nData:\n- Fuit (variable Y, contínua)\n- Root (variable X, contínua)\n- Grazing (variable X, factorial)\n¿Cómo afecta el tipo de pastoreo (factor) y el diámetro del tallo sobre la raíz (continua) a la producción de semilla y fruta de la planta?\n\n\n\nFigure 11.2: Efectos de pastoreo (Grazed)\n\n\n\nFigure 11.3: One-way ANCOVA\n\n\n\n\n\n\n\n\n\n\n\nEjemplo:\nEl siguiente experimento, con el peso como variable de respuesta, incluía el genotipo y el sexo como dos variables explicativas categóricas y la edad como covariable continua. Hay seis niveles de genotipo y dos niveles de sexo.\nPeso ~ genotipo(factor) + sexo(factor) + edad(numérica)\n\n\n\nFigure 11.4: Summary del Ejemplo propuesto\n\n\n\n\nUsar stepwise selección automática para hacer el modelo más simple?\nStep() hace el trabajo similar a lo hecho en caret con los modelos de regresión: prueba todas las combinaciones de variables y elije la mas parsimoniosa según AIC:\n\n\n\n\nm1 <- aov(Weight~Sex*Age*Genotype)\nsummary(m1)\n\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nSex               1  10.37  10.374 183.440 1.06e-15 ***\nAge               1  10.77  10.770 190.450 6.03e-16 ***\nGenotype          5  54.96  10.992 194.371  < 2e-16 ***\nSex:Age           1   0.05   0.049   0.865    0.358    \nSex:Genotype      5   0.15   0.029   0.520    0.760    \nAge:Genotype      5   0.17   0.034   0.595    0.704    \nSex:Age:Genotype  5   0.35   0.070   1.235    0.313    \nResiduals        36   2.04   0.057                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nm2 <- step(m1)\n\nStart:  AIC=-155.01\nWeight ~ Sex * Age * Genotype\n\n                   Df Sum of Sq    RSS     AIC\n- Sex:Age:Genotype  5   0.34912 2.3849 -155.51\n<none>                          2.0358 -155.01\n\nStep:  AIC=-155.51\nWeight ~ Sex + Age + Genotype + Sex:Age + Sex:Genotype + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Sex:Genotype  5  0.146901 2.5318 -161.92\n- Age:Genotype  5  0.168136 2.5531 -161.42\n- Sex:Age       1  0.048937 2.4339 -156.29\n<none>                      2.3849 -155.51\n\nStep:  AIC=-161.92\nWeight ~ Sex + Age + Genotype + Sex:Age + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Age:Genotype  5  0.168136 2.7000 -168.07\n- Sex:Age       1  0.048937 2.5808 -162.78\n<none>                      2.5318 -161.92\n\nStep:  AIC=-168.07\nWeight ~ Sex + Age + Genotype + Sex:Age\n\n           Df Sum of Sq    RSS      AIC\n- Sex:Age   1     0.049  2.749 -168.989\n<none>                   2.700 -168.066\n- Genotype  5    54.958 57.658    5.612\n\nStep:  AIC=-168.99\nWeight ~ Sex + Age + Genotype\n\n           Df Sum of Sq    RSS      AIC\n<none>                   2.749 -168.989\n- Sex       1    10.374 13.122  -77.201\n- Age       1    10.770 13.519  -75.415\n- Genotype  5    54.958 57.707    3.662\n\nsummary(m2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nSex          1  10.37  10.374   196.2 <2e-16 ***\nAge          1  10.77  10.770   203.7 <2e-16 ***\nGenotype     5  54.96  10.992   207.9 <2e-16 ***\nResiduals   52   2.75   0.053                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsummary.lm(m2)\n\n\nCall:\naov(formula = Weight ~ Sex + Age + Genotype)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40005 -0.15120 -0.01668  0.16953  0.49227 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     7.93701    0.10066  78.851  < 2e-16 ***\nSexmale        -0.83161    0.05937 -14.008  < 2e-16 ***\nAge             0.29958    0.02099  14.273  < 2e-16 ***\nGenotypeCloneB  0.96778    0.10282   9.412 8.07e-13 ***\nGenotypeCloneC -1.04361    0.10282 -10.149 6.21e-14 ***\nGenotypeCloneD  0.82396    0.10282   8.013 1.21e-10 ***\nGenotypeCloneE -0.87540    0.10282  -8.514 1.98e-11 ***\nGenotypeCloneF  1.53460    0.10282  14.925  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2299 on 52 degrees of freedom\nMultiple R-squared:  0.9651,    Adjusted R-squared:  0.9604 \nF-statistic: 205.7 on 7 and 52 DF,  p-value: < 2.2e-16\n\n\nDiferencias de Modelos\n\nanova(m1, m2)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ Sex * Age * Genotype\nModel 2: Weight ~ Sex + Age + Genotype\n  Res.Df    RSS  Df Sum of Sq      F Pr(>F)\n1     36 2.0358                            \n2     52 2.7489 -16   -0.7131 0.7881 0.6883\n\n\nNormalidad en los Residuos\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98321, p-value = 0.5782\n\n\nDistribución de los residuos\n\n\n\nFigure 11.5: Distribución de Residuos Ancova"
  },
  {
    "objectID": "ancova.html#sección-práctica-ancova",
    "href": "ancova.html#sección-práctica-ancova",
    "title": "11  Ancova",
    "section": "11.2 Sección Práctica Ancova",
    "text": "11.2 Sección Práctica Ancova"
  },
  {
    "objectID": "ancova.html#anova-con-parcelas-dividadas",
    "href": "ancova.html#anova-con-parcelas-dividadas",
    "title": "11  Ancova",
    "section": "11.3 ANOVA con parcelas dividadas",
    "text": "11.3 ANOVA con parcelas dividadas\n\n11.3.1 Carga de datos\nTipos de suelo y cosecha (yield) en cultivos\n\ndata <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/splityield.txt',\n                   header = T, stringsAsFactors = TRUE)\n# estructura de los datos\nstr(data)\n\n'data.frame':   72 obs. of  5 variables:\n $ yield     : int  90 95 107 92 89 92 81 92 93 80 ...\n $ block     : Factor w/ 4 levels \"A\",\"B\",\"C\",\"D\": 1 1 1 1 1 1 1 1 1 1 ...\n $ irrigation: Factor w/ 2 levels \"control\",\"irrigated\": 1 1 1 1 1 1 1 1 1 2 ...\n $ density   : Factor w/ 3 levels \"high\",\"low\",\"medium\": 2 2 2 3 3 3 1 1 1 2 ...\n $ fertilizer: Factor w/ 3 levels \"N\",\"NP\",\"P\": 1 3 2 1 3 2 1 3 2 1 ...\n\nsummary(data)\n\n     yield        block      irrigation   density   fertilizer\n Min.   : 60.00   A:18   control  :36   high  :24   N :24     \n 1st Qu.: 86.00   B:18   irrigated:36   low   :24   NP:24     \n Median : 95.00   C:18                  medium:24   P :24     \n Mean   : 99.72   D:18                                        \n 3rd Qu.:114.00                                               \n Max.   :136.00                                               \n\n\nFertilizantes:\n\nN: Nitrogeno\nP: Fósforo\n\n\n\n11.3.2 Modelo ANOVA\n\n# ANOVA normal que hacemos siempre\n\nmodel1 <- aov(yield ~ irrigation*density*fertilizer, data = data)\nsummary(model1)\n\n                              Df Sum Sq Mean Sq F value   Pr(>F)    \nirrigation                     1   8278    8278  59.575 2.81e-10 ***\ndensity                        2   1758     879   6.328  0.00340 ** \nfertilizer                     2   1977     989   7.116  0.00181 ** \nirrigation:density             2   2747    1374   9.885  0.00022 ***\nirrigation:fertilizer          2    953     477   3.431  0.03956 *  \ndensity:fertilizer             4    305      76   0.549  0.70082    \nirrigation:density:fertilizer  4    235      59   0.422  0.79183    \nResiduals                     54   7503     139                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n11.3.3 Modelo ANOVA con declaracion de Error\nSe debe poner los bloques de mayor a menor tamano separados por un parentesis. El tamano mas pequeno no es necesario ponerlo\n(por defecto se sabe que el que no se pone es el ultimo)\n\nmodel2 <- aov(yield ~ irrigation * density * fertilizer  + Error(block / irrigation / density), data = data)\nsummary(model2)\n\n\nError: block\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  194.4   64.81               \n\nError: block:irrigation\n           Df Sum Sq Mean Sq F value Pr(>F)  \nirrigation  1   8278    8278   17.59 0.0247 *\nResiduals   3   1412     471                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: block:irrigation:density\n                   Df Sum Sq Mean Sq F value Pr(>F)  \ndensity             2   1758   879.2   3.784 0.0532 .\nirrigation:density  2   2747  1373.5   5.912 0.0163 *\nResiduals          12   2788   232.3                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n                              Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer                     2 1977.4   988.7  11.449 0.000142 ***\nirrigation:fertilizer          2  953.4   476.7   5.520 0.008108 ** \ndensity:fertilizer             4  304.9    76.2   0.883 0.484053    \nirrigation:density:fertilizer  4  234.7    58.7   0.680 0.610667    \nResiduals                     36 3108.8    86.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n11.3.4 Graficos de interacción\n\n# ver interacciones entre fertilizacion y riego\ninteraction.plot(data$fertilizer, data$irrigation, data$yield)\n\n\n\n# ver interacciones entre densidad y riego\ninteraction.plot(data$density, data$irrigation, data$yield)\n\n\n\n\n\n\n11.3.5 Interacción entre variables\nInteraccion entre variables usando el paquete effects. Se debe usar modelo lm en este caso\n\n# \nlibrary(effects)\n\nLoading required package: carData\n\n\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n\n# hacer un modelo lm. No es necasario los terminos de error, ya que es solo para ver interacciones en un grafico\nmodel2_b <- lm(yield ~ irrigation*density*fertilizer, data = data) # es el mismo que model1, pero con la funcion lm\neffects <- allEffects(model2_b)\nplot(effects)"
  },
  {
    "objectID": "ancova.html#anova-con-muestreo-anidado-bloque",
    "href": "ancova.html#anova-con-muestreo-anidado-bloque",
    "title": "11  Ancova",
    "section": "11.4 ANOVA con muestreo anidado (bloque)",
    "text": "11.4 ANOVA con muestreo anidado (bloque)\n\n11.4.1 Lectura de Datos\n\n## Carga de datos ---------------------------------------------------------\n\ndata <- read.csv('../data/crop.data.csv')\n\nstr(data)\n\n'data.frame':   96 obs. of  4 variables:\n $ density   : int  1 2 1 2 1 2 1 2 1 2 ...\n $ block     : int  1 2 3 4 1 2 3 4 1 2 ...\n $ fertilizer: int  1 1 1 1 1 1 1 1 1 1 ...\n $ yield     : num  177 178 176 178 177 ...\n\n# se fijan, hay tratamientos de fertilizacion 1, 2, 3 en cada bloque\ndata[data$block == 4, ]\n\n   density block fertilizer    yield\n4        2     4          1 177.7036\n8        2     4          1 177.0612\n12       2     4          1 177.0305\n16       2     4          1 176.0084\n20       2     4          1 176.9188\n24       2     4          1 176.8179\n28       2     4          1 177.1649\n32       2     4          1 175.8828\n36       2     4          2 177.3608\n40       2     4          2 177.9980\n44       2     4          2 177.0341\n48       2     4          2 177.1977\n52       2     4          2 176.8191\n56       2     4          2 176.6683\n60       2     4          2 176.8789\n64       2     4          2 177.3526\n68       2     4          3 177.5403\n72       2     4          3 176.4308\n76       2     4          3 177.3442\n80       2     4          3 179.0609\n84       2     4          3 177.7945\n88       2     4          3 177.6328\n92       2     4          3 177.4053\n96       2     4          3 177.1182\n\n\n\n\n11.4.2 one-way ANOVA\n\nsummary(aov(yield ~ fertilizer, data = data))\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer   1   5.74   5.743   14.91 0.000207 ***\nResiduals   94  36.21   0.385                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTukeyHSD(aov(yield ~ as.factor(fertilizer), data = data))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = yield ~ as.factor(fertilizer), data = data)\n\n$`as.factor(fertilizer)`\n         diff         lwr       upr     p adj\n2-1 0.1761687 -0.19371896 0.5460564 0.4954705\n3-1 0.5991256  0.22923789 0.9690133 0.0006125\n3-2 0.4229569  0.05306916 0.7928445 0.0208735\n\n\n\n\n11.4.3 two-way ANOVA\n\nsummary(aov(yield ~ fertilizer + density, data = data))\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer   1  5.743   5.743   17.18 7.49e-05 ***\ndensity      1  5.122   5.122   15.32 0.000173 ***\nResiduals   93 31.089   0.334                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(yield ~ fertilizer * density, data = data))\n\n                   Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer          1  5.743   5.743  17.078  7.9e-05 ***\ndensity             1  5.122   5.122  15.230 0.000181 ***\nfertilizer:density  1  0.150   0.150   0.447 0.505630    \nResiduals          92 30.939   0.336                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n## Agregar bloque ----------------------------------------------------------\nsummary(aov(yield ~ fertilizer + density + block, data = data))\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer   1  5.743   5.743  17.265 7.27e-05 ***\ndensity      1  5.122   5.122  15.397 0.000168 ***\nblock        1  0.486   0.486   1.461 0.229823    \nResiduals   92 30.603   0.333                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# LO IMPORTANTE ACA ES QUE LA IMPORTANCIA DEL BLOQUE ES BAJA. SE LOGRA ELIMINAR SU EFECTO"
  },
  {
    "objectID": "ancova.html#one-way-ancova-1",
    "href": "ancova.html#one-way-ancova-1",
    "title": "11  Ancova",
    "section": "11.5 one-way ANCOVA",
    "text": "11.5 one-way ANCOVA\n\n11.5.1 Cargar Datos\n\n## Carga de datos ----------------------------------------------------------\n\nregrowth <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/ipomopsis.txt',\n                       header = T, stringsAsFactors = TRUE)\nnames(regrowth)\n\n[1] \"Root\"    \"Fruit\"   \"Grazing\"\n\nstr(regrowth)\n\n'data.frame':   40 obs. of  3 variables:\n $ Root   : num  6.22 6.49 4.92 5.13 5.42 ...\n $ Fruit  : num  59.8 61 14.7 19.3 34.2 ...\n $ Grazing: Factor w/ 2 levels \"Grazed\",\"Ungrazed\": 2 2 2 2 2 2 2 2 2 2 ...\n\nlevels(regrowth$Grazing)\n\n[1] \"Grazed\"   \"Ungrazed\"\n\n\n\n\n11.5.2 Ploteo relacion entre variables\n\n# plot de la relacion entre cantidad de fruta, tamano de raiz y clases de riego\nplot(regrowth$Root, regrowth$Fruit, pch = 16 + as.numeric(regrowth$Grazing),\n     col = c(\"blue\", \"red\")[as.numeric(regrowth$Grazing)],\n     xlab = \"Tamaño de la raíz\", ylab = \"Cantidad de fruta\")\nabline(lm(Fruit[Grazing == \"Grazed\"] ~ Root[Grazing == \"Grazed\"], data = regrowth),\n       lty = 2, col = \"blue\")\nabline(lm(Fruit[Grazing == \"Ungrazed\"] ~ Root[Grazing == \"Ungrazed\"], data = regrowth),\n       lty = 2, col = \"red\")\nlegend('topleft', legend = c('Grazed', 'Ungrazed'), lwd = 2, col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n11.5.3 ANOVA\n\nsummary(aov(Fruit ~ Grazing, data = regrowth))\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nGrazing      1   2910  2910.4   5.309 0.0268 *\nResiduals   38  20833   548.2                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n11.5.4 Regresion\n\nsummary(lm(Fruit ~ Root, data = regrowth))\n\n\nCall:\nlm(formula = Fruit ~ Root, data = regrowth)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.3844 -10.4447  -0.7574  10.7606  23.7556 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -41.286     10.723  -3.850 0.000439 ***\nRoot          14.022      1.463   9.584  1.1e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.52 on 38 degrees of freedom\nMultiple R-squared:  0.7073,    Adjusted R-squared:  0.6996 \nF-statistic: 91.84 on 1 and 38 DF,  p-value: 1.099e-11\n\n\n\n\n11.5.5 ANCOCA\n\n# ANCOVA\nancova <- aov(Fruit ~ Root*Grazing, data = regrowth)\n# Root -> variable continua\n# Grazing -> Factor\n\n\n\n11.5.6 Resumen de los Modelos\n\nsummary(ancova)\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot          1  16795   16795 359.968  < 2e-16 ***\nGrazing       1   5264    5264 112.832 1.21e-12 ***\nRoot:Grazing  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(ancova)\n\n\nCall:\naov(formula = Fruit ~ Root * Grazing, data = regrowth)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.3177  -2.8320   0.1247   3.8511  17.1313 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          -125.173     12.811  -9.771 1.15e-11 ***\nRoot                   23.240      1.531  15.182  < 2e-16 ***\nGrazingUngrazed        30.806     16.842   1.829   0.0757 .  \nRoot:GrazingUngrazed    0.756      2.354   0.321   0.7500    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.831 on 36 degrees of freedom\nMultiple R-squared:  0.9293,    Adjusted R-squared:  0.9234 \nF-statistic: 157.6 on 3 and 36 DF,  p-value: < 2.2e-16\n\n\n\n\n11.5.7 Simplificacion del modelo\nAlternativa 1\n\nancova2 <- aov(Fruit ~ Grazing + Root, data = regrowth)\nsummary(ancova2)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)    \nGrazing      1   2910    2910   63.93 1.4e-09 ***\nRoot         1  19149   19149  420.62 < 2e-16 ***\nResiduals   37   1684      46                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAlternativa 2\n\nancova2 <- update(ancova, ~ . - Grazing:Root)\nsummary(ancova2)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot         1  16795   16795   368.9  < 2e-16 ***\nGrazing      1   5264    5264   115.6 6.11e-13 ***\nResiduals   37   1684      46                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComparación de las simplificaciones\n\n# la diferencia es significativa?\n\nanova(ancova, ancova2)\n\nAnalysis of Variance Table\n\nModel 1: Fruit ~ Root * Grazing\nModel 2: Fruit ~ Root + Grazing\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     36 1679.7                           \n2     37 1684.5 -1   -4.8122 0.1031   0.75\n\nAIC(ancova, ancova2) # AIC ancova2 es menor\n\n        df      AIC\nancova   5 273.0135\nancova2  4 271.1279\n\nsummary(ancova2)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot         1  16795   16795   368.9  < 2e-16 ***\nGrazing      1   5264    5264   115.6 6.11e-13 ***\nResiduals   37   1684      46                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(ancova2) \n\n\nCall:\naov(formula = Fruit ~ Root + Grazing, data = regrowth)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1920  -2.8224   0.3223   3.9144  17.3290 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -127.829      9.664  -13.23 1.35e-15 ***\nRoot              23.560      1.149   20.51  < 2e-16 ***\nGrazingUngrazed   36.103      3.357   10.75 6.11e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.747 on 37 degrees of freedom\nMultiple R-squared:  0.9291,    Adjusted R-squared:  0.9252 \nF-statistic: 242.3 on 2 and 37 DF,  p-value: < 2.2e-16\n\n# Intercept es Grazinggrazed (es la primera variable)\n\nEvaluación de Modelos con la función step()\nSe puede hacer una simplificacion de modelos automaticamente tambien usando la funcion step() la funcion es similar a lo que hicimos anteriormente en regresión, prueba todas las combinaicones de terminos y variables\n\n## step() -----------------------------------------------------------------\n\nstep(ancova)\n\nStart:  AIC=157.5\nFruit ~ Root * Grazing\n\n               Df Sum of Sq    RSS    AIC\n- Root:Grazing  1    4.8122 1684.5 155.61\n<none>                      1679.7 157.50\n\nStep:  AIC=155.61\nFruit ~ Root + Grazing\n\n          Df Sum of Sq     RSS    AIC\n<none>                  1684.5 155.61\n- Grazing  1    5264.4  6948.8 210.30\n- Root     1   19148.9 20833.4 254.22\n\n\nCall:\n   aov(formula = Fruit ~ Root + Grazing, data = regrowth)\n\nTerms:\n                     Root   Grazing Residuals\nSum of Squares  16795.002  5264.374  1684.461\nDeg. of Freedom         1         1        37\n\nResidual standard error: 6.747294\nEstimated effects may be unbalanced\n\nancova2 <- step(ancova)\n\nStart:  AIC=157.5\nFruit ~ Root * Grazing\n\n               Df Sum of Sq    RSS    AIC\n- Root:Grazing  1    4.8122 1684.5 155.61\n<none>                      1679.7 157.50\n\nStep:  AIC=155.61\nFruit ~ Root + Grazing\n\n          Df Sum of Sq     RSS    AIC\n<none>                  1684.5 155.61\n- Grazing  1    5264.4  6948.8 210.30\n- Root     1   19148.9 20833.4 254.22\n\nsummary.aov(ancova2)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot         1  16795   16795   368.9  < 2e-16 ***\nGrazing      1   5264    5264   115.6 6.11e-13 ***\nResiduals   37   1684      46                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "ancova.html#ancova-con-dos-factores-y-una-variable-continua",
    "href": "ancova.html#ancova-con-dos-factores-y-una-variable-continua",
    "title": "11  Ancova",
    "section": "11.6 ANCOVA con dos factores y una variable continua",
    "text": "11.6 ANCOVA con dos factores y una variable continua\n\n11.6.1 Cargar los Datos\n\nGain <- read.table('https://raw.githubusercontent.com/shifteight/R-lang/master/TRB/data/Gain.txt',\n                   header=T, stringsAsFactors = TRUE)\n\nattach(Gain)\n\nThe following objects are masked from Gain (pos = 5):\n\n    Age, Genotype, Score, Sex, Weight\n\nnames(Gain)\n\n[1] \"Weight\"   \"Sex\"      \"Age\"      \"Genotype\" \"Score\"   \n\nstr(Gain)\n\n'data.frame':   60 obs. of  5 variables:\n $ Weight  : num  7.45 8 7.71 8.35 8.45 ...\n $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Age     : int  1 2 3 4 5 1 2 3 4 5 ...\n $ Genotype: Factor w/ 6 levels \"CloneA\",\"CloneB\",..: 1 1 1 1 1 2 2 2 2 2 ...\n $ Score   : num  4 4 4 4 4 5 5 5 5 5 ...\n\n\n\n\n11.6.2 ANCOVA multiple\n\nm1 <- aov(Weight ~ Sex*Age*Genotype) # argumento data no se utiliza\n# Sex -> factor\n# Age -> variable continua\n# Genotype -> factor\n\n\nsummary(m1)\n\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nSex               1  10.37  10.374 183.440 1.06e-15 ***\nAge               1  10.77  10.770 190.450 6.03e-16 ***\nGenotype          5  54.96  10.992 194.371  < 2e-16 ***\nSex:Age           1   0.05   0.049   0.865    0.358    \nSex:Genotype      5   0.15   0.029   0.520    0.760    \nAge:Genotype      5   0.17   0.034   0.595    0.704    \nSex:Age:Genotype  5   0.35   0.070   1.235    0.313    \nResiduals        36   2.04   0.057                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(m1)\n\n\nCall:\naov(formula = Weight ~ Sex * Age * Genotype)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40218 -0.12043 -0.01065  0.12592  0.44687 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 7.80053    0.24941  31.276  < 2e-16 ***\nSexmale                    -0.51966    0.35272  -1.473  0.14936    \nAge                         0.34950    0.07520   4.648 4.39e-05 ***\nGenotypeCloneB              1.19870    0.35272   3.398  0.00167 ** \nGenotypeCloneC             -0.41751    0.35272  -1.184  0.24429    \nGenotypeCloneD              0.95600    0.35272   2.710  0.01023 *  \nGenotypeCloneE             -0.81604    0.35272  -2.314  0.02651 *  \nGenotypeCloneF              1.66851    0.35272   4.730 3.41e-05 ***\nSexmale:Age                -0.11283    0.10635  -1.061  0.29579    \nSexmale:GenotypeCloneB     -0.31716    0.49882  -0.636  0.52891    \nSexmale:GenotypeCloneC     -1.06234    0.49882  -2.130  0.04010 *  \nSexmale:GenotypeCloneD     -0.73547    0.49882  -1.474  0.14906    \nSexmale:GenotypeCloneE     -0.28533    0.49882  -0.572  0.57087    \nSexmale:GenotypeCloneF     -0.19839    0.49882  -0.398  0.69319    \nAge:GenotypeCloneB         -0.10146    0.10635  -0.954  0.34643    \nAge:GenotypeCloneC         -0.20825    0.10635  -1.958  0.05799 .  \nAge:GenotypeCloneD         -0.01757    0.10635  -0.165  0.86970    \nAge:GenotypeCloneE         -0.03825    0.10635  -0.360  0.72123    \nAge:GenotypeCloneF         -0.05512    0.10635  -0.518  0.60743    \nSexmale:Age:GenotypeCloneB  0.15469    0.15040   1.029  0.31055    \nSexmale:Age:GenotypeCloneC  0.35322    0.15040   2.349  0.02446 *  \nSexmale:Age:GenotypeCloneD  0.19227    0.15040   1.278  0.20929    \nSexmale:Age:GenotypeCloneE  0.13203    0.15040   0.878  0.38585    \nSexmale:Age:GenotypeCloneF  0.08709    0.15040   0.579  0.56616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2378 on 36 degrees of freedom\nMultiple R-squared:  0.9742,    Adjusted R-squared:  0.9577 \nF-statistic: 59.06 on 23 and 36 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "ancova.html#evaluación-de-modelo-ancova-multiple",
    "href": "ancova.html#evaluación-de-modelo-ancova-multiple",
    "title": "11  Ancova",
    "section": "11.7 Evaluación de Modelo Ancova Multiple",
    "text": "11.7 Evaluación de Modelo Ancova Multiple\n\n## step() -----------------------------------------------------------------\nm2 <- step(m1)\n\nStart:  AIC=-155.01\nWeight ~ Sex * Age * Genotype\n\n                   Df Sum of Sq    RSS     AIC\n- Sex:Age:Genotype  5   0.34912 2.3849 -155.51\n<none>                          2.0358 -155.01\n\nStep:  AIC=-155.51\nWeight ~ Sex + Age + Genotype + Sex:Age + Sex:Genotype + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Sex:Genotype  5  0.146901 2.5318 -161.92\n- Age:Genotype  5  0.168136 2.5531 -161.42\n- Sex:Age       1  0.048937 2.4339 -156.29\n<none>                      2.3849 -155.51\n\nStep:  AIC=-161.92\nWeight ~ Sex + Age + Genotype + Sex:Age + Age:Genotype\n\n               Df Sum of Sq    RSS     AIC\n- Age:Genotype  5  0.168136 2.7000 -168.07\n- Sex:Age       1  0.048937 2.5808 -162.78\n<none>                      2.5318 -161.92\n\nStep:  AIC=-168.07\nWeight ~ Sex + Age + Genotype + Sex:Age\n\n           Df Sum of Sq    RSS      AIC\n- Sex:Age   1     0.049  2.749 -168.989\n<none>                   2.700 -168.066\n- Genotype  5    54.958 57.658    5.612\n\nStep:  AIC=-168.99\nWeight ~ Sex + Age + Genotype\n\n           Df Sum of Sq    RSS      AIC\n<none>                   2.749 -168.989\n- Sex       1    10.374 13.122  -77.201\n- Age       1    10.770 13.519  -75.415\n- Genotype  5    54.958 57.707    3.662\n\nsummary(m2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nSex          1  10.37  10.374   196.2 <2e-16 ***\nAge          1  10.77  10.770   203.7 <2e-16 ***\nGenotype     5  54.96  10.992   207.9 <2e-16 ***\nResiduals   52   2.75   0.053                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(m2)\n\n\nCall:\naov(formula = Weight ~ Sex + Age + Genotype)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40005 -0.15120 -0.01668  0.16953  0.49227 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     7.93701    0.10066  78.851  < 2e-16 ***\nSexmale        -0.83161    0.05937 -14.008  < 2e-16 ***\nAge             0.29958    0.02099  14.273  < 2e-16 ***\nGenotypeCloneB  0.96778    0.10282   9.412 8.07e-13 ***\nGenotypeCloneC -1.04361    0.10282 -10.149 6.21e-14 ***\nGenotypeCloneD  0.82396    0.10282   8.013 1.21e-10 ***\nGenotypeCloneE -0.87540    0.10282  -8.514 1.98e-11 ***\nGenotypeCloneF  1.53460    0.10282  14.925  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2299 on 52 degrees of freedom\nMultiple R-squared:  0.9651,    Adjusted R-squared:  0.9604 \nF-statistic: 205.7 on 7 and 52 DF,  p-value: < 2.2e-16\n\nanova(m1, m2)\n\nAnalysis of Variance Table\n\nModel 1: Weight ~ Sex * Age * Genotype\nModel 2: Weight ~ Sex + Age + Genotype\n  Res.Df    RSS  Df Sum of Sq      F Pr(>F)\n1     36 2.0358                            \n2     52 2.7489 -16   -0.7131 0.7881 0.6883\n\nAIC(m1, m2)\n\n   df       AIC\nm1 25 17.265355\nm2  9  3.283978\n\n\n\n11.7.1 Normalidad de residuos\n\n# shapiro test de normalidad en los residuos\n\nshapiro.test(m2$residuals) # son normales\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98321, p-value = 0.5782\n\npar(mfrow = c(2, 2))\nplot(m2)\n\n\n\ndev.off()\n\nnull device \n          1 \n\n\n\n\n11.7.2 Visualización relación entre variables\nGráfico de las relaciones entre peso y edad en relacion a las clases de genotipo.\n\nplot(Age, Weight, type = \"n\")\ncolours <- c(\"green\", \"red\", \"black\", \"blue\")\nlines <- c(1, 2)\nsymbols <- c(16, 17)\npoints(Age, Weight, pch = symbols[as.numeric(Sex)],\n       col = colours[as.numeric(Genotype)])\nxv <- c(1, 5)\n\nfor (i in 1:2) {\n  for (j in 1:4) {\n    a <- coef(m2)[1]+(i>1)* coef(m2)[2]+(j>1)*coef(m2)[j+2]\n    b <- coef(m2)[3]\n    yv <- a+b*xv\n    lines(xv,yv,lty=lines[i],col=colours[j]) } }"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Canavos, George C. 1988. “The Sensitivity of the One-Sample and\nTwo-Sample Student t Statistics.” Computational Statistics\n& Data Analysis 6 (1): 39–46. https://doi.org/10.1016/0167-9473(88)90061-8.\n\n\n“Explaining the Lm() Summary in R –\nLearn by Marketing.” n.d. Accessed\nSeptember 2, 2022. https://www.learnbymarketing.com/tutorials/explaining-the-lm-summary-in-r/.\n\n\nKuhn, Max. n.d. 7 Train Models By Tag |\nThe Caret Package. Accessed September 9,\n2022. https://topepo.github.io/caret/train-models-by-tag.html.\n\n\nMatemáticas profe Alex. 2017. “Varianza y Desviación Estándar |\nIntroducción,” June. https://www.youtube.com/watch?v=oZRaDwnpXkY.\n\n\nMcClave, J. T., and T. Sincich. 2003. Statistics. Prentice\nHall.\n\n\n“Varianza.” 2022. https://es.wikipedia.org/w/index.php?title=Varianza&oldid=144468342.\n\n\nZar, Jerrold H. 1999. Biostatistical Analysis. Pearson\nEducation India."
  }
]