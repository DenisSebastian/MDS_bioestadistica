{
  "hash": "a215198509fe1ed8e32e553d131912e7",
  "result": {
    "markdown": "---\nsubtitletitle: \"Análisis multivariado\"\neditor: visual\n---\n\n\n# Clusters\n\n\n## Práctico\n\n**Cargar librerías**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vegan)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: permute\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is vegan 2.6-4\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggpubr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggplot2\n```\n:::\n\n```{.r .cell-code}\nlibrary(factoextra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n```\n:::\n\n```{.r .cell-code}\nlibrary(hopkins)\nlibrary(NbClust)\n```\n:::\n\n\n\nCargar Data\n\nDatos iris de plantas:\n: Este famoso conjunto de datos de iris (de Fisher o de Anderson) da las medidas en centimetros de las variables longitud y ancho de los sepalos y longitud y ancho de los petalos, respectivamente,  para 50 flores de cada una de las 3 especies de iris. Las especies son Iris setosa, versicolor y virginica.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"iris\")\n\n# sacar informacion que no es necesaria\ndf <- iris[, -5]\n```\n:::\n\n\n\nGenerar datos aleatorios\n\nGeneramos un dataset de mentira, usando valores aleatorios en los rangos de valores de cada columna vamos a usarlo para comparar la posibilidad de hacer clustering con datos aleatorios y agregados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_df <- apply(df, 2, # el argumento MARGIN = 2 quiere decir que se realizara la funcion sobre las columnas\n                   function(x){runif(length(x), min(x), (max(x)))}) # runif para crear x numero de observaciones\nrandom_df <- as.data.frame(random_df)\n```\n:::\n\n\n\n\n### PCA \n\n::: {.cell}\n\n```{.r .cell-code}\n# hacer PCA, usar escalado p normalizacion de los datos\npca = prcomp(df, scale = T)\npca_random = prcomp(random_df, scale = T)\n```\n:::\n\n\n\nPlot PCA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_ind(pca, title = \"PCA - Iris data\", \n             habillage = iris$Species,  \n             palette = \"jco\",\n             geom = \"text\", # \"text\"\n             ggtheme = theme_classic(),\n             legend = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the random df\nfviz_pca_ind(pca_random, \n             title = \"PCA - Random data\",\n             habillage = iris$Species,  \n             palette = \"jco\",\n             geom = \"point\", \n             ggtheme = theme_classic())\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### fviz_pca_var ------------------------------------------------------------\n# La funcion fviz_pca_var grafica los vectores de las variables\n\nfviz_pca_var(pca,\n             geom = \"arrow\", # \"text\"\n             col.var = \"red\",\n             alpha.var = \"contrib\"\n               ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_var(pca_random,\n             geom = \"arrow\", # \"text\"\n             col.var = \"red\",\n             alpha.var = \"contrib\"\n) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### fviz_pca_biplot ---------------------------------------------------------\n\nfviz_pca_biplot(pca)\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfviz_pca_biplot(pca_random)\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\n\n\n### Inspección de los datos\n\nHopkins statistics\n\n\nOpción 1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### get_clust_tendency ------------------------------------------------------\n# Esta funcion es iterativa, como nombramos en la case, por lo que valores > 0.5 \n# se concluyen que son clusterizables\n\n# data iris\nres <- get_clust_tendency(pca$x[, 1:2], n = nrow(df) - 1, graph = FALSE)\nres$hopkins_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7766724\n```\n:::\n\n```{.r .cell-code}\n# data random\nres <- get_clust_tendency(random_df, n = nrow(random_df)-1, graph = FALSE)\nres$hopkins_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.50328\n```\n:::\n:::\n\n\n\nOpciópn 2:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### clustertend -------------------------------------------------------------\n# Con esta funcion  es mas dicicil de interpretar, se basa en un test mas clasico estadistico\n# H0 = aleatorio\n# H1 = clusterizado\n# pero van a ver que el valor de P no es tan directo como P < 0.05\n\nhopkins(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9980229\n```\n:::\n\n```{.r .cell-code}\nhopkins(random_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5850471\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Interpretacion visual  --------------------------------------------------\n# estimar matrices de disimilaridad usando distancia euclidiana\n# la funcion dist() sirve bien en este caso, para mas opciones usar vegdist (vegan)\n\n# datos Iris\ndm <- dist(df)\nfviz_dist(dm) \n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# datos random\ndm <- dist(random_df)\nfviz_dist(dm) \n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Selección de K\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Seleccion numero cluster para k-means  ----------------------------\n###  Metodo del codo --------------------------------------------------------\n# variacion inter-cluster (wss) (mas bajo mejor)\nfviz_nbclust(x = scale(df), FUNcluster = kmeans, method = \"wss\", k.max = 15) +\n  labs(title = \"Número óptimo de clusters\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### Metodo de silueta -------------------------------------------------------\n# silhouette (numero mas alto mejor)\nfviz_nbclust(x = scale(df), FUNcluster = kmeans, method = \"silhouette\", k.max = 15) +\n  labs(title = \"Número óptimo de clusters\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### Gap statistic -----------------------------------------------------------\n# Gap statistic (numero mas alto mejor)\nfviz_nbclust(x = scale(df), FUNcluster = kmeans,\n             method = \"gap_stat\", k.max = 15) +\n  labs(title = \"Número óptimo de clusters\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n### Kmeans\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Kmeans ------------------------------------------------------------------\n\nkmeans1 <- kmeans(scale(df), centers = 3)\nkmeans1$cluster\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2\n [75] 2 3 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3\n[112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 3 3 3 3 3 3 2 2 3 3 3 2 3 3 3 2 3 3 3 2 3\n[149] 3 2\n```\n:::\n\n```{.r .cell-code}\nkmeans1$tot.withinss\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 138.8884\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Estimar por varios metodos simultaneamente ----------------------------\n\nclusters1 <- NbClust(data = scale(df), distance = \"euclidean\", min.nc = 2,\n                     max.nc = 10, method = \"kmeans\", index = \"alllong\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n*** : The Hubert index is a graphical method of determining the number of clusters.\n                In the plot of Hubert index, we seek a significant knee that corresponds to a \n                significant increase of the value of the measure i.e the significant peak in Hubert\n                index second differences plot. \n \n```\n:::\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n*** : The D index is a graphical method of determining the number of clusters. \n                In the plot of D index, we seek a significant knee (the significant peak in Dindex\n                second differences plot) that corresponds to a significant increase of the value of\n                the measure. \n \n******************************************************************* \n* Among all indices:                                                \n* 13 proposed 2 as the best number of clusters \n* 10 proposed 3 as the best number of clusters \n* 1 proposed 4 as the best number of clusters \n* 1 proposed 6 as the best number of clusters \n* 3 proposed 10 as the best number of clusters \n\n                   ***** Conclusion *****                            \n \n* According to the majority rule, the best number of clusters is  2 \n \n \n******************************************************************* \n```\n:::\n\n```{.r .cell-code}\nfviz_nbclust(clusters1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"numeric\") print(best_nc) else if\n(class(best_nc) == : the condition has length > 1 and only the first element\nwill be used\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"matrix\") .viz_NbClust(x, print.summary, : the\ncondition has length > 1 and only the first element will be used\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"numeric\") print(best_nc) else if\n(class(best_nc) == : the condition has length > 1 and only the first element\nwill be used\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"matrix\") {: the condition has length > 1 and\nonly the first element will be used\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAmong all indices: \n===================\n* 2 proposed  0 as the best number of clusters\n* 13 proposed  2 as the best number of clusters\n* 10 proposed  3 as the best number of clusters\n* 1 proposed  4 as the best number of clusters\n* 1 proposed  6 as the best number of clusters\n* 3 proposed  10 as the best number of clusters\n\nConclusion\n=========================\n* According to the majority rule, the best number of clusters is  2 .\n```\n:::\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-18-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# clusters1$All.index\nclusters1$Best.partition\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[149] 2 2\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### Resultados --------------------------------------------------------------\n# que observaciones corresponden a cada clase? \nwhich(clusters1$Best.partition == 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n```\n:::\n\n```{.r .cell-code}\nwhich(clusters1$Best.partition == 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1]  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n [19]  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n [37]  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n [55] 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n [73] 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n [91] 141 142 143 144 145 146 147 148 149 150\n```\n:::\n\n```{.r .cell-code}\niris$Species[clusters1$Best.partition==1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] setosa setosa setosa setosa setosa setosa setosa setosa setosa setosa\n[11] setosa setosa setosa setosa setosa setosa setosa setosa setosa setosa\n[21] setosa setosa setosa setosa setosa setosa setosa setosa setosa setosa\n[31] setosa setosa setosa setosa setosa setosa setosa setosa setosa setosa\n[41] setosa setosa setosa setosa setosa setosa setosa setosa setosa setosa\nLevels: setosa versicolor virginica\n```\n:::\n\n```{.r .cell-code}\niris$Species[clusters1$Best.partition==2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] versicolor versicolor versicolor versicolor versicolor versicolor\n  [7] versicolor versicolor versicolor versicolor versicolor versicolor\n [13] versicolor versicolor versicolor versicolor versicolor versicolor\n [19] versicolor versicolor versicolor versicolor versicolor versicolor\n [25] versicolor versicolor versicolor versicolor versicolor versicolor\n [31] versicolor versicolor versicolor versicolor versicolor versicolor\n [37] versicolor versicolor versicolor versicolor versicolor versicolor\n [43] versicolor versicolor versicolor versicolor versicolor versicolor\n [49] versicolor versicolor virginica  virginica  virginica  virginica \n [55] virginica  virginica  virginica  virginica  virginica  virginica \n [61] virginica  virginica  virginica  virginica  virginica  virginica \n [67] virginica  virginica  virginica  virginica  virginica  virginica \n [73] virginica  virginica  virginica  virginica  virginica  virginica \n [79] virginica  virginica  virginica  virginica  virginica  virginica \n [85] virginica  virginica  virginica  virginica  virginica  virginica \n [91] virginica  virginica  virginica  virginica  virginica  virginica \n [97] virginica  virginica  virginica  virginica \nLevels: setosa versicolor virginica\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# grafico con colores por clases\nfviz_pca_ind(pca, \n             title = \"PCA - Iris data\", \n             habillage = clusters1$Best.partition,  \n             palette = \"jco\",\n             geom = \"point\", \n             ggtheme = theme_classic(),\n             legend = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n### Datos 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Datos de espectoscopia de campo -----------------------------------------\n# cargar foliares de pigmentos (clorofila, carotenoides, contenido de agua, ...) \n# con datos hiperespectrales tomados por espectroscopia de campo \n# (datos de reflectancia de teledetección = 2051 variables)\n\n# datos de rasgos de hojas + reflectancia\ndata1 <- read.csv('https://raw.githubusercontent.com/JavierLopatin/Clases/master/M%C3%A9todos_avanzados_en_R/dataset/angers-leaf-optical-properties-database--2003.csv')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtrar datos -----------------------------------------------------------\n# solamente utilizar los datos de reflectancia, los de transmitancia no los utilizaremos.\ndata1 <- data1[data1$Measurement_type == 'reflectance', ]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# obtener los los rasgos y cambiar el nombre de las columnas\ntraits <- data1[, c(2, 4, 7, 9, 15)]\ncolnames(traits) <- c('Car', 'Cab', 'Cw', 'Cm', 'N')\nhead(traits)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Car      Cab         Cw         Cm        N\n1  4.33 12.54078 0.01222310 0.00550680 1.313594\n4  3.65 12.41369 0.01200028 0.00525210 1.425785\n7  6.50 25.81402 0.01059972 0.00445635 1.549407\n10 6.90 24.13499 0.01085436 0.00432900 1.652313\n12 4.91 17.12158 0.01037691 0.00401070 1.437254\n14 3.85 13.54378 0.01021775 0.00401070 1.531708\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# obtener la reflectancia\nreflec <- data1[, 22:ncol(data1)]\n# head(reflec)\n```\n:::\n\n\n## PCA\n\n\n::: {.cell}\n\n```{.r .cell-code}\npca <- prcomp(reflec, scale = TRUE)\nnames(pca)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Cluster -----------------------------------------------------------------\n# numero ideal de clusters\nset.seed(123)\nclusters2 <- NbClust(data = pca$x[,1:2], distance = \"euclidean\", min.nc = 2,\n                     max.nc = 10, method = \"kmeans\", index = \"alllong\")\nfviz_nbclust(clusters2)\nclusters2$Best.partition\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"numeric\") print(best_nc) else if\n(class(best_nc) == : the condition has length > 1 and only the first element\nwill be used\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"matrix\") .viz_NbClust(x, print.summary, : the\ncondition has length > 1 and only the first element will be used\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"numeric\") print(best_nc) else if\n(class(best_nc) == : the condition has length > 1 and only the first element\nwill be used\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in if (class(best_nc) == \"matrix\") {: the condition has length > 1 and\nonly the first element will be used\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAmong all indices: \n===================\n* 2 proposed  0 as the best number of clusters\n* 1 proposed  1 as the best number of clusters\n* 6 proposed  2 as the best number of clusters\n* 5 proposed  3 as the best number of clusters\n* 4 proposed  4 as the best number of clusters\n* 2 proposed  5 as the best number of clusters\n* 1 proposed  6 as the best number of clusters\n* 1 proposed  7 as the best number of clusters\n* 4 proposed  8 as the best number of clusters\n* 1 proposed  9 as the best number of clusters\n* 3 proposed  10 as the best number of clusters\n\nConclusion\n=========================\n* According to the majority rule, the best number of clusters is  2 .\n```\n:::\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n  1   4   7  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38  40  42 \n  1   1   2   2   2   2   2   2   2   2   2   2   2   2   2   2   1   1   2   2 \n 44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76  78  80  82 \n  1   1   2   2   2   1   2   2   2   2   2   2   2   1   2   2   2   2   2   2 \n 84  86  88  90  92  94  96  98 100 102 104 106 108 110 112 114 116 118 120 122 \n  2   2   2   2   2   2   2   2   2   2   2   2   1   1   1   1   1   1   1   2 \n124 126 128 130 132 134 136 138 140 142 144 146 148 150 152 154 156 158 160 162 \n  1   1   2   2   2   2   2   2   1   1   2   2   1   1   2   1   2   2   2   2 \n164 166 168 170 172 174 176 178 180 182 184 186 188 190 192 194 196 198 200 202 \n  2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2 \n204 206 208 210 212 214 216 218 220 222 224 226 228 230 232 234 236 238 240 242 \n  2   2   2   2   1   1   2   2   1   1   2   2   1   1   2   2   2   2   2   2 \n244 246 248 250 252 254 256 258 260 262 264 266 268 270 272 274 276 278 280 282 \n  2   2   2   2   2   2   2   2   2   2   1   1   1   1   2   2   1   1   1   1 \n284 286 288 290 292 294 296 298 300 302 304 306 308 310 312 314 316 318 320 322 \n  1   1   1   1   2   1   2   2   2   2   2   2   1   1   1   1   1   1   1   2 \n324 326 328 330 332 334 336 338 340 342 344 346 348 350 352 354 356 358 360 362 \n  1   1   1   1   1   1   1   2   2   1   1   1   1   1   2   2   2   2   2   2 \n364 366 368 370 372 374 376 378 380 382 384 386 388 390 392 394 396 398 400 402 \n  1   1   1   2   2   2   2   2   2   1   1   1   1   1   2   1   1   1   1   1 \n404 406 408 410 412 414 416 418 420 422 424 426 428 430 432 434 436 438 440 442 \n  1   2   2   2   2   2   2   2   1   2   2   2   2   1   1   1   2   1   1   1 \n444 446 448 450 452 454 456 458 460 462 464 466 468 470 472 474 476 478 480 482 \n  1   2   2   2   2   2   1   2   2   2   2   2   2   1   1   1   1   2   2   1 \n484 486 488 490 492 494 496 498 500 502 504 506 508 510 512 514 516 518 520 522 \n  1   1   1   2   2   1   1   2   1   1   1   1   1   1   1   1   1   2   1   1 \n524 526 528 530 532 534 536 538 540 542 544 546 548 550 552 554 \n  1   1   2   2   1   1   1   1   1   1   1   1   1   1   1   1 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### Plot --------------------------------------------------------------------\n\nenv <- envfit(pca, traits) # La funcion ajusta vectores o factores ambientales en una ordenacion.\nplot(pca$x[,c(1,2)], col = clusters2$Best.partition, pch = 16)\n# dev.off()\nplot(env)\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n## Turberas\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Turbera con NMDS --------------------------------------------------------\n\n## Cargar datos ------------------------------------------------------------\n\ncob_data = read.csv('https://raw.githubusercontent.com/JavierLopatin/Clases/master/M%C3%A9todos_avanzados_en_R/dataset/Cover_spp_peatland.csv')\nveg_data = read.csv('https://raw.githubusercontent.com/JavierLopatin/Clases/master/M%C3%A9todos_avanzados_en_R/dataset/Peatland.csv')\n\n# datos de presencia/cobertura (0-100) de especies\ncob_data[1:8, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Plot Sphagnum.sp Sticherus_cryptocarpus Uncinia_tenuis Juncus_procerus\n1    1          10                     50              0              20\n2    2          20                     40             20               0\n3    3           0                      0              0               0\n4    4           0                     70              0               0\n5    5          10                     50              1               0\n6    6           5                     10              0              60\n7    7          30                     35              0              10\n8    8           0                     65              0               0\n```\n:::\n\n```{.r .cell-code}\n# datos de vegetacion y suelo en tuerbera\nveg_data[1:8, 4:7]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Altura   Biomasa   Carbono Riqueza\n1    153 1.3305831 13.496848       7\n2     54 0.8129926  8.835885       5\n3     52 0.9461947 12.377857       8\n4     25 0.3336366 18.261476       7\n5     90 2.3740400 16.807558       6\n6    130 1.0142415  6.237896       8\n7      4 0.3697878 12.081336       7\n8     48 1.4807187 14.042533       7\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# NMDS --------------------------------------------------------------------\n\n# Seleccionar el número de componentes (k) de acuerdo al stress\nnmds.stress <- sapply(1:6, function(x) metaMDS(cob_data[,2:ncol(cob_data)], distance='bray', k = x)$stress)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.3857319 \nRun 1 stress 0.5426863 \nRun 2 stress 0.5601819 \nRun 3 stress 0.5604783 \nRun 4 stress 0.5542214 \nRun 5 stress 0.5414761 \nRun 6 stress 0.527185 \nRun 7 stress 0.5327152 \nRun 8 stress 0.5047657 \nRun 9 stress 0.3890268 \nRun 10 stress 0.5606399 \nRun 11 stress 0.4450788 \nRun 12 stress 0.4793383 \nRun 13 stress 0.5587264 \nRun 14 stress 0.5083215 \nRun 15 stress 0.4614011 \nRun 16 stress 0.4763974 \nRun 17 stress 0.5520983 \nRun 18 stress 0.456409 \nRun 19 stress 0.5254892 \nRun 20 stress 0.4372759 \n*** Best solution was not repeated -- monoMDS stopping criteria:\n     1: stress ratio > sratmax\n    19: scale factor of the gradient < sfgrmin\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.1923727 \nRun 1 stress 0.1923726 \n... New best solution\n... Procrustes: rmse 8.541045e-05  max resid 0.000400036 \n... Similar to previous best\nRun 2 stress 0.1923727 \n... Procrustes: rmse 0.0001222113  max resid 0.0006005915 \n... Similar to previous best\nRun 3 stress 0.1923726 \n... Procrustes: rmse 7.050848e-06  max resid 2.465748e-05 \n... Similar to previous best\nRun 4 stress 0.2561639 \nRun 5 stress 0.1923727 \n... Procrustes: rmse 0.0001082055  max resid 0.0005322097 \n... Similar to previous best\nRun 6 stress 0.2031201 \nRun 7 stress 0.3936754 \nRun 8 stress 0.1923726 \n... Procrustes: rmse 1.087396e-05  max resid 5.329712e-05 \n... Similar to previous best\nRun 9 stress 0.2518956 \nRun 10 stress 0.1923726 \n... Procrustes: rmse 1.493948e-06  max resid 7.117867e-06 \n... Similar to previous best\nRun 11 stress 0.2564063 \nRun 12 stress 0.1923727 \n... Procrustes: rmse 7.224348e-05  max resid 0.000355573 \n... Similar to previous best\nRun 13 stress 0.2333127 \nRun 14 stress 0.2031201 \nRun 15 stress 0.2800944 \nRun 16 stress 0.1923726 \n... Procrustes: rmse 1.966379e-06  max resid 8.060699e-06 \n... Similar to previous best\nRun 17 stress 0.1923726 \n... New best solution\n... Procrustes: rmse 7.575362e-06  max resid 3.662978e-05 \n... Similar to previous best\nRun 18 stress 0.2139629 \nRun 19 stress 0.2038645 \nRun 20 stress 0.1923726 \n... Procrustes: rmse 1.201172e-05  max resid 5.872963e-05 \n... Similar to previous best\n*** Best solution repeated 2 times\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.1235178 \nRun 1 stress 0.1235178 \n... New best solution\n... Procrustes: rmse 6.382757e-05  max resid 0.0001885531 \n... Similar to previous best\nRun 2 stress 0.1393996 \nRun 3 stress 0.1264616 \nRun 4 stress 0.1263587 \nRun 5 stress 0.1235179 \n... Procrustes: rmse 4.978539e-05  max resid 0.0001602043 \n... Similar to previous best\nRun 6 stress 0.1243044 \nRun 7 stress 0.1235179 \n... Procrustes: rmse 0.0001227537  max resid 0.0004786504 \n... Similar to previous best\nRun 8 stress 0.1235179 \n... Procrustes: rmse 0.0001453185  max resid 0.0005514929 \n... Similar to previous best\nRun 9 stress 0.1235178 \n... Procrustes: rmse 3.386403e-05  max resid 9.864189e-05 \n... Similar to previous best\nRun 10 stress 0.1235178 \n... Procrustes: rmse 5.244228e-05  max resid 0.00017385 \n... Similar to previous best\nRun 11 stress 0.1264609 \nRun 12 stress 0.1235178 \n... Procrustes: rmse 4.984972e-05  max resid 0.0001577974 \n... Similar to previous best\nRun 13 stress 0.1235179 \n... Procrustes: rmse 7.983455e-05  max resid 0.0002743034 \n... Similar to previous best\nRun 14 stress 0.1235179 \n... Procrustes: rmse 0.0001461075  max resid 0.0005522178 \n... Similar to previous best\nRun 15 stress 0.1235178 \n... Procrustes: rmse 5.893151e-05  max resid 0.0001985999 \n... Similar to previous best\nRun 16 stress 0.126461 \nRun 17 stress 0.1264609 \nRun 18 stress 0.1263583 \nRun 19 stress 0.1267449 \nRun 20 stress 0.1235178 \n... New best solution\n... Procrustes: rmse 9.850897e-06  max resid 2.279755e-05 \n... Similar to previous best\n*** Best solution repeated 1 times\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.09289043 \nRun 1 stress 0.0928907 \n... Procrustes: rmse 0.0004625496  max resid 0.001576994 \n... Similar to previous best\nRun 2 stress 0.0928907 \n... Procrustes: rmse 0.0004495649  max resid 0.001527415 \n... Similar to previous best\nRun 3 stress 0.09289389 \n... Procrustes: rmse 0.001172071  max resid 0.004064954 \n... Similar to previous best\nRun 4 stress 0.09897122 \nRun 5 stress 0.09289124 \n... Procrustes: rmse 0.0006922692  max resid 0.002445032 \n... Similar to previous best\nRun 6 stress 0.09289117 \n... Procrustes: rmse 0.0006596876  max resid 0.002444468 \n... Similar to previous best\nRun 7 stress 0.09289126 \n... Procrustes: rmse 0.0007180485  max resid 0.002642458 \n... Similar to previous best\nRun 8 stress 0.09289059 \n... Procrustes: rmse 0.0004052224  max resid 0.001440503 \n... Similar to previous best\nRun 9 stress 0.09289125 \n... Procrustes: rmse 0.0006262657  max resid 0.002195934 \n... Similar to previous best\nRun 10 stress 0.0928906 \n... Procrustes: rmse 0.0002335095  max resid 0.0008958358 \n... Similar to previous best\nRun 11 stress 0.09482517 \nRun 12 stress 0.09370445 \nRun 13 stress 0.09279393 \n... New best solution\n... Procrustes: rmse 0.02579753  max resid 0.1069719 \nRun 14 stress 0.09289055 \n... Procrustes: rmse 0.02573238  max resid 0.1066406 \nRun 15 stress 0.09279385 \n... New best solution\n... Procrustes: rmse 0.0004611966  max resid 0.001388567 \n... Similar to previous best\nRun 16 stress 0.09289053 \n... Procrustes: rmse 0.02593918  max resid 0.1076334 \nRun 17 stress 0.09289051 \n... Procrustes: rmse 0.02606942  max resid 0.1084585 \nRun 18 stress 0.09279407 \n... Procrustes: rmse 0.0001115516  max resid 0.0003075789 \n... Similar to previous best\nRun 19 stress 0.09289063 \n... Procrustes: rmse 0.02584293  max resid 0.1073264 \nRun 20 stress 0.09289051 \n... Procrustes: rmse 0.02584909  max resid 0.1074566 \n*** Best solution repeated 2 times\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.07593068 \nRun 1 stress 0.07593456 \n... Procrustes: rmse 0.002897248  max resid 0.008073687 \n... Similar to previous best\nRun 2 stress 0.07526411 \n... New best solution\n... Procrustes: rmse 0.05121967  max resid 0.1656961 \nRun 3 stress 0.07526441 \n... Procrustes: rmse 0.001311145  max resid 0.004363915 \n... Similar to previous best\nRun 4 stress 0.07578304 \nRun 5 stress 0.07584263 \nRun 6 stress 0.07635292 \nRun 7 stress 0.07526442 \n... Procrustes: rmse 0.0009042487  max resid 0.002258812 \n... Similar to previous best\nRun 8 stress 0.07620666 \nRun 9 stress 0.07526439 \n... Procrustes: rmse 0.001655325  max resid 0.006437287 \n... Similar to previous best\nRun 10 stress 0.07616248 \nRun 11 stress 0.07579168 \nRun 12 stress 0.07619842 \nRun 13 stress 0.07614624 \nRun 14 stress 0.07583621 \nRun 15 stress 0.07564013 \n... Procrustes: rmse 0.0263841  max resid 0.1271941 \nRun 16 stress 0.07598125 \nRun 17 stress 0.07736624 \nRun 18 stress 0.07597923 \nRun 19 stress 0.07706052 \nRun 20 stress 0.07526406 \n... New best solution\n... Procrustes: rmse 0.001277672  max resid 0.004385501 \n... Similar to previous best\n*** Best solution repeated 1 times\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.06186845 \nRun 1 stress 0.06379612 \nRun 2 stress 0.06237454 \nRun 3 stress 0.06263849 \nRun 4 stress 0.06251037 \nRun 5 stress 0.06243933 \nRun 6 stress 0.06197935 \n... Procrustes: rmse 0.01017859  max resid 0.02968044 \nRun 7 stress 0.06313993 \nRun 8 stress 0.06356649 \nRun 9 stress 0.06197038 \n... Procrustes: rmse 0.00962411  max resid 0.02805013 \nRun 10 stress 0.1763408 \nRun 11 stress 0.06223962 \n... Procrustes: rmse 0.01748858  max resid 0.06610401 \nRun 12 stress 0.06234147 \n... Procrustes: rmse 0.02147161  max resid 0.08600148 \nRun 13 stress 0.06329911 \nRun 14 stress 0.06350443 \nRun 15 stress 0.06337565 \nRun 16 stress 0.06187247 \n... Procrustes: rmse 0.003994152  max resid 0.01117107 \nRun 17 stress 0.06188965 \n... Procrustes: rmse 0.003567426  max resid 0.01113659 \nRun 18 stress 0.06333107 \nRun 19 stress 0.06246038 \nRun 20 stress 0.06309002 \n*** Best solution was not repeated -- monoMDS stopping criteria:\n    19: no. of iterations >= maxit\n     1: stress ratio > sratmax\n```\n:::\n\n```{.r .cell-code}\nplot(1:6, \n     nmds.stress, \n     xlab = \"Número de componentes\", \n     ylab = 'Stress')\nabline(h = 0.15, lty = 2, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](cluster_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "cluster_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}